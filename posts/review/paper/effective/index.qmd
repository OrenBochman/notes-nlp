---
date: 2021-05-08
title: "Effective Approaches to Attention-based Neural Machine Translation"
subtitle: "review"
description: 'Review of the 2015 paper "Effective Approaches to Attention-based Neural Machine Translation" on the scaled dot product attention.'
categories: [NLP, Paper, Attention, Deep learning, Review, Stub]
#draft: true
---

![Litrature review](/images/literature-review-open-book.jpg){.column-margin}


::: {#vid-01 .column-margin}
{{< video  https://youtu.be/IxQtK2SjWWM?t=7 >}}

Attention models by Christopher D. Manning
:::

::: {#vid-02 .column-margin}
{{< video  https://youtu.be/R05UzD8SQLE?t=6 >}}

Paper Explained by Professor. Maziar Raissi
:::

## Introduction

## Effective Approaches to Attention-based Neural Machine Translation

## Abstract

> An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMTâ€™15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. -- [@luong2015effectiveapproachesattentionbasedneural]

![](img/fig-01.png){#fig-01 .column-margin}

![](img/fig-02.png){#fig-02 .column-margin}

![](img/fig-03.png){#fig-03 .column-margin}

![](img/fig-04.png){#fig-04 .column-margin}

![](img/fig-05.png){#fig-05 .column-margin}

![](img/fig-06.png){#fig-06 .column-margin}

![](img/fig-07.png){#fig-07 .column-margin}




## Outline

## The Paper

![paper](./paper.pdf){.col-page width=800px height=1000px group="slides"}
