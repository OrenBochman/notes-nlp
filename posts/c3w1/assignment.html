<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">

<title>Assignment 1: Sentiment with Deep Neural Networks – NLP Specialization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1372234da3246ce8e868649689ba5ed0.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-d99a2a2a191b5c7f2a9a83135e7f0803.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">NLP Specialization</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Assignment 1: Sentiment with Deep Neural Networks</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Assignment 1: Sentiment with Deep Neural Networks</h1>
            <p class="subtitle lead">Sequence Models</p>
                                <div class="quarto-categories">
                <div class="quarto-category">NLP</div>
                <div class="quarto-category">Coursera</div>
                <div class="quarto-category">Lab</div>
                <div class="quarto-category">Sequence Models</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-body">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Wednesday, February 5, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Classification &amp; Vector Spaces</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 Preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 Frequencies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w1/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 Visualizing tweets</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w1/assignment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A1 Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability and Bayes Rule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 Visualizing Naive Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w2/assignment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A2 Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vector Space Models and PCA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 Linear algebra with NumPy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 Manipulating word embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w3/assignment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A3 Hello Vectors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Machine Translation and Document Search via KNN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 Vector manipulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 Hash functions and multiplanes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c1w3/assignment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A4 Naive Machine Translation and LSH</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilistic Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c2w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Autocorrect and Dynamic Programming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c2w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Part of Speech Tagging and Hidden Markov Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c2w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Autocomplete and Language Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c2w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word embeddings with neural networks</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequence Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c3w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Machine Translation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c3w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Text Summarization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c3w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Question Answering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c3w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chat Bots</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">NLP with Attention Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c4w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Machine Translation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c4w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Text Summarization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c4w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Question Answering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/c4w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chat Bots</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#outline" id="toc-outline" class="nav-link active" data-scroll-target="#outline">Outline</a></li>
  <li><a href="#1" id="toc-1" class="nav-link" data-scroll-target="#1">Part 1: Import libraries and try out Trax</a></li>
  <li><a href="#2" id="toc-2" class="nav-link" data-scroll-target="#2">Part 2: Importing the data</a>
  <ul class="collapse">
  <li><a href="#2.1" id="toc-2.1" class="nav-link" data-scroll-target="#2.1">2.1 Loading in the data</a></li>
  <li><a href="#2.2" id="toc-2.2" class="nav-link" data-scroll-target="#2.2">2.2 Building the vocabulary</a></li>
  <li><a href="#2.3" id="toc-2.3" class="nav-link" data-scroll-target="#2.3">2.3 Converting a tweet to a tensor</a>
  <ul class="collapse">
  <li><a href="#ex01" id="toc-ex01" class="nav-link" data-scroll-target="#ex01">Exercise 01</a></li>
  </ul></li>
  <li><a href="#2.4" id="toc-2.4" class="nav-link" data-scroll-target="#2.4">2.4 Creating a batch generator</a>
  <ul class="collapse">
  <li><a href="#ex02" id="toc-ex02" class="nav-link" data-scroll-target="#ex02">Exercise 02</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#3" id="toc-3" class="nav-link" data-scroll-target="#3">Part 3: Defining classes</a>
  <ul class="collapse">
  <li><a href="#3.1" id="toc-3.1" class="nav-link" data-scroll-target="#3.1">3.1 ReLU class</a>
  <ul class="collapse">
  <li><a href="#ex03" id="toc-ex03" class="nav-link" data-scroll-target="#ex03">Exercise 03</a></li>
  </ul></li>
  <li><a href="#3.2" id="toc-3.2" class="nav-link" data-scroll-target="#3.2">3.2 Dense class</a>
  <ul class="collapse">
  <li><a href="#exercise" id="toc-exercise" class="nav-link" data-scroll-target="#exercise">Exercise</a></li>
  <li><a href="#ex04" id="toc-ex04" class="nav-link" data-scroll-target="#ex04">Exercise 04</a></li>
  </ul></li>
  <li><a href="#3.3" id="toc-3.3" class="nav-link" data-scroll-target="#3.3">3.3 Model</a>
  <ul class="collapse">
  <li><a href="#ex05" id="toc-ex05" class="nav-link" data-scroll-target="#ex05">Exercise 05</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#4" id="toc-4" class="nav-link" data-scroll-target="#4">Part 4: Training</a>
  <ul class="collapse">
  <li><a href="#4.1" id="toc-4.1" class="nav-link" data-scroll-target="#4.1">4.1 Training the model</a>
  <ul class="collapse">
  <li><a href="#ex06" id="toc-ex06" class="nav-link" data-scroll-target="#ex06">Exercise 06</a></li>
  </ul></li>
  <li><a href="#4.2" id="toc-4.2" class="nav-link" data-scroll-target="#4.2">4.2 Practice Making a prediction</a></li>
  </ul></li>
  <li><a href="#5" id="toc-5" class="nav-link" data-scroll-target="#5">Part 5: Evaluation</a>
  <ul class="collapse">
  <li><a href="#5.1" id="toc-5.1" class="nav-link" data-scroll-target="#5.1">5.1 Computing the accuracy on a batch</a>
  <ul class="collapse">
  <li><a href="#ex07" id="toc-ex07" class="nav-link" data-scroll-target="#ex07">Exercise 07</a></li>
  </ul></li>
  <li><a href="#5.2" id="toc-5.2" class="nav-link" data-scroll-target="#5.2">5.2 Testing your model on Validation Data</a></li>
  </ul></li>
  <li><a href="#6" id="toc-6" class="nav-link" data-scroll-target="#6">Part 6: Testing with your own input</a>
  <ul class="collapse">
  <li><a href="#on-deep-nets" id="toc-on-deep-nets" class="nav-link" data-scroll-target="#on-deep-nets">On Deep Nets</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/posts/c3w1/assignment.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full column-body" id="quarto-document-content">






<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/Course-Logo-3-3.webp" class="nolightbox img-fluid figure-img"></p>
<figcaption>course banner</figcaption>
</figure>
</div></div><div class="callout callout-style-simple callout-none no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Honor code alert
</div>
</div>
<div class="callout-body-container callout-body">
<p>Due to the Coursera Honor Code, I cannot provide the solutions to the assignments.</p>
<ul>
<li>This notebook is the original notebook provided by the course</li>
<li>It is setup to run without stopping for errors.</li>
<li>It is also likely to be out of date as the course has had some updates since I took it.</li>
<li>Although I aced the course this assignment was the most time consuming.</li>
<li>Good luck with the assignment it should make we a better programmer.</li>
<li>It is also a good idea to go over it a few times until we can do it easily.</li>
</ul>
</div>
</div>
<p>Welcome to the first assignment of course 3. In this assignment, you will explore sentiment analysis using deep neural networks.</p>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<ul>
<li><a href="#1">Part 1: Import libraries and try out Trax</a></li>
<li><a href="#2">Part 2: Importing the data</a>
<ul>
<li><a href="#2.1">2.1 Loading in the data</a></li>
<li><a href="#2.2">2.2 Building the vocabulary</a></li>
<li><a href="#2.3">2.3 Converting a tweet to a tensor</a>
<ul>
<li><a href="#ex01">Exercise 01</a></li>
</ul></li>
<li><a href="#2.4">2.4 Creating a batch generator</a>
<ul>
<li><a href="#ex02">Exercise 02</a></li>
</ul></li>
</ul></li>
<li><a href="#3">Part 3: Defining classes</a>
<ul>
<li><a href="#3.1">3.1 ReLU class</a>
<ul>
<li><a href="#ex03">Exercise 03</a></li>
</ul></li>
<li><a href="#3.2">3.2 Dense class</a>
<ul>
<li><a href="#ex04">Exercise 04</a></li>
</ul></li>
<li><a href="#3.3">3.3 Model</a>
<ul>
<li><a href="#ex05">Exercise 05</a></li>
</ul></li>
</ul></li>
<li><a href="#4">Part 4: Training</a>
<ul>
<li><a href="#4.1">4.1 Training the model</a>
<ul>
<li><a href="#ex06">Exercise 06</a></li>
</ul></li>
<li><a href="#4.2">4.2 Practice Making a prediction</a></li>
</ul></li>
<li><a href="#5">Part 5: Evaluation</a>
<ul>
<li><a href="#5.1">5.1 Computing the accuracy on a batch</a>
<ul>
<li><a href="#ex07">Exercise 07</a></li>
</ul></li>
<li><a href="#5.2">5.2 Testing your model on Validation Data</a>
<ul>
<li><a href="#ex08">Exercise 08</a></li>
</ul></li>
</ul></li>
<li><a href="#6">Part 6: Testing with your own input</a></li>
</ul>
<p>In course 1, you implemented <strong>Logistic regression</strong> and <strong>Naive Bayes</strong> for sentiment analysis. However if you were to give your old models an example like:</p>
<div style="text-align: center">
<p><span style="color:blue"><strong>This movie was almost good.</strong></span></p>
</div>
<p>Your model would have predicted a positive sentiment for that review. However, that sentence has a <strong>negative sentiment</strong> and indicates that the movie was <strong>not good</strong>. To solve those kinds of misclassifications, you will write a program that uses deep neural networks to identify sentiment in text. By completing this assignment, you will:</p>
<ul>
<li>Understand how you can build/design a model using layers</li>
<li>Train a model using a training loop</li>
<li>Use a binary cross-entropy loss function</li>
<li>Compute the accuracy of your model</li>
<li>Predict using your own input</li>
</ul>
<p>As you can tell, this model follows a similar structure to the one you previously implemented in the second course of this specialization. - Indeed most of the deep nets you will be implementing will have a similar structure. The only thing that changes is the model architecture, the inputs, and the outputs. Before starting the assignment, we will introduce you to the Google library <code>trax</code> that we use for building and training models.</p>
<p>Now we will show you how to compute the gradient of a certain function <code>f</code> by just using <code>.grad(f)</code>.</p>
<ul>
<li>Trax source code can be found on Github: <a href="https://github.com/google/trax">Trax</a></li>
<li>The Trax code also uses the JAX library: <a href="https://jax.readthedocs.io/en/latest/index.html">JAX</a></li>
</ul>
</section>
<section id="1" class="level1">
<h1>Part 1: Import libraries and try out Trax</h1>
<ul>
<li>Let’s import libraries and look at an example of using the Trax library.</li>
</ul>
<div id="50556356" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random <span class="im">as</span> rnd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># import relevant libraries</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> trax</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># set random seeds to make this notebook easier to replicate</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trax <span class="im">import</span> fastmath</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>seed<span class="op">=</span><span class="dv">31</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> fastmath.random.get_prng(seed)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">#trax.supervised.trainer_lib.init_random_number_generators(31)</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># import trax.fastmath.numpy</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> trax.fastmath.numpy <span class="im">as</span> np</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># import trax.layers</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trax <span class="im">import</span> layers <span class="im">as</span> tl</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># import Layer from the utils.py file</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> utils <span class="im">import</span> Layer, load_tweets, process_tweet</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">#from utils import </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2025-02-05 18:37:57.493608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1738773477.508865  544018 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1738773477.513090  544018 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
[nltk_data] Downloading package twitter_samples to
[nltk_data]     /home/oren/nltk_data...
[nltk_data]   Package twitter_samples is already up-to-date!
[nltk_data] Downloading package stopwords to /home/oren/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!</code></pre>
</div>
</div>
<div id="3cafa76d" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an array using trax.fastmath.numpy</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.array(<span class="fl">5.0</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># View the returned array</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>display(a)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(a))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Array(5., dtype=float32, weak_type=True)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'jaxlib.xla_extension.ArrayImpl'&gt;</code></pre>
</div>
</div>
<p>Notice that trax.fastmath.numpy returns a DeviceArray from the jax library.</p>
<div id="89c8e512" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function that will use the trax.fastmath.numpy array</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># f = x^2</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (x<span class="op">**</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b5db4095" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the function</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"f(a) for a=</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss"> is </span><span class="sc">{</span>f(a)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>f(a) for a=5.0 is 25.0</code></pre>
</div>
</div>
<p>The gradient (derivative) of function <code>f</code> with respect to its input <code>x</code> is the derivative of <span class="math inline">x^2</span>. - The derivative of <span class="math inline">x^2</span> is <span class="math inline">2x</span>.<br>
- When x is 5, then <span class="math inline">2x=10</span>.</p>
<p>You can calculate the gradient of a function by using <code>trax.fastmath.grad(fun=)</code> and passing in the name of the function. - In this case the function you want to take the gradient of is <code>f</code>. - The object returned (saved in <code>grad_f</code> in this example) is a function that can calculate the gradient of f for a given trax.fastmath.numpy array.</p>
<div id="eefa769f" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Directly use trax.fastmath.grad to calculate the gradient (derivative) of the function</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>grad_f <span class="op">=</span> trax.fastmath.grad(fun<span class="op">=</span>f)  <span class="co"># df / dx - Gradient of function f(x) with respect to x</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># View the type of the retuned object (it's a function)</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(grad_f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>function</code></pre>
</div>
</div>
<div id="9ad42ed4" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the newly created function and pass in a value for x (the DeviceArray stored in 'a')</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>grad_calculation <span class="op">=</span> grad_f(a)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># View the result of calling the grad_f function</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>display(grad_calculation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Array(10., dtype=float32, weak_type=True)</code></pre>
</div>
</div>
<p>The function returned by trax.fastmath.grad takes in x=5 and calculates the gradient of f, which is 2*x, which is 10. The value is also stored as a DeviceArray from the jax library.</p>
</section>
<section id="2" class="level1">
<h1>Part 2: Importing the data</h1>
<section id="2.1" class="level2">
<h2 class="anchored" data-anchor-id="2.1">2.1 Loading in the data</h2>
<p>Import the data set.<br>
- You may recognize this from earlier assignments in the specialization. - Details of process_tweet function are available in utils.py file</p>
<div id="e648413e" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">## DO NOT EDIT THIS CELL</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Import functions from the utils.py file</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load positive and negative tweets</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>all_positive_tweets, all_negative_tweets <span class="op">=</span> load_tweets()</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># View the total number of positive and negative tweets.</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The number of positive tweets: </span><span class="sc">{</span><span class="bu">len</span>(all_positive_tweets)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The number of negative tweets: </span><span class="sc">{</span><span class="bu">len</span>(all_negative_tweets)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Split positive set into validation and training</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>val_pos   <span class="op">=</span> all_positive_tweets[<span class="dv">4000</span>:] <span class="co"># generating validation set for positive tweets</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>train_pos  <span class="op">=</span> all_positive_tweets[:<span class="dv">4000</span>]<span class="co"># generating training set for positive tweets</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Split negative set into validation and training</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>val_neg   <span class="op">=</span> all_negative_tweets[<span class="dv">4000</span>:] <span class="co"># generating validation set for negative tweets</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>train_neg  <span class="op">=</span> all_negative_tweets[:<span class="dv">4000</span>] <span class="co"># generating training set for nagative tweets</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine training data into one set</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>train_x <span class="op">=</span> train_pos <span class="op">+</span> train_neg </span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine validation data into one set</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>val_x  <span class="op">=</span> val_pos <span class="op">+</span> val_neg</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the labels for the training set (1 for positive, 0 for negative)</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>train_y <span class="op">=</span> np.append(np.ones(<span class="bu">len</span>(train_pos)), np.zeros(<span class="bu">len</span>(train_neg)))</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the labels for the validation set (1 for positive, 0 for negative)</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>val_y  <span class="op">=</span> np.append(np.ones(<span class="bu">len</span>(val_pos)), np.zeros(<span class="bu">len</span>(val_neg)))</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"length of train_x </span><span class="sc">{</span><span class="bu">len</span>(train_x)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"length of val_x </span><span class="sc">{</span><span class="bu">len</span>(val_x)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The number of positive tweets: 5000
The number of negative tweets: 5000
length of train_x 8000
length of val_x 2000</code></pre>
</div>
</div>
<p>Now import a function that processes tweets (we’ve provided this in the utils.py file). - `process_tweets’ removes unwanted characters e.g.&nbsp;hashtag, hyperlinks, stock tickers from tweet. - It also returns a list of words (it tokenizes the original string).</p>
<div id="1e25f6f3" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import a function that processes the tweets</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># from utils import process_tweet</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Try out function that processes tweets</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"original tweet at training position 0"</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_pos[<span class="dv">0</span>])</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tweet at training position 0 after processing:"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>process_tweet(train_pos[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>original tweet at training position 0
#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)
Tweet at training position 0 after processing:</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']</code></pre>
</div>
</div>
<p>Notice that the function <code>process_tweet</code> keeps key words, removes the hash # symbol, and ignores usernames (words that begin with ‘@’). It also returns a list of the words.</p>
</section>
<section id="2.2" class="level2">
<h2 class="anchored" data-anchor-id="2.2">2.2 Building the vocabulary</h2>
<p>Now build the vocabulary. - Map each word in each tweet to an integer (an “index”). - The following code does this for you, but please read it and understand what it’s doing. - Note that you will build the vocabulary based on the training data. - To do so, you will assign an index to everyword by iterating over your training set.</p>
<p>The vocabulary will also include some special tokens - <code>__PAD__</code>: padding - <code>&lt;/e&gt;</code>: end of line - <code>__UNK__</code>: a token representing any word that is not in the vocabulary.</p>
<div id="99bdf77d" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the vocabulary</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Unit Test Note - There is no test set here only train/val</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Include special tokens </span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># started with pad, end of line and unk tokens</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>Vocab <span class="op">=</span> {<span class="st">'__PAD__'</span>: <span class="dv">0</span>, <span class="st">'__&lt;/e&gt;__'</span>: <span class="dv">1</span>, <span class="st">'__UNK__'</span>: <span class="dv">2</span>} </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that we build vocab using training data</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tweet <span class="kw">in</span> train_x: </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    processed_tweet <span class="op">=</span> process_tweet(tweet)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word <span class="kw">in</span> processed_tweet:</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> Vocab: </span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>            Vocab[word] <span class="op">=</span> <span class="bu">len</span>(Vocab)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Total words in vocab are"</span>,<span class="bu">len</span>(Vocab))</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>display(Vocab)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total words in vocab are 9088</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>{'__PAD__': 0,
 '__&lt;/e&gt;__': 1,
 '__UNK__': 2,
 'followfriday': 3,
 'top': 4,
 'engag': 5,
 'member': 6,
 'commun': 7,
 'week': 8,
 ':)': 9,
 'hey': 10,
 'jame': 11,
 'odd': 12,
 ':/': 13,
 'pleas': 14,
 'call': 15,
 'contact': 16,
 'centr': 17,
 '02392441234': 18,
 'abl': 19,
 'assist': 20,
 'mani': 21,
 'thank': 22,
 'listen': 23,
 'last': 24,
 'night': 25,
 'bleed': 26,
 'amaz': 27,
 'track': 28,
 'scotland': 29,
 'congrat': 30,
 'yeaaah': 31,
 'yipppi': 32,
 'accnt': 33,
 'verifi': 34,
 'rqst': 35,
 'succeed': 36,
 'got': 37,
 'blue': 38,
 'tick': 39,
 'mark': 40,
 'fb': 41,
 'profil': 42,
 '15': 43,
 'day': 44,
 'one': 45,
 'irresist': 46,
 'flipkartfashionfriday': 47,
 'like': 48,
 'keep': 49,
 'love': 50,
 'custom': 51,
 'wait': 52,
 'long': 53,
 'hope': 54,
 'enjoy': 55,
 'happi': 56,
 'friday': 57,
 'lwwf': 58,
 'second': 59,
 'thought': 60,
 '’': 61,
 'enough': 62,
 'time': 63,
 'dd': 64,
 'new': 65,
 'short': 66,
 'enter': 67,
 'system': 68,
 'sheep': 69,
 'must': 70,
 'buy': 71,
 'jgh': 72,
 'go': 73,
 'bayan': 74,
 ':d': 75,
 'bye': 76,
 'act': 77,
 'mischiev': 78,
 'etl': 79,
 'layer': 80,
 'in-hous': 81,
 'wareh': 82,
 'app': 83,
 'katamari': 84,
 'well': 85,
 '…': 86,
 'name': 87,
 'impli': 88,
 ':p': 89,
 'influenc': 90,
 'big': 91,
 '...': 92,
 'juici': 93,
 'selfi': 94,
 'follow': 95,
 'perfect': 96,
 'alreadi': 97,
 'know': 98,
 "what'": 99,
 'great': 100,
 'opportun': 101,
 'junior': 102,
 'triathlet': 103,
 'age': 104,
 '12': 105,
 '13': 106,
 'gatorad': 107,
 'seri': 108,
 'get': 109,
 'entri': 110,
 'lay': 111,
 'greet': 112,
 'card': 113,
 'rang': 114,
 'print': 115,
 'today': 116,
 'job': 117,
 ':-)': 118,
 "friend'": 119,
 'lunch': 120,
 'yummm': 121,
 'nostalgia': 122,
 'tb': 123,
 'ku': 124,
 'id': 125,
 'conflict': 126,
 'help': 127,
 "here'": 128,
 'screenshot': 129,
 'work': 130,
 'hi': 131,
 'liv': 132,
 'hello': 133,
 'need': 134,
 'someth': 135,
 'u': 136,
 'fm': 137,
 'twitter': 138,
 '—': 139,
 'sure': 140,
 'thing': 141,
 'dm': 142,
 'x': 143,
 "i'v": 144,
 'heard': 145,
 'four': 146,
 'season': 147,
 'pretti': 148,
 'dope': 149,
 'penthous': 150,
 'obv': 151,
 'gobigorgohom': 152,
 'fun': 153,
 "y'all": 154,
 'yeah': 155,
 'suppos': 156,
 'lol': 157,
 'chat': 158,
 'bit': 159,
 'youth': 160,
 '💅🏽': 161,
 '💋': 162,
 'seen': 163,
 'year': 164,
 'rest': 165,
 'goe': 166,
 'quickli': 167,
 'bed': 168,
 'music': 169,
 'fix': 170,
 'dream': 171,
 'spiritu': 172,
 'ritual': 173,
 'festiv': 174,
 'népal': 175,
 'begin': 176,
 'line-up': 177,
 'left': 178,
 'see': 179,
 'sarah': 180,
 'send': 181,
 'us': 182,
 'email': 183,
 'bitsy@bitdefender.com': 184,
 "we'll": 185,
 'asap': 186,
 'kik': 187,
 'hatessuc': 188,
 '32429': 189,
 'kikm': 190,
 'lgbt': 191,
 'tinder': 192,
 'nsfw': 193,
 'akua': 194,
 'cumshot': 195,
 'come': 196,
 'hous': 197,
 'nsn_supplement': 198,
 'effect': 199,
 'press': 200,
 'releas': 201,
 'distribut': 202,
 'result': 203,
 'link': 204,
 'remov': 205,
 'pressreleas': 206,
 'newsdistribut': 207,
 'bam': 208,
 'bestfriend': 209,
 'lot': 210,
 'warsaw': 211,
 '&lt;3': 212,
 'x46': 213,
 'everyon': 214,
 'watch': 215,
 'documentari': 216,
 'earthl': 217,
 'youtub': 218,
 'support': 219,
 'buuut': 220,
 'oh': 221,
 'look': 222,
 'forward': 223,
 'visit': 224,
 'next': 225,
 'letsgetmessi': 226,
 'jo': 227,
 'make': 228,
 'feel': 229,
 'better': 230,
 'never': 231,
 'anyon': 232,
 'kpop': 233,
 'flesh': 234,
 'good': 235,
 'girl': 236,
 'best': 237,
 'wish': 238,
 'reason': 239,
 'epic': 240,
 'soundtrack': 241,
 'shout': 242,
 'ad': 243,
 'video': 244,
 'playlist': 245,
 'would': 246,
 'dear': 247,
 'jordan': 248,
 'okay': 249,
 'fake': 250,
 'gameplay': 251,
 ';)': 252,
 'haha': 253,
 'im': 254,
 'kid': 255,
 'stuff': 256,
 'exactli': 257,
 'product': 258,
 'line': 259,
 'etsi': 260,
 'shop': 261,
 'check': 262,
 'vacat': 263,
 'recharg': 264,
 'normal': 265,
 'charger': 266,
 'asleep': 267,
 'talk': 268,
 'sooo': 269,
 'someon': 270,
 'text': 271,
 'ye': 272,
 'bet': 273,
 "he'll": 274,
 'fit': 275,
 'hear': 276,
 'speech': 277,
 'piti': 278,
 'green': 279,
 'garden': 280,
 'midnight': 281,
 'sun': 282,
 'beauti': 283,
 'canal': 284,
 'dasvidaniya': 285,
 'till': 286,
 'scout': 287,
 'sg': 288,
 'futur': 289,
 'wlan': 290,
 'pro': 291,
 'confer': 292,
 'asia': 293,
 'chang': 294,
 'lollipop': 295,
 '🍭': 296,
 'nez': 297,
 'agnezmo': 298,
 'oley': 299,
 'mama': 300,
 'stand': 301,
 'stronger': 302,
 'god': 303,
 'misti': 304,
 'babi': 305,
 'cute': 306,
 'woohoo': 307,
 "can't": 308,
 'sign': 309,
 'yet': 310,
 'still': 311,
 'think': 312,
 'mka': 313,
 'liam': 314,
 'access': 315,
 'welcom': 316,
 'stat': 317,
 'arriv': 318,
 '1': 319,
 'unfollow': 320,
 'via': 321,
 'surpris': 322,
 'figur': 323,
 'happybirthdayemilybett': 324,
 'sweet': 325,
 'talent': 326,
 '2': 327,
 'plan': 328,
 'drain': 329,
 'gotta': 330,
 'timezon': 331,
 'parent': 332,
 'proud': 333,
 'least': 334,
 'mayb': 335,
 'sometim': 336,
 'grade': 337,
 'al': 338,
 'grand': 339,
 'manila_bro': 340,
 'chosen': 341,
 'let': 342,
 'around': 343,
 '..': 344,
 'side': 345,
 'world': 346,
 'eh': 347,
 'take': 348,
 'care': 349,
 'final': 350,
 'fuck': 351,
 'weekend': 352,
 'real': 353,
 'x45': 354,
 'join': 355,
 'hushedcallwithfraydo': 356,
 'gift': 357,
 'yeahhh': 358,
 'hushedpinwithsammi': 359,
 'event': 360,
 'might': 361,
 'luv': 362,
 'realli': 363,
 'appreci': 364,
 'share': 365,
 'wow': 366,
 'tom': 367,
 'gym': 368,
 'monday': 369,
 'invit': 370,
 'scope': 371,
 'friend': 372,
 'nude': 373,
 'sleep': 374,
 'birthday': 375,
 'want': 376,
 't-shirt': 377,
 'cool': 378,
 'haw': 379,
 'phela': 380,
 'mom': 381,
 'obvious': 382,
 'princ': 383,
 'charm': 384,
 'stage': 385,
 'luck': 386,
 'tyler': 387,
 'hipster': 388,
 'glass': 389,
 'marti': 390,
 'glad': 391,
 'done': 392,
 'afternoon': 393,
 'read': 394,
 'kahfi': 395,
 'finish': 396,
 'ohmyg': 397,
 'yaya': 398,
 'dub': 399,
 'stalk': 400,
 'ig': 401,
 'gondooo': 402,
 'moo': 403,
 'tologooo': 404,
 'becom': 405,
 'detail': 406,
 'zzz': 407,
 'xx': 408,
 'physiotherapi': 409,
 'hashtag': 410,
 '💪': 411,
 'monica': 412,
 'miss': 413,
 'sound': 414,
 'morn': 415,
 "that'": 416,
 'x43': 417,
 'definit': 418,
 'tri': 419,
 'tonight': 420,
 'took': 421,
 'advic': 422,
 'treviso': 423,
 'concert': 424,
 'citi': 425,
 'countri': 426,
 "i'll": 427,
 'start': 428,
 'fine': 429,
 'gorgeou': 430,
 'xo': 431,
 'oven': 432,
 'roast': 433,
 'garlic': 434,
 'oliv': 435,
 'oil': 436,
 'dri': 437,
 'tomato': 438,
 'basil': 439,
 'centuri': 440,
 'tuna': 441,
 'right': 442,
 'back': 443,
 'atchya': 444,
 'even': 445,
 'almost': 446,
 'chanc': 447,
 'cheer': 448,
 'po': 449,
 'ice': 450,
 'cream': 451,
 'agre': 452,
 '100': 453,
 'heheheh': 454,
 'that': 455,
 'point': 456,
 'stay': 457,
 'home': 458,
 'soon': 459,
 'promis': 460,
 'web': 461,
 'whatsapp': 462,
 'volta': 463,
 'funcionar': 464,
 'com': 465,
 'iphon': 466,
 'jailbroken': 467,
 'later': 468,
 '34': 469,
 'min': 470,
 'leia': 471,
 'appear': 472,
 'hologram': 473,
 'r2d2': 474,
 'w': 475,
 'messag': 476,
 'obi': 477,
 'wan': 478,
 'sit': 479,
 'luke': 480,
 'inter': 481,
 '3': 482,
 'ucl': 483,
 'arsen': 484,
 'small': 485,
 'team': 486,
 'pass': 487,
 '🚂': 488,
 'dewsburi': 489,
 'railway': 490,
 'station': 491,
 'dew': 492,
 'west': 493,
 'yorkshir': 494,
 '430': 495,
 'smh': 496,
 '9:25': 497,
 'live': 498,
 'strang': 499,
 'imagin': 500,
 'megan': 501,
 'masaantoday': 502,
 'a4': 503,
 'shweta': 504,
 'tripathi': 505,
 '5': 506,
 '20': 507,
 'kurta': 508,
 'half': 509,
 'number': 510,
 'wsalelov': 511,
 'ah': 512,
 'larri': 513,
 'anyway': 514,
 'kinda': 515,
 'goood': 516,
 'life': 517,
 'enn': 518,
 'could': 519,
 'warmup': 520,
 '15th': 521,
 'bath': 522,
 'dum': 523,
 'andar': 524,
 'ram': 525,
 'sampath': 526,
 'sona': 527,
 'mohapatra': 528,
 'samantha': 529,
 'edward': 530,
 'mein': 531,
 'tulan': 532,
 'razi': 533,
 'wah': 534,
 'josh': 535,
 'alway': 536,
 'smile': 537,
 'pictur': 538,
 '16.20': 539,
 'giveitup': 540,
 'given': 541,
 'ga': 542,
 'subsidi': 543,
 'initi': 544,
 'propos': 545,
 'delight': 546,
 'yesterday': 547,
 'x42': 548,
 'lmaoo': 549,
 'song': 550,
 'ever': 551,
 'shall': 552,
 'littl': 553,
 'throwback': 554,
 'outli': 555,
 'island': 556,
 'cheung': 557,
 'chau': 558,
 'mui': 559,
 'wo': 560,
 'total': 561,
 'differ': 562,
 'kfckitchentour': 563,
 'kitchen': 564,
 'clean': 565,
 "i'm": 566,
 'cusp': 567,
 'test': 568,
 'water': 569,
 'reward': 570,
 'arummzz': 571,
 "let'": 572,
 'drive': 573,
 'travel': 574,
 'yogyakarta': 575,
 'jeep': 576,
 'indonesia': 577,
 'instamood': 578,
 'wanna': 579,
 'skype': 580,
 'may': 581,
 'nice': 582,
 'friendli': 583,
 'pretend': 584,
 'film': 585,
 'congratul': 586,
 'winner': 587,
 'cheesydelight': 588,
 'contest': 589,
 'address': 590,
 'guy': 591,
 'market': 592,
 '24/7': 593,
 '14': 594,
 'hour': 595,
 'leav': 596,
 'without': 597,
 'delay': 598,
 'actual': 599,
 'easi': 600,
 'guess': 601,
 'train': 602,
 'wd': 603,
 'shift': 604,
 'engin': 605,
 'etc': 606,
 'sunburn': 607,
 'peel': 608,
 'blog': 609,
 'huge': 610,
 'warm': 611,
 '☆': 612,
 'complet': 613,
 'triangl': 614,
 'northern': 615,
 'ireland': 616,
 'sight': 617,
 'smthng': 618,
 'fr': 619,
 'hug': 620,
 'xoxo': 621,
 'uu': 622,
 'jaann': 623,
 'topnewfollow': 624,
 'connect': 625,
 'wonder': 626,
 'made': 627,
 'fluffi': 628,
 'insid': 629,
 'pirouett': 630,
 'moos': 631,
 'trip': 632,
 'philli': 633,
 'decemb': 634,
 "i'd": 635,
 'dude': 636,
 'x41': 637,
 'question': 638,
 'flaw': 639,
 'pain': 640,
 'negat': 641,
 'strength': 642,
 'went': 643,
 'solo': 644,
 'move': 645,
 'fav': 646,
 'nirvana': 647,
 'smell': 648,
 'teen': 649,
 'spirit': 650,
 'rip': 651,
 'ami': 652,
 'winehous': 653,
 'coupl': 654,
 'tomhiddleston': 655,
 'elizabetholsen': 656,
 'yaytheylookgreat': 657,
 'goodnight': 658,
 'vid': 659,
 'wake': 660,
 'gonna': 661,
 'shoot': 662,
 'itti': 663,
 'bitti': 664,
 'teeni': 665,
 'bikini': 666,
 'much': 667,
 '4th': 668,
 'togeth': 669,
 'end': 670,
 'xfile': 671,
 'content': 672,
 'rain': 673,
 'fabul': 674,
 'fantast': 675,
 '♡': 676,
 'jb': 677,
 'forev': 678,
 'belieb': 679,
 'nighti': 680,
 'bug': 681,
 'bite': 682,
 'bracelet': 683,
 'idea': 684,
 'foundri': 685,
 'game': 686,
 'sens': 687,
 'pic': 688,
 'ef': 689,
 'phone': 690,
 'woot': 691,
 'derek': 692,
 'use': 693,
 'parkshar': 694,
 'gloucestershir': 695,
 'aaaahhh': 696,
 'man': 697,
 'traffic': 698,
 'stress': 699,
 'reliev': 700,
 "how'r": 701,
 'arbeloa': 702,
 'turn': 703,
 '17': 704,
 'omg': 705,
 'say': 706,
 'europ': 707,
 'rise': 708,
 'find': 709,
 'hard': 710,
 'believ': 711,
 'uncount': 712,
 'coz': 713,
 'unlimit': 714,
 'cours': 715,
 'teamposit': 716,
 'aldub': 717,
 '☕': 718,
 'rita': 719,
 'info': 720,
 "we'd": 721,
 'way': 722,
 'boy': 723,
 'x40': 724,
 'true': 725,
 'sethi': 726,
 'high': 727,
 'exe': 728,
 'skeem': 729,
 'saam': 730,
 'peopl': 731,
 'polit': 732,
 'izzat': 733,
 'wese': 734,
 'trust': 735,
 'khawateen': 736,
 'k': 737,
 'sath': 738,
 'mana': 739,
 'kar': 740,
 'deya': 741,
 'sort': 742,
 'smart': 743,
 'hair': 744,
 'tbh': 745,
 'jacob': 746,
 'g': 747,
 'upgrad': 748,
 'tee': 749,
 'famili': 750,
 'person': 751,
 'two': 752,
 'convers': 753,
 'onlin': 754,
 'mclaren': 755,
 'fridayfeel': 756,
 'tgif': 757,
 'squar': 758,
 'enix': 759,
 'bissmillah': 760,
 'ya': 761,
 'allah': 762,
 "we'r": 763,
 'socent': 764,
 'startup': 765,
 'drop': 766,
 'your': 767,
 'arnd': 768,
 'town': 769,
 'basic': 770,
 'piss': 771,
 'cup': 772,
 'also': 773,
 'terribl': 774,
 'complic': 775,
 'discuss': 776,
 'snapchat': 777,
 'lynettelow': 778,
 'kikmenow': 779,
 'snapm': 780,
 'hot': 781,
 'amazon': 782,
 'kikmeguy': 783,
 'defin': 784,
 'grow': 785,
 'sport': 786,
 'rt': 787,
 'rakyat': 788,
 'write': 789,
 'sinc': 790,
 'mention': 791,
 'fli': 792,
 'fish': 793,
 'promot': 794,
 'post': 795,
 'cyber': 796,
 'ourdaughtersourprid': 797,
 'mypapamyprid': 798,
 'papa': 799,
 'coach': 800,
 'posit': 801,
 'kha': 802,
 'atleast': 803,
 'x39': 804,
 'mango': 805,
 "lassi'": 806,
 "monty'": 807,
 'marvel': 808,
 'though': 809,
 'suspect': 810,
 'meant': 811,
 '24': 812,
 'hr': 813,
 'touch': 814,
 'kepler': 815,
 '452b': 816,
 'chalna': 817,
 'hai': 818,
 'thankyou': 819,
 'hazel': 820,
 'food': 821,
 'brooklyn': 822,
 'pta': 823,
 'awak': 824,
 'okayi': 825,
 'awww': 826,
 'ha': 827,
 'doc': 828,
 'splendid': 829,
 'spam': 830,
 'folder': 831,
 'amount': 832,
 'nigeria': 833,
 'claim': 834,
 'rted': 835,
 'leg': 836,
 'hurt': 837,
 'bad': 838,
 'mine': 839,
 'saturday': 840,
 'thaaank': 841,
 'puhon': 842,
 'happinesss': 843,
 'tnc': 844,
 'prior': 845,
 'notif': 846,
 'fat': 847,
 'co': 848,
 'probabl': 849,
 'ate': 850,
 'yuna': 851,
 'tamesid': 852,
 '´': 853,
 'googl': 854,
 'account': 855,
 'scouser': 856,
 'everyth': 857,
 'zoe': 858,
 'mate': 859,
 'liter': 860,
 "they'r": 861,
 'samee': 862,
 'edgar': 863,
 'updat': 864,
 'log': 865,
 'bring': 866,
 'abe': 867,
 'meet': 868,
 'x38': 869,
 'sigh': 870,
 'dreamili': 871,
 'pout': 872,
 'eye': 873,
 'quacketyquack': 874,
 'funni': 875,
 'happen': 876,
 'phil': 877,
 'em': 878,
 'del': 879,
 'rodder': 880,
 'els': 881,
 'play': 882,
 'newest': 883,
 'gamejam': 884,
 'irish': 885,
 'literatur': 886,
 'inaccess': 887,
 "kareena'": 888,
 'fan': 889,
 'brain': 890,
 'dot': 891,
 'braindot': 892,
 'fair': 893,
 'rush': 894,
 'either': 895,
 'brandi': 896,
 '18': 897,
 'carniv': 898,
 'men': 899,
 'put': 900,
 'mask': 901,
 'xavier': 902,
 'forneret': 903,
 'jennif': 904,
 'site': 905,
 'free': 906,
 '50.000': 907,
 '8': 908,
 'ball': 909,
 'pool': 910,
 'coin': 911,
 'edit': 912,
 'trish': 913,
 '♥': 914,
 'grate': 915,
 'three': 916,
 'comment': 917,
 'wakeup': 918,
 'besid': 919,
 'dirti': 920,
 'sex': 921,
 'lmaooo': 922,
 '😤': 923,
 'loui': 924,
 "he'": 925,
 'throw': 926,
 'caus': 927,
 'inspir': 928,
 'ff': 929,
 'twoof': 930,
 'gr8': 931,
 'wkend': 932,
 'kind': 933,
 'exhaust': 934,
 'word': 935,
 'cheltenham': 936,
 'area': 937,
 'kale': 938,
 'crisp': 939,
 'ruin': 940,
 'x37': 941,
 'open': 942,
 'worldwid': 943,
 'outta': 944,
 'sfvbeta': 945,
 'vantast': 946,
 'xcylin': 947,
 'bundl': 948,
 'show': 949,
 'internet': 950,
 'price': 951,
 'realisticli': 952,
 'pay': 953,
 'net': 954,
 'educ': 955,
 'power': 956,
 'weapon': 957,
 'nelson': 958,
 'mandela': 959,
 'recent': 960,
 'j': 961,
 'chenab': 962,
 'flow': 963,
 'pakistan': 964,
 'incredibleindia': 965,
 'teenchoic': 966,
 'choiceinternationalartist': 967,
 'superjunior': 968,
 'caught': 969,
 'first': 970,
 'salmon': 971,
 'super-blend': 972,
 'project': 973,
 'youth@bipolaruk.org.uk': 974,
 'awesom': 975,
 'stream': 976,
 'alma': 977,
 'mater': 978,
 'highschoolday': 979,
 'clientvisit': 980,
 'faith': 981,
 'christian': 982,
 'school': 983,
 'lizaminnelli': 984,
 'upcom': 985,
 'uk': 986,
 '😄': 987,
 'singl': 988,
 'hill': 989,
 'everi': 990,
 'beat': 991,
 'wrong': 992,
 'readi': 993,
 'natur': 994,
 'pefumeri': 995,
 'workshop': 996,
 'neal': 997,
 'yard': 998,
 'covent': 999,
 ...}</code></pre>
</div>
</div>
<p>The dictionary <code>Vocab</code> will look like this:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="op">{</span><span class="ch">'_</span><span class="er">_PAD__</span><span class="ch">'</span><span class="op">:</span> <span class="dv">0</span><span class="op">,</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a> <span class="ch">'_</span><span class="er">_&lt;/e&gt;__</span><span class="ch">'</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a> <span class="ch">'_</span><span class="er">_UNK__</span><span class="ch">'</span><span class="op">:</span> <span class="dv">2</span><span class="op">,</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a> <span class="ch">'f</span><span class="er">ollowfriday</span><span class="ch">'</span><span class="op">:</span> <span class="dv">3</span><span class="op">,</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a> <span class="ch">'t</span><span class="er">op</span><span class="ch">'</span><span class="op">:</span> <span class="dv">4</span><span class="op">,</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a> <span class="ch">'e</span><span class="er">ngag</span><span class="ch">'</span><span class="op">:</span> <span class="dv">5</span><span class="op">,</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a> <span class="op">...</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Each unique word has a unique integer associated with it.</li>
<li>The total number of words in Vocab: 9088</li>
</ul>
</section>
<section id="2.3" class="level2">
<h2 class="anchored" data-anchor-id="2.3">2.3 Converting a tweet to a tensor</h2>
<p>Write a function that will convert each tweet to a tensor (a list of unique integer IDs representing the processed tweet). - Note, the returned data type will be a <strong>regular Python <code>list()</code></strong> - You won’t use TensorFlow in this function - You also won’t use a numpy array - You also won’t use trax.fastmath.numpy array - For words in the tweet that are not in the vocabulary, set them to the unique ID for the token <code>__UNK__</code>.</p>
<section id="example" class="level5">
<h5 class="anchored" data-anchor-id="example">Example</h5>
<p>Input a tweet:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="ch">'@</span><span class="er">happypuppy, is Maria happy?</span><span class="ch">'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The tweet_to_tensor will first conver the tweet into a list of tokens (including only relevant words)</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="op">[</span><span class="ch">'m</span><span class="er">aria</span><span class="ch">'</span><span class="op">,</span> <span class="ch">'h</span><span class="er">appi</span><span class="ch">'</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then it will convert each word into its unique integer</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="op">[</span><span class="dv">2</span><span class="op">,</span> <span class="dv">56</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Notice that the word “maria” is not in the vocabulary, so it is assigned the unique integer associated with the <code>__UNK__</code> token, because it is considered “unknown.”</li>
</ul>
</section>
<section id="ex01" class="level3">
<h3 class="anchored" data-anchor-id="ex01">Exercise 01</h3>
<p><strong>Instructions:</strong> Write a program <code>tweet_to_tensor</code> that takes in a tweet and converts it to an array of numbers. You can use the <code>Vocab</code> dictionary you just found to help create the tensor.</p>
<ul>
<li>Use the vocab_dict parameter and not a global variable.</li>
<li>Do not hard code the integer value for the <code>__UNK__</code> token.</li>
</ul>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
</p><ul>
<li>
Map each word in tweet to corresponding token in ‘Vocab’
</li>
<li>
Use Python’s Dictionary.get(key,value) so that the function returns a default value if the key is not found in the dictionary.
</li>
</ul>
<p></p>
</details>
<div id="cf37da83" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: tweet_to_tensor</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tweet_to_tensor(tweet, vocab_dict, unk_token<span class="op">=</span><span class="st">'__UNK__'</span>, verbose<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: </span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co">        tweet - A string containing a tweet</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co">        vocab_dict - The words dictionary</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">        unk_token - The special string for unknown tokens</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">        verbose - Print info durign runtime</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Output:</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co">        tensor_l - A python list with</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span>  </span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process the tweet into a list of words</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># where only important words are kept (stop words removed)</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    word_l <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"List of words from the processed tweet:"</span>)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(word_l)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize the list that will contain the unique integer IDs of each word</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>    tensor_l <span class="op">=</span> []</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the unique integer ID of the __UNK__ token</span></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>    unk_ID <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> verbose:</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"The unique integer ID for the unk_token is </span><span class="sc">{</span>unk_ID<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># for each word in the list:</span></span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word <span class="kw">in</span> word_l:</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the unique integer ID.</span></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the word doesn't exist in the vocab dictionary,</span></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># use the unique ID for __UNK__ instead.</span></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>        word_ID <span class="op">=</span> <span class="va">None</span></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>    <span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append the unique integer ID to the tensor list.</span></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>        tensor_l.append(word_ID) </span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tensor_l</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0f032de0" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Actual tweet is</span><span class="ch">\n</span><span class="st">"</span>, val_pos[<span class="dv">0</span>])</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Tensor of tweet:</span><span class="ch">\n</span><span class="st">"</span>, tweet_to_tensor(val_pos[<span class="dv">0</span>], vocab_dict<span class="op">=</span>Vocab))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Actual tweet is
 Bro:U wan cut hair anot,ur hair long Liao bo
Me:since ord liao,take it easy lor treat as save $ leave it longer :)
Bro:LOL Sibei xialan</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TypeError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[11], line 2</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">Actual tweet is</span><span style="font-weight:bold;color:rgb(175,95,0)">\n</span><span style="color:rgb(175,0,0)">"</span>, val_pos[<span style="color:rgb(98,98,98)">0</span>])
<span class="ansi-green-fg">----&gt; 2</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">"</span><span style="font-weight:bold;color:rgb(175,95,0)">\n</span><span style="color:rgb(175,0,0)">Tensor of tweet:</span><span style="font-weight:bold;color:rgb(175,95,0)">\n</span><span style="color:rgb(175,0,0)">"</span>, <span class="ansi-yellow-bg">tweet_to_tensor</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">val_pos</span><span class="ansi-yellow-bg">[</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">0</span><span class="ansi-yellow-bg">]</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">vocab_dict</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">Vocab</span><span class="ansi-yellow-bg">)</span>)

Cell <span class="ansi-green-fg">In[10], line 34</span>, in <span class="ansi-cyan-fg">tweet_to_tensor</span><span class="ansi-blue-fg">(tweet, vocab_dict, unk_token, verbose)</span>
<span class="ansi-green-fg ansi-bold">     31</span>     <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">The unique integer ID for the unk_token is </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>unk_ID<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">"</span>)
<span class="ansi-green-fg ansi-bold">     33</span> <span style="font-style:italic;color:rgb(95,135,135)"># for each word in the list:</span>
<span class="ansi-green-fg">---&gt; 34</span> <span style="font-weight:bold;color:rgb(0,135,0)">for</span> word <span style="font-weight:bold;color:rgb(175,0,255)">in</span> word_l:
<span class="ansi-green-fg ansi-bold">     35</span>     
<span class="ansi-green-fg ansi-bold">     36</span>     <span style="font-style:italic;color:rgb(95,135,135)"># Get the unique integer ID.</span>
<span class="ansi-green-fg ansi-bold">     37</span>     <span style="font-style:italic;color:rgb(95,135,135)"># If the word doesn't exist in the vocab dictionary,</span>
<span class="ansi-green-fg ansi-bold">     38</span>     <span style="font-style:italic;color:rgb(95,135,135)"># use the unique ID for __UNK__ instead.</span>
<span class="ansi-green-fg ansi-bold">     39</span>     word_ID <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span>
<span class="ansi-green-fg ansi-bold">     40</span> <span style="font-style:italic;color:rgb(95,135,135)">### END CODE HERE ###</span>
<span class="ansi-green-fg ansi-bold">     41</span>     
<span class="ansi-green-fg ansi-bold">     42</span>     <span style="font-style:italic;color:rgb(95,135,135)"># Append the unique integer ID to the tensor list.</span>

<span class="ansi-red-fg">TypeError</span>: 'NoneType' object is not iterable</pre>
</div>
</div>
</div>
<section id="expected-output" class="level5">
<h5 class="anchored" data-anchor-id="expected-output">Expected output</h5>
<div class="sourceCode" id="cb28"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>Actual tweet is</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a> Bro<span class="op">:</span>U wan cut hair anot<span class="op">,</span>ur hair <span class="dt">long</span> Liao bo</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>Me<span class="op">:</span>since ord liao<span class="op">,</span>take it easy lor treat as save <span class="er">$</span> leave it longer <span class="op">:)</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>Bro<span class="op">:</span>LOL Sibei xialan</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>Tensor of tweet<span class="op">:</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a> <span class="op">[</span><span class="dv">1065</span><span class="op">,</span> <span class="dv">136</span><span class="op">,</span> <span class="dv">479</span><span class="op">,</span> <span class="dv">2351</span><span class="op">,</span> <span class="dv">745</span><span class="op">,</span> <span class="dv">8148</span><span class="op">,</span> <span class="dv">1123</span><span class="op">,</span> <span class="dv">745</span><span class="op">,</span> <span class="dv">53</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">2672</span><span class="op">,</span> <span class="dv">791</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">349</span><span class="op">,</span> <span class="dv">601</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3489</span><span class="op">,</span> <span class="dv">1017</span><span class="op">,</span> <span class="dv">597</span><span class="op">,</span> <span class="dv">4559</span><span class="op">,</span> <span class="dv">9</span><span class="op">,</span> <span class="dv">1065</span><span class="op">,</span> <span class="dv">157</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">2</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="2d3ae940" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># test tweet_to_tensor</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_tweet_to_tensor():</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    test_cases <span class="op">=</span> [</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"name"</span>:<span class="st">"simple_test_check"</span>,</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"input"</span>: [val_pos[<span class="dv">1</span>], Vocab],</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">"expected"</span>:[<span class="dv">444</span>, <span class="dv">2</span>, <span class="dv">304</span>, <span class="dv">567</span>, <span class="dv">56</span>, <span class="dv">9</span>],</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">"error"</span>:<span class="st">"The function gives bad output for val_pos[1]. Test failed"</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">"name"</span>:<span class="st">"datatype_check"</span>,</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">"input"</span>:[val_pos[<span class="dv">1</span>], Vocab],</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">"expected"</span>:<span class="bu">type</span>([]),</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">"error"</span>:<span class="st">"Datatype mismatch. Need only list not np.array"</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">"name"</span>:<span class="st">"without_unk_check"</span>,</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">"input"</span>:[val_pos[<span class="dv">1</span>], Vocab],</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">"expected"</span>:<span class="dv">6</span>,</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>            <span class="st">"error"</span>:<span class="st">"Unk word check not done- Please check if you included mapping for unknown word"</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>    count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> test_case <span class="kw">in</span> test_cases:</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> test_case[<span class="st">'name'</span>] <span class="op">==</span> <span class="st">"simple_test_check"</span>:</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>                <span class="cf">assert</span> test_case[<span class="st">"expected"</span>] <span class="op">==</span> tweet_to_tensor(<span class="op">*</span>test_case[<span class="st">'input'</span>])</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>                count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> test_case[<span class="st">'name'</span>] <span class="op">==</span> <span class="st">"datatype_check"</span>:</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>                <span class="cf">assert</span> <span class="bu">isinstance</span>(tweet_to_tensor(<span class="op">*</span>test_case[<span class="st">'input'</span>]), test_case[<span class="st">"expected"</span>])</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>                count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> test_case[<span class="st">'name'</span>] <span class="op">==</span> <span class="st">"without_unk_check"</span>:</span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>                <span class="cf">assert</span> <span class="va">None</span> <span class="kw">not</span> <span class="kw">in</span> tweet_to_tensor(<span class="op">*</span>test_case[<span class="st">'input'</span>])</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>                count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span>:</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(test_case[<span class="st">'error'</span>])</span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> count <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\033</span><span class="st">[92m All tests passed"</span>)</span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(count,<span class="st">" Tests passed out of 3"</span>)</span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a>test_tweet_to_tensor()            </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The function gives bad output for val_pos[1]. Test failed
Datatype mismatch. Need only list not np.array
Unk word check not done- Please check if you included mapping for unknown word
0  Tests passed out of 3</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="2.4" class="level2">
<h2 class="anchored" data-anchor-id="2.4">2.4 Creating a batch generator</h2>
<p>Most of the time in Natural Language Processing, and AI in general we use batches when training our data sets. - If instead of training with batches of examples, you were to train a model with one example at a time, it would take a very long time to train the model. - You will now build a data generator that takes in the positive/negative tweets and returns a batch of training examples. It returns the model inputs, the targets (positive or negative labels) and the weight for each target (ex: this allows us to can treat some examples as more important to get right than others, but commonly this will all be 1.0).</p>
<p>Once you create the generator, you could include it in a for loop</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_inputs<span class="op">,</span> batch_targets<span class="op">,</span> batch_example_weights in data_generator<span class="op">:</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">...</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can also get a single batch like this:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>batch_inputs<span class="op">,</span> batch_targets<span class="op">,</span> batch_example_weights <span class="op">=</span> next<span class="op">(</span>data_generator<span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The generator returns the next batch each time it’s called. - This generator returns the data in a format (tensors) that you could directly use in your model. - It returns a triple: the inputs, targets, and loss weights: – Inputs is a tensor that contains the batch of tweets we put into the model. – Targets is the corresponding batch of labels that we train to generate. – Loss weights here are just 1s with same shape as targets. Next week, you will use it to mask input padding.</p>
<section id="ex02" class="level3">
<h3 class="anchored" data-anchor-id="ex02">Exercise 02</h3>
<p>Implement <code>data_generator</code>.</p>
<div id="fef81cc4" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED: Data generator</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> data_generator(data_pos, data_neg, batch_size, loop, vocab_dict, shuffle<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: </span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co">        data_pos - Set of posstive examples</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co">        data_neg - Set of negative examples</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co">        batch_size - number of samples per batch. Must be even</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co">        loop - True or False</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co">        vocab_dict - The words dictionary</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co">        shuffle - Shuffle the data order</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Yield:</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co">        inputs - Subset of positive and negative examples</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co">        targets - The corresponding labels for the subset</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="co">        example_weights - An array specifying the importance of each example</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span>     </span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="co">### START GIVEN CODE </span><span class="al">###</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># make sure the batch size is an even number</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to allow an equal number of positive and negative samples</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> batch_size <span class="op">%</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Number of positive examples in each batch is half of the batch size</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># same with number of negative examples in each batch</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    n_to_take <span class="op">=</span> batch_size <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use pos_index to walk through the data_pos array</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># same with neg_index and data_neg</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>    pos_index <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    neg_index <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    len_data_pos <span class="op">=</span> <span class="bu">len</span>(data_pos)</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>    len_data_neg <span class="op">=</span> <span class="bu">len</span>(data_neg)</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get and array with the data indexes</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>    pos_index_lines <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(len_data_pos))</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>    neg_index_lines <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(len_data_neg))</span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># shuffle lines if shuffle is set to True</span></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> shuffle:</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a>        rnd.shuffle(pos_index_lines)</span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a>        rnd.shuffle(neg_index_lines)</span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a>    stop <span class="op">=</span> <span class="va">False</span></span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loop indefinitely</span></span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> stop:  </span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># create a batch with positive and negative examples</span></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> []</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># First part: Pack n_to_take positive examples</span></span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Start from pos_index and increment i up to n_to_take</span></span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_to_take):</span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the positive index goes past the positive dataset lenght,</span></span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> pos_index <span class="op">&gt;=</span> len_data_pos: </span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If loop is set to False, break once we reach the end of the dataset</span></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="kw">not</span> loop:</span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a>                    stop <span class="op">=</span> <span class="va">True</span><span class="op">;</span></span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span><span class="op">;</span></span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If user wants to keep re-using the data, reset the index</span></span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a>                pos_index <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> shuffle:</span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Shuffle the index of the positive sample</span></span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a>                    rnd.shuffle(pos_index_lines)</span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb33-72"><a href="#cb33-72" aria-hidden="true" tabindex="-1"></a>            <span class="co"># get the tweet as pos_index</span></span>
<span id="cb33-73"><a href="#cb33-73" aria-hidden="true" tabindex="-1"></a>            tweet <span class="op">=</span> data_pos[pos_index_lines[pos_index]]</span>
<span id="cb33-74"><a href="#cb33-74" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-75"><a href="#cb33-75" aria-hidden="true" tabindex="-1"></a>            <span class="co"># convert the tweet into tensors of integers representing the processed words</span></span>
<span id="cb33-76"><a href="#cb33-76" aria-hidden="true" tabindex="-1"></a>            tensor <span class="op">=</span> tweet_to_tensor(tweet, vocab_dict)</span>
<span id="cb33-77"><a href="#cb33-77" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-78"><a href="#cb33-78" aria-hidden="true" tabindex="-1"></a>            <span class="co"># append the tensor to the batch list</span></span>
<span id="cb33-79"><a href="#cb33-79" aria-hidden="true" tabindex="-1"></a>            batch.append(tensor)</span>
<span id="cb33-80"><a href="#cb33-80" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-81"><a href="#cb33-81" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Increment pos_index by one</span></span>
<span id="cb33-82"><a href="#cb33-82" aria-hidden="true" tabindex="-1"></a>            pos_index <span class="op">=</span> pos_index <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb33-83"><a href="#cb33-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-84"><a href="#cb33-84" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="re">END</span><span class="co"> GIVEN CODE </span><span class="al">###</span></span>
<span id="cb33-85"><a href="#cb33-85" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-86"><a href="#cb33-86" aria-hidden="true" tabindex="-1"></a><span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb33-87"><a href="#cb33-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-88"><a href="#cb33-88" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Second part: Pack n_to_take negative examples</span></span>
<span id="cb33-89"><a href="#cb33-89" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-90"><a href="#cb33-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Using the same batch list, start from neg_index and increment i up to n_to_take</span></span>
<span id="cb33-91"><a href="#cb33-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">None</span>):</span>
<span id="cb33-92"><a href="#cb33-92" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-93"><a href="#cb33-93" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If the negative index goes past the negative dataset length,</span></span>
<span id="cb33-94"><a href="#cb33-94" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">None</span></span>
<span id="cb33-95"><a href="#cb33-95" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb33-96"><a href="#cb33-96" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If loop is set to False, break once we reach the end of the dataset</span></span>
<span id="cb33-97"><a href="#cb33-97" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="kw">not</span> loop:</span>
<span id="cb33-98"><a href="#cb33-98" aria-hidden="true" tabindex="-1"></a>                    stop <span class="op">=</span> <span class="va">True</span><span class="op">;</span></span>
<span id="cb33-99"><a href="#cb33-99" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span><span class="op">;</span></span>
<span id="cb33-100"><a href="#cb33-100" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb33-101"><a href="#cb33-101" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If user wants to keep re-using the data, reset the index</span></span>
<span id="cb33-102"><a href="#cb33-102" aria-hidden="true" tabindex="-1"></a>                neg_index <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-103"><a href="#cb33-103" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb33-104"><a href="#cb33-104" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> shuffle:</span>
<span id="cb33-105"><a href="#cb33-105" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Shuffle the index of the negative sample</span></span>
<span id="cb33-106"><a href="#cb33-106" aria-hidden="true" tabindex="-1"></a>                    <span class="va">None</span></span>
<span id="cb33-107"><a href="#cb33-107" aria-hidden="true" tabindex="-1"></a>            <span class="co"># get the tweet as neg_index</span></span>
<span id="cb33-108"><a href="#cb33-108" aria-hidden="true" tabindex="-1"></a>            tweet <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-109"><a href="#cb33-109" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-110"><a href="#cb33-110" aria-hidden="true" tabindex="-1"></a>            <span class="co"># convert the tweet into tensors of integers representing the processed words</span></span>
<span id="cb33-111"><a href="#cb33-111" aria-hidden="true" tabindex="-1"></a>            tensor <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-112"><a href="#cb33-112" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-113"><a href="#cb33-113" aria-hidden="true" tabindex="-1"></a>            <span class="co"># append the tensor to the batch list</span></span>
<span id="cb33-114"><a href="#cb33-114" aria-hidden="true" tabindex="-1"></a>            <span class="va">None</span></span>
<span id="cb33-115"><a href="#cb33-115" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-116"><a href="#cb33-116" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Increment neg_index by one</span></span>
<span id="cb33-117"><a href="#cb33-117" aria-hidden="true" tabindex="-1"></a>            neg_index <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-118"><a href="#cb33-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-119"><a href="#cb33-119" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span><span class="co">        </span></span>
<span id="cb33-120"><a href="#cb33-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-121"><a href="#cb33-121" aria-hidden="true" tabindex="-1"></a><span class="co">### START GIVEN CODE </span><span class="al">###</span></span>
<span id="cb33-122"><a href="#cb33-122" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> stop:</span>
<span id="cb33-123"><a href="#cb33-123" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span><span class="op">;</span></span>
<span id="cb33-124"><a href="#cb33-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-125"><a href="#cb33-125" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update the start index for positive data </span></span>
<span id="cb33-126"><a href="#cb33-126" aria-hidden="true" tabindex="-1"></a>        <span class="co"># so that it's n_to_take positions after the current pos_index</span></span>
<span id="cb33-127"><a href="#cb33-127" aria-hidden="true" tabindex="-1"></a>        pos_index <span class="op">+=</span> n_to_take</span>
<span id="cb33-128"><a href="#cb33-128" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-129"><a href="#cb33-129" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update the start index for negative data </span></span>
<span id="cb33-130"><a href="#cb33-130" aria-hidden="true" tabindex="-1"></a>        <span class="co"># so that it's n_to_take positions after the current neg_index</span></span>
<span id="cb33-131"><a href="#cb33-131" aria-hidden="true" tabindex="-1"></a>        neg_index <span class="op">+=</span> n_to_take</span>
<span id="cb33-132"><a href="#cb33-132" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-133"><a href="#cb33-133" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the max tweet length (the length of the longest tweet) </span></span>
<span id="cb33-134"><a href="#cb33-134" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (you will pad all shorter tweets to have this length)</span></span>
<span id="cb33-135"><a href="#cb33-135" aria-hidden="true" tabindex="-1"></a>        max_len <span class="op">=</span> <span class="bu">max</span>([<span class="bu">len</span>(t) <span class="cf">for</span> t <span class="kw">in</span> batch]) </span>
<span id="cb33-136"><a href="#cb33-136" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-137"><a href="#cb33-137" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-138"><a href="#cb33-138" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize the input_l, which will </span></span>
<span id="cb33-139"><a href="#cb33-139" aria-hidden="true" tabindex="-1"></a>        <span class="co"># store the padded versions of the tensors</span></span>
<span id="cb33-140"><a href="#cb33-140" aria-hidden="true" tabindex="-1"></a>        tensor_pad_l <span class="op">=</span> []</span>
<span id="cb33-141"><a href="#cb33-141" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pad shorter tweets with zeros</span></span>
<span id="cb33-142"><a href="#cb33-142" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> tensor <span class="kw">in</span> batch:</span>
<span id="cb33-143"><a href="#cb33-143" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="re">END</span><span class="co"> GIVEN CODE </span><span class="al">###</span></span>
<span id="cb33-144"><a href="#cb33-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-145"><a href="#cb33-145" aria-hidden="true" tabindex="-1"></a><span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb33-146"><a href="#cb33-146" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get the number of positions to pad for this tensor so that it will be max_len long</span></span>
<span id="cb33-147"><a href="#cb33-147" aria-hidden="true" tabindex="-1"></a>            n_pad <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-148"><a href="#cb33-148" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-149"><a href="#cb33-149" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Generate a list of zeros, with length n_pad</span></span>
<span id="cb33-150"><a href="#cb33-150" aria-hidden="true" tabindex="-1"></a>            pad_l <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-151"><a href="#cb33-151" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-152"><a href="#cb33-152" aria-hidden="true" tabindex="-1"></a>            <span class="co"># concatenate the tensor and the list of padded zeros</span></span>
<span id="cb33-153"><a href="#cb33-153" aria-hidden="true" tabindex="-1"></a>            tensor_pad <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-154"><a href="#cb33-154" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb33-155"><a href="#cb33-155" aria-hidden="true" tabindex="-1"></a>            <span class="co"># append the padded tensor to the list of padded tensors</span></span>
<span id="cb33-156"><a href="#cb33-156" aria-hidden="true" tabindex="-1"></a>            <span class="va">None</span></span>
<span id="cb33-157"><a href="#cb33-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-158"><a href="#cb33-158" aria-hidden="true" tabindex="-1"></a>        <span class="co"># convert the list of padded tensors to a numpy array</span></span>
<span id="cb33-159"><a href="#cb33-159" aria-hidden="true" tabindex="-1"></a>        <span class="co"># and store this as the model inputs</span></span>
<span id="cb33-160"><a href="#cb33-160" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-161"><a href="#cb33-161" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb33-162"><a href="#cb33-162" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate the list of targets for the positive examples (a list of ones)</span></span>
<span id="cb33-163"><a href="#cb33-163" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The length is the number of positive examples in the batch</span></span>
<span id="cb33-164"><a href="#cb33-164" aria-hidden="true" tabindex="-1"></a>        target_pos <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-165"><a href="#cb33-165" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-166"><a href="#cb33-166" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate the list of targets for the negative examples (a list of zeros)</span></span>
<span id="cb33-167"><a href="#cb33-167" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The length is the number of negative examples in the batch</span></span>
<span id="cb33-168"><a href="#cb33-168" aria-hidden="true" tabindex="-1"></a>        target_neg <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-169"><a href="#cb33-169" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-170"><a href="#cb33-170" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Concatenate the positve and negative targets</span></span>
<span id="cb33-171"><a href="#cb33-171" aria-hidden="true" tabindex="-1"></a>        target_l <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-172"><a href="#cb33-172" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-173"><a href="#cb33-173" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert the target list into a numpy array</span></span>
<span id="cb33-174"><a href="#cb33-174" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-175"><a href="#cb33-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-176"><a href="#cb33-176" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Example weights: Treat all examples equally importantly.It should return an np.array. Hint: Use np.ones_like()</span></span>
<span id="cb33-177"><a href="#cb33-177" aria-hidden="true" tabindex="-1"></a>        example_weights <span class="op">=</span> <span class="va">None</span></span>
<span id="cb33-178"><a href="#cb33-178" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb33-179"><a href="#cb33-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-180"><a href="#cb33-180" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb33-181"><a href="#cb33-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-182"><a href="#cb33-182" aria-hidden="true" tabindex="-1"></a><span class="co">### GIVEN CODE </span><span class="al">###</span></span>
<span id="cb33-183"><a href="#cb33-183" aria-hidden="true" tabindex="-1"></a>        <span class="co"># note we use yield and not return</span></span>
<span id="cb33-184"><a href="#cb33-184" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> inputs, targets, example_weights</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-cyan-fg">  Cell </span><span class="ansi-green-fg">In[13], line 94</span>
<span class="ansi-red-fg">    if None</span>
           ^
<span class="ansi-red-fg">SyntaxError</span><span class="ansi-red-fg">:</span> expected ':'
</pre>
</div>
</div>
</div>
<p>Now you can use your data generator to create a data generator for the training data, and another data generator for the validation data.</p>
<p>We will create a third data generator that does not loop, for testing the final accuracy of the model.</p>
<div id="0fd8ed21" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the random number generator for the shuffle procedure</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>rnd.seed(<span class="dv">30</span>) </span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the training data generator</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_generator(batch_size, shuffle <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_generator(train_pos, train_neg, batch_size, <span class="va">True</span>, Vocab, shuffle)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the validation data generator</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> val_generator(batch_size, shuffle <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_generator(val_pos, val_neg, batch_size, <span class="va">True</span>, Vocab, shuffle)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the validation data generator</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_generator(batch_size, shuffle <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data_generator(val_pos, val_neg, batch_size, <span class="va">False</span>, Vocab, shuffle)</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a batch from the train_generator and inspect.</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>inputs, targets, example_weights <span class="op">=</span> <span class="bu">next</span>(train_generator(<span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="co"># this will print a list of 4 tensors padded with zeros</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Inputs: </span><span class="sc">{</span>inputs<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Targets: </span><span class="sc">{</span>targets<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Example Weights: </span><span class="sc">{</span>example_weights<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[14], line 17</span>
<span class="ansi-green-fg ansi-bold">     14</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> data_generator(val_pos, val_neg, batch_size, <span style="font-weight:bold;color:rgb(0,135,0)">False</span>, Vocab, shuffle)
<span class="ansi-green-fg ansi-bold">     16</span> <span style="font-style:italic;color:rgb(95,135,135)"># Get a batch from the train_generator and inspect.</span>
<span class="ansi-green-fg">---&gt; 17</span> inputs, targets, example_weights <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">next</span>(<span class="ansi-yellow-bg">train_generator</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">4</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">shuffle</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span style="font-weight:bold;color:rgb(0,135,0)" class="ansi-yellow-bg">True</span><span class="ansi-yellow-bg">)</span>)
<span class="ansi-green-fg ansi-bold">     19</span> <span style="font-style:italic;color:rgb(95,135,135)"># this will print a list of 4 tensors padded with zeros</span>
<span class="ansi-green-fg ansi-bold">     20</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">Inputs: </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>inputs<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">'</span>)

Cell <span class="ansi-green-fg">In[14], line 6</span>, in <span class="ansi-cyan-fg">train_generator</span><span class="ansi-blue-fg">(batch_size, shuffle)</span>
<span class="ansi-green-fg ansi-bold">      5</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span style="color:rgb(0,0,255)">train_generator</span>(batch_size, shuffle <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">False</span>):
<span class="ansi-green-fg">----&gt; 6</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">data_generator</span>(train_pos, train_neg, batch_size, <span style="font-weight:bold;color:rgb(0,135,0)">True</span>, Vocab, shuffle)

<span class="ansi-red-fg">NameError</span>: name 'data_generator' is not defined</pre>
</div>
</div>
</div>
<div id="ce4477da" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the train_generator</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data generator for training data,</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># which produces batches of size 4 (for tensors and their respective targets)</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>tmp_data_gen <span class="op">=</span> train_generator(batch_size <span class="op">=</span> <span class="dv">4</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the data generator to get one batch and its targets</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>tmp_inputs, tmp_targets, tmp_example_weights <span class="op">=</span> <span class="bu">next</span>(tmp_data_gen)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The inputs shape is </span><span class="sc">{</span>tmp_inputs<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The targets shape is </span><span class="sc">{</span>tmp_targets<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The example weights shape is </span><span class="sc">{</span>tmp_example_weights<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,t <span class="kw">in</span> <span class="bu">enumerate</span>(tmp_inputs):</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"input tensor: </span><span class="sc">{</span>t<span class="sc">}</span><span class="ss">; target </span><span class="sc">{</span>tmp_targets[i]<span class="sc">}</span><span class="ss">; example weights </span><span class="sc">{</span>tmp_example_weights[i]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[15], line 5</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># Test the train_generator</span>
<span class="ansi-green-fg ansi-bold">      2</span> 
<span class="ansi-green-fg ansi-bold">      3</span> <span style="font-style:italic;color:rgb(95,135,135)"># Create a data generator for training data,</span>
<span class="ansi-green-fg ansi-bold">      4</span> <span style="font-style:italic;color:rgb(95,135,135)"># which produces batches of size 4 (for tensors and their respective targets)</span>
<span class="ansi-green-fg">----&gt; 5</span> tmp_data_gen <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">train_generator</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">batch_size</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg"> </span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">4</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">      7</span> <span style="font-style:italic;color:rgb(95,135,135)"># Call the data generator to get one batch and its targets</span>
<span class="ansi-green-fg ansi-bold">      8</span> tmp_inputs, tmp_targets, tmp_example_weights <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">next</span>(tmp_data_gen)

Cell <span class="ansi-green-fg">In[14], line 6</span>, in <span class="ansi-cyan-fg">train_generator</span><span class="ansi-blue-fg">(batch_size, shuffle)</span>
<span class="ansi-green-fg ansi-bold">      5</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span style="color:rgb(0,0,255)">train_generator</span>(batch_size, shuffle <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">False</span>):
<span class="ansi-green-fg">----&gt; 6</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">data_generator</span>(train_pos, train_neg, batch_size, <span style="font-weight:bold;color:rgb(0,135,0)">True</span>, Vocab, shuffle)

<span class="ansi-red-fg">NameError</span>: name 'data_generator' is not defined</pre>
</div>
</div>
</div>
<section id="expected-output-1" class="level5">
<h5 class="anchored" data-anchor-id="expected-output-1">Expected output</h5>
<div class="sourceCode" id="cb36"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>The inputs shape is <span class="op">(</span><span class="dv">4</span><span class="op">,</span> <span class="dv">14</span><span class="op">)</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>The targets shape is <span class="op">(</span><span class="dv">4</span><span class="op">,)</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>The example weights shape is <span class="op">(</span><span class="dv">4</span><span class="op">,)</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>input tensor<span class="op">:</span> <span class="op">[</span><span class="dv">3</span> <span class="dv">4</span> <span class="dv">5</span> <span class="dv">6</span> <span class="dv">7</span> <span class="dv">8</span> <span class="dv">9</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span><span class="op">];</span> target <span class="dv">1</span><span class="op">;</span> example weights <span class="dv">1</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>input tensor<span class="op">:</span> <span class="op">[</span><span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span>  <span class="dv">9</span> <span class="dv">21</span> <span class="dv">22</span><span class="op">];</span> target <span class="dv">1</span><span class="op">;</span> example weights <span class="dv">1</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>input tensor<span class="op">:</span> <span class="op">[</span><span class="dv">5738</span> <span class="dv">2901</span> <span class="dv">3761</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span><span class="op">];</span> target <span class="dv">0</span><span class="op">;</span> example weights <span class="dv">1</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>input tensor<span class="op">:</span> <span class="op">[</span> <span class="dv">858</span>  <span class="dv">256</span> <span class="dv">3652</span> <span class="dv">5739</span>  <span class="dv">307</span> <span class="dv">4458</span>  <span class="dv">567</span> <span class="dv">1230</span> <span class="dv">2767</span>  <span class="dv">328</span> <span class="dv">1202</span> <span class="dv">3761</span>    <span class="dv">0</span>    <span class="dv">0</span><span class="op">];</span> target <span class="dv">0</span><span class="op">;</span> example weights <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now that you have your train/val generators, you can just call them and they will return tensors which correspond to your tweets in the first column and their corresponding labels in the second column. Now you can go ahead and start building your neural network.</p>
</section>
</section>
</section>
</section>
<section id="3" class="level1">
<h1>Part 3: Defining classes</h1>
<p>In this part, you will write your own library of layers. It will be very similar to the one used in Trax and also in Keras and PyTorch. Writing your own small framework will help you understand how they all work and use them effectively in the future.</p>
<p>Your framework will be based on the following <code>Layer</code> class from utils.py.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Layer<span class="op">(</span>object<span class="op">):</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">""" Base class for layers.</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"""</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">Constructor</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    def __init__<span class="op">(</span>self<span class="op">):</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>        <span class="pp"># </span><span class="er">set weights to None</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>        self<span class="op">.</span>weights <span class="op">=</span> None</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">The forward propagation should be implemented</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">by subclasses of this Layer class</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    def forward<span class="op">(</span>self<span class="op">,</span> x<span class="op">):</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>        raise NotImplementedError</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">This function initializes the weights</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">based on the input signature and random key,</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">should be implemented by subclasses of this Layer class</span></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>    def init_weights_and_state<span class="op">(</span>self<span class="op">,</span> input_signature<span class="op">,</span> random_key<span class="op">):</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>        pass</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">This initializes and returns the weights, do not override.</span></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>    def init<span class="op">(</span>self<span class="op">,</span> input_signature<span class="op">,</span> random_key<span class="op">):</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>        self<span class="op">.</span>init_weights_and_state<span class="op">(</span>input_signature<span class="op">,</span> random_key<span class="op">)</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> self<span class="op">.</span>weights</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">__call__ allows an object of this class</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>    <span class="pp"># </span><span class="er">to be called like it's a function.</span></span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>    def __call__<span class="op">(</span>self<span class="op">,</span> x<span class="op">):</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>        <span class="pp"># </span><span class="er">When this layer object is called, </span></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>        <span class="pp"># </span><span class="er">it calls its forward propagation function</span></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> self<span class="op">.</span>forward<span class="op">(</span>x<span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="3.1" class="level2">
<h2 class="anchored" data-anchor-id="3.1">3.1 ReLU class</h2>
<p>You will now implement the ReLU activation function in a class below. The ReLU function looks as follows:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/relu.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="ReLU"><img src="img/relu.jpg" width="300" height="150" alt="ReLU" class="figure-img"></a></p>
<figcaption>ReLU</figcaption>
</figure>
</div>
<p><span class="math display">
\mathrm{ReLU}(x) = \mathrm{max}(0,x)
</span></p>
<section id="ex03" class="level3">
<h3 class="anchored" data-anchor-id="ex03">Exercise 03</h3>
<p><strong>Instructions:</strong> Implement the ReLU activation function below. Your function should take in a matrix or vector and it should transform all the negative numbers into 0 while keeping all the positive numbers intact.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
</p><ul>
<li>
Please use numpy.maximum(A,k) to find the maximum between each element in A and a scalar k
</li>
</ul>
<p></p>
</details>
<div id="6574f721" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: Relu</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Relu(Layer):</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Relu activation function implementation"""</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co">        Input: </span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co">            - x (a numpy array): the input</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Output:</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co">            - activation (numpy array): all positive or 0 version of x</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>        <span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>        activation <span class="op">=</span> <span class="va">None</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>        <span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> activation</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="bd34700c" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test your relu function</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.array([[<span class="op">-</span><span class="fl">2.0</span>, <span class="op">-</span><span class="fl">1.0</span>, <span class="fl">0.0</span>], [<span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">2.0</span>]], dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>relu_layer <span class="op">=</span> Relu()</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test data is:"</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Output of Relu is:"</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(relu_layer(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Test data is:
[[-2. -1.  0.]
 [ 0.  1.  2.]]
Output of Relu is:
None</code></pre>
</div>
</div>
<section id="expected-outout" class="level5">
<h5 class="anchored" data-anchor-id="expected-outout">Expected Outout</h5>
<div class="sourceCode" id="cb41"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>Test data is<span class="op">:</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="op">[[-</span><span class="dv">2</span><span class="er">.</span><span class="at"> </span><span class="op">-</span><span class="dv">1</span><span class="er">.</span><span class="at">  </span><span class="dv">0</span><span class="er">.</span><span class="op">]</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="at"> </span><span class="op">[</span><span class="at"> </span><span class="dv">0</span><span class="er">.</span><span class="at">  </span><span class="dv">1</span><span class="er">.</span><span class="at">  </span><span class="dv">2</span><span class="er">.</span><span class="op">]]</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>Output of Relu is<span class="op">:</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="op">[[</span><span class="dv">0</span><span class="er">.</span><span class="at"> </span><span class="dv">0</span><span class="er">.</span><span class="at"> </span><span class="dv">0</span><span class="er">.</span><span class="op">]</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="at"> </span><span class="op">[</span><span class="dv">0</span><span class="er">.</span><span class="at"> </span><span class="dv">1</span><span class="er">.</span><span class="at"> </span><span class="dv">2</span><span class="er">.</span><span class="op">]]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="3.2" class="level2">
<h2 class="anchored" data-anchor-id="3.2">3.2 Dense class</h2>
<section id="exercise" class="level3">
<h3 class="anchored" data-anchor-id="exercise">Exercise</h3>
<p>Implement the forward function of the Dense class. - The forward function multiplies the input to the layer (<code>x</code>) by the weight matrix (<code>W</code>)</p>
<p><span class="math display">\mathrm{forward}(\mathbf{x},\mathbf{W}) = \mathbf{xW} </span></p>
<ul>
<li>You can use <code>numpy.dot</code> to perform the matrix multiplication.</li>
</ul>
<p>Note that for more efficient code execution, you will use the trax version of <code>math</code>, which includes a trax version of <code>numpy</code> and also <code>random</code>.</p>
<p>Implement the weight initializer <code>new_weights</code> function - Weights are initialized with a random key. - The second parameter is a tuple for the desired shape of the weights (num_rows, num_cols) - The num of rows for weights should equal the number of columns in x, because for forward propagation, you will multiply x times weights.</p>
<p>Please use <code>trax.fastmath.random.normal(key, shape, dtype=tf.float32)</code> to generate random values for the weight matrix. The key difference between this function and the standard <code>numpy</code> randomness is the explicit use of random keys, which need to be passed. While it can look tedious at the first sight to pass the random key everywhere, you will learn in Course 4 why this is very helpful when implementing some advanced models. - <code>key</code> can be generated by calling <code>random.get_prng(seed=)</code> and passing in a number for the <code>seed</code>. - <code>shape</code> is a tuple with the desired shape of the weight matrix. - The number of rows in the weight matrix should equal the number of columns in the variable <code>x</code>. Since <code>x</code> may have 2 dimensions if it reprsents a single training example (row, col), or three dimensions (batch_size, row, col), get the last dimension from the tuple that holds the dimensions of x. - The number of columns in the weight matrix is the number of units chosen for that dense layer. Look at the <code>__init__</code> function to see which variable stores the number of units. - <code>dtype</code> is the data type of the values in the generated matrix; keep the default of <code>tf.float32</code>. In this case, don’t explicitly set the dtype (just let it use the default value).</p>
<p>Set the standard deviation of the random values to 0.1 - The values generated have a mean of 0 and standard deviation of 1. - Set the default standard deviation <code>stdev</code> to be 0.1 by multiplying the standard deviation to each of the values in the weight matrix.</p>
<div id="975354c6" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use the fastmath module within trax</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trax <span class="im">import</span> fastmath</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co"># use the numpy module from trax</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>np <span class="op">=</span> fastmath.numpy</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="co"># use the fastmath.random module from trax</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>random <span class="op">=</span> fastmath.random</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c64dbd12" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># See how the fastmath.trax.random.normal function works</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>tmp_key <span class="op">=</span> random.get_prng(seed<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The random seed generated by random.get_prng"</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>display(tmp_key)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"choose a matrix with 2 rows and 3 columns"</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>tmp_shape<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>display(tmp_shape)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a weight matrix</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that you'll get an error if you try to set dtype to tf.float32, where tf is tensorflow</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Just avoid setting the dtype and allow it to use the default data type</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>tmp_weight <span class="op">=</span> trax.fastmath.random.normal(key<span class="op">=</span>tmp_key, shape<span class="op">=</span>tmp_shape)</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Weight matrix generated with a normal distribution with mean 0 and stdev of 1"</span>)</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>display(tmp_weight)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The random seed generated by random.get_prng</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>Array([0, 1], dtype=uint32)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>choose a matrix with 2 rows and 3 columns</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>(2, 3)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Weight matrix generated with a normal distribution with mean 0 and stdev of 1</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>Array([[-0.15443718,  0.08470728, -0.13598049],
       [-0.15503626,  1.2666672 ,  0.14829758]], dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="ex04" class="level3">
<h3 class="anchored" data-anchor-id="ex04">Exercise 04</h3>
<p>Implement the <code>Dense</code> class.</p>
<div id="7b7a221e" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: Dense</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Dense(Layer):</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co">    A dense (fully-connected) layer.</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># __init__ is implemented for you</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_units, init_stdev<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set the number of units in this layer</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._n_units <span class="op">=</span> n_units</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._init_stdev <span class="op">=</span> init_stdev</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Please implement 'forward()'</span></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a><span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Matrix multiply x and the weight matrix</span></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>        dense <span class="op">=</span> <span class="va">None</span> </span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> dense</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># init_weights</span></span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> init_weights_and_state(<span class="va">self</span>, input_signature, random_key):</span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a><span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The input_signature has a .shape attribute that gives the shape as a tuple</span></span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a>        input_shape <span class="op">=</span> <span class="va">None</span></span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-34"><a href="#cb50-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate the weight matrix from a normal distribution, </span></span>
<span id="cb50-35"><a href="#cb50-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># and standard deviation of 'stdev'        </span></span>
<span id="cb50-36"><a href="#cb50-36" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> <span class="va">None</span></span>
<span id="cb50-37"><a href="#cb50-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb50-38"><a href="#cb50-38" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span><span class="co">     </span></span>
<span id="cb50-39"><a href="#cb50-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights <span class="op">=</span> w</span>
<span id="cb50-40"><a href="#cb50-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.weights</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c5058f2b" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing your Dense layer </span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>dense_layer <span class="op">=</span> Dense(n_units<span class="op">=</span><span class="dv">10</span>)  <span class="co">#sets  number of units in dense layer</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>random_key <span class="op">=</span> random.get_prng(seed<span class="op">=</span><span class="dv">0</span>)  <span class="co"># sets random seed</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.array([[<span class="fl">2.0</span>, <span class="fl">7.0</span>, <span class="fl">25.0</span>]]) <span class="co"># input array </span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>dense_layer.init(z, random_key)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Weights are</span><span class="ch">\n</span><span class="st"> "</span>,dense_layer.weights) <span class="co">#Returns randomly generated weights</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Foward function output is "</span>, dense_layer(z)) <span class="co"># Returns multiplied values of units and weights</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Weights are
  None
Foward function output is  None</code></pre>
</div>
</div>
<section id="expected-outout-1" class="level5">
<h5 class="anchored" data-anchor-id="expected-outout-1">Expected Outout</h5>
<div class="sourceCode" id="cb53"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>Weights are</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>  <span class="op">[[-</span><span class="dv">0</span><span class="er">.02837108</span><span class="at">  </span><span class="dv">0</span><span class="er">.09368162</span><span class="at"> </span><span class="op">-</span><span class="dv">0</span><span class="er">.10050076</span><span class="at">  </span><span class="dv">0</span><span class="er">.14165013</span><span class="at">  </span><span class="dv">0</span><span class="er">.10543301</span><span class="at">  </span><span class="dv">0</span><span class="er">.09108126</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="op">-</span><span class="dv">0</span><span class="er">.04265672</span><span class="at">  </span><span class="dv">0</span><span class="er">.0986188</span><span class="at">  </span><span class="op">-</span><span class="dv">0</span><span class="er">.05575325</span><span class="at">  </span><span class="dv">0</span><span class="er">.00153249</span><span class="op">]</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="at"> </span><span class="op">[-</span><span class="dv">0</span><span class="er">.20785688</span><span class="at">  </span><span class="dv">0</span><span class="er">.0554837</span><span class="at">   </span><span class="dv">0</span><span class="er">.09142365</span><span class="at">  </span><span class="dv">0</span><span class="er">.05744595</span><span class="at">  </span><span class="dv">0</span><span class="er">.07227863</span><span class="at">  </span><span class="dv">0</span><span class="er">.01210617</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="op">-</span><span class="dv">0</span><span class="er">.03237354</span><span class="at">  </span><span class="dv">0</span><span class="er">.16234995</span><span class="at">  </span><span class="dv">0</span><span class="er">.02450038</span><span class="at"> </span><span class="op">-</span><span class="dv">0</span><span class="er">.13809784</span><span class="op">]</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="at"> </span><span class="op">[-</span><span class="dv">0</span><span class="er">.06111237</span><span class="at">  </span><span class="dv">0</span><span class="er">.01403724</span><span class="at">  </span><span class="dv">0</span><span class="er">.08410042</span><span class="at"> </span><span class="op">-</span><span class="dv">0</span><span class="er">.1094358</span><span class="at">  </span><span class="op">-</span><span class="dv">0</span><span class="er">.10775021</span><span class="at"> </span><span class="op">-</span><span class="dv">0</span><span class="er">.11396459</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="op">-</span><span class="dv">0</span><span class="er">.05933381</span><span class="at"> </span><span class="op">-</span><span class="dv">0</span><span class="er">.01557652</span><span class="at"> </span><span class="op">-</span><span class="dv">0</span><span class="er">.03832145</span><span class="at"> </span><span class="op">-</span><span class="dv">0</span><span class="er">.11144515</span><span class="op">]]</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>Foward function output is  <span class="op">[[-</span><span class="dv">3</span><span class="er">.0395496</span><span class="at">   </span><span class="dv">0</span><span class="er">.9266802</span><span class="at">   </span><span class="dv">2</span><span class="er">.5414743</span><span class="at">  </span><span class="op">-</span><span class="dv">2</span><span class="er">.050473</span><span class="at">   </span><span class="op">-</span><span class="dv">1</span><span class="er">.9769388</span><span class="at">  </span><span class="op">-</span><span class="dv">2</span><span class="er">.582209</span></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="at">  </span><span class="op">-</span><span class="dv">1</span><span class="er">.7952735</span><span class="at">   </span><span class="dv">0</span><span class="er">.94427425</span><span class="at"> </span><span class="op">-</span><span class="dv">0</span><span class="er">.8980402</span><span class="at">  </span><span class="op">-</span><span class="dv">3</span><span class="er">.7497487</span><span class="at"> </span><span class="op">]]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="3.3" class="level2">
<h2 class="anchored" data-anchor-id="3.3">3.3 Model</h2>
<p>Now you will implement a classifier using neural networks. Here is the model architecture you will be implementing.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/nn.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="NN"><img src="img/nn.jpg" width="400" height="250" alt="NN" class="figure-img"></a></p>
<figcaption>NN</figcaption>
</figure>
</div>
<p>For the model implementation, you will use the Trax layers library <code>tl</code>. Note that the second character of <code>tl</code> is the lowercase of letter <code>L</code>, not the number 1. Trax layers are very similar to the ones you implemented above, but in addition to trainable weights also have a non-trainable state. State is used in layers like batch normalization and for inference, you will learn more about it in course 4.</p>
<p>First, look at the code of the Trax Dense layer and compare to your implementation above. - <a href="https://github.com/google/trax/blob/master/trax/layers/core.py#L29">tl.Dense</a>: Trax Dense layer implementation</p>
<p>One other important layer that you will use a lot is one that allows to execute one layer after another in sequence. - <a href="https://github.com/google/trax/blob/master/trax/layers/combinators.py#L26">tl.Serial</a>: Combinator that applies layers serially.<br>
- You can pass in the layers as arguments to <code>Serial</code>, separated by commas. - For example: <code>tl.Serial(tl.Embeddings(...), tl.Mean(...), tl.Dense(...), tl.LogSoftmax(...))</code></p>
<p>Please use the <code>help</code> function to view documentation for each layer.</p>
<div id="ff1918fc" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View documentation on tl.Dense</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(tl.Dense)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on class Dense in module trax.layers.core:

class Dense(trax.layers.base.Layer)
 |  Dense(n_units, kernel_initializer=&lt;function ScaledInitializer.&lt;locals&gt;.Init at 0x7b3f64ea5fc0&gt;, bias_initializer=&lt;function RandomNormalInitializer.&lt;locals&gt;.&lt;lambda&gt; at 0x7b3f64ea6050&gt;, use_bias=True, use_bfloat16=False)
 |  
 |  A dense (a.k.a. fully-connected, affine) layer.
 |  
 |  Dense layers are the prototypical example of a trainable layer, i.e., a layer
 |  with trainable weights. Each node in a dense layer computes a weighted sum of
 |  all node values from the preceding layer and adds to that sum a node-specific
 |  bias term. The full layer computation is expressed compactly in linear
 |  algebra as an affine map `y = Wx + b`, where `W` is a matrix and `y`, `x`,
 |  and `b` are vectors. The layer is trained, or "learns", by updating the
 |  values in `W` and `b`.
 |  
 |  Less commonly, a dense layer can omit the bias term and be a pure linear map:
 |  `y = Wx`.
 |  
 |  Method resolution order:
 |      Dense
 |      trax.layers.base.Layer
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, n_units, kernel_initializer=&lt;function ScaledInitializer.&lt;locals&gt;.Init at 0x7b3f64ea5fc0&gt;, bias_initializer=&lt;function RandomNormalInitializer.&lt;locals&gt;.&lt;lambda&gt; at 0x7b3f64ea6050&gt;, use_bias=True, use_bfloat16=False)
 |      Returns a dense (fully connected) layer of width `n_units`.
 |      
 |      A dense layer maps collections of `R^m` vectors to `R^n`, where `n`
 |      (`= n_units`) is fixed at layer creation time, and `m` is set at layer
 |      initialization time.
 |      
 |      Args:
 |        n_units: Number of nodes in the layer, also known as the width of the
 |            layer.
 |        kernel_initializer: Function that creates a matrix of (random) initial
 |            connection weights `W` for the layer.
 |        bias_initializer: Function that creates a vector of (random) initial
 |            bias weights `b` for the layer.
 |        use_bias: If `True`, compute an affine map `y = Wx + b`; else compute
 |            a linear map `y = Wx`.
 |        use_bfloat16: If `True`, use bfloat16 weights instead of the default
 |          float32; this can save memory but may (rarely) lead to numerical issues.
 |  
 |  forward(self, x)
 |      Executes this layer as part of a forward pass through the model.
 |      
 |      Args:
 |        x: Tensor of same shape and dtype as the input signature used to
 |            initialize this layer.
 |      
 |      Returns:
 |        Tensor of same shape and dtype as the input, except the final dimension
 |        is the layer's `n_units` value.
 |  
 |  init_weights_and_state(self, input_signature)
 |      Randomly initializes this layer's weights.
 |      
 |      Weights are a `(w, b)` tuple for layers created with `use_bias=True` (the
 |      default case), or a `w` tensor for layers created with `use_bias=False`.
 |      
 |      Args:
 |        input_signature: `ShapeDtype` instance characterizing the input this layer
 |            should compute on.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from trax.layers.base.Layer:
 |  
 |  __call__(self, x, weights=None, state=None, rng=None)
 |      Makes layers callable; for use in tests or interactive settings.
 |      
 |      This convenience method helps library users play with, test, or otherwise
 |      probe the behavior of layers outside of a full training environment. It
 |      presents the layer as callable function from inputs to outputs, with the
 |      option of manually specifying weights and non-parameter state per individual
 |      call. For convenience, weights and non-parameter state are cached per layer
 |      instance, starting from default values of `EMPTY_WEIGHTS` and `EMPTY_STATE`,
 |      and acquiring non-empty values either by initialization or from values
 |      explicitly provided via the weights and state keyword arguments, in which
 |      case the old weights will be preserved, and the state will be updated.
 |      
 |      Args:
 |        x: Zero or more input tensors, packaged as described in the `Layer` class
 |            docstring.
 |        weights: Weights or `None`; if `None`, use self's cached weights value.
 |        state: State or `None`; if `None`, use self's cached state value.
 |        rng: Single-use random number generator (JAX PRNG key), or `None`;
 |            if `None`, use a default computed from an integer 0 seed.
 |      
 |      Returns:
 |        Zero or more output tensors, packaged as described in the `Layer` class
 |        docstring.
 |  
 |  __repr__(self)
 |      Renders this layer as a medium-detailed string, to help in debugging.
 |      
 |      Subclasses should aim for high-signal/low-noise when overriding this
 |      method.
 |      
 |      Returns:
 |        A high signal-to-noise string representing this layer.
 |  
 |  __setattr__(self, attr, value)
 |      Sets class attributes and protects from typos.
 |      
 |      In Trax layers, we only allow to set the following public attributes::
 |      
 |        - weights
 |        - state
 |        - rng
 |      
 |      This function prevents from setting other public attributes to avoid typos,
 |      for example, this is not possible and would be without this function::
 |      
 |        [typo]   layer.weighs = some_tensor
 |      
 |      If you need to set other public attributes in a derived class (which we
 |      do not recommend as in almost all cases it suffices to use a private
 |      attribute), override self._settable_attrs to include the attribute name.
 |      
 |      Args:
 |        attr: Name of the attribute to be set.
 |        value: Value to be assigned to the attribute.
 |  
 |  backward(self, inputs, output, grad, weights, state, new_state, rng)
 |      Custom backward pass to propagate gradients in a custom way.
 |      
 |      Args:
 |        inputs: Input tensors; can be a (possibly nested) tuple.
 |        output: The result of running this layer on inputs.
 |        grad: Gradient signal computed based on subsequent layers; its structure
 |            and shape must match output.
 |        weights: This layer's weights.
 |        state: This layer's state prior to the current forward pass.
 |        new_state: This layer's state after the current forward pass.
 |        rng: Single-use random number generator (JAX PRNG key).
 |      
 |      Returns:
 |        The custom gradient signal for the input. Note that we need to return
 |        a gradient for each argument of forward, so it will usually be a tuple
 |        of signals: the gradient for inputs and weights.
 |  
 |  init(self, input_signature, rng=None, use_cache=False)
 |      Initializes weights/state of this layer and its sublayers recursively.
 |      
 |      Initialization creates layer weights and state, for layers that use them.
 |      It derives the necessary array shapes and data types from the layer's input
 |      signature, which is itself just shape and data type information.
 |      
 |      For layers without weights or state, this method safely does nothing.
 |      
 |      This method is designed to create weights/state only once for each layer
 |      instance, even if the same layer instance occurs in multiple places in the
 |      network. This enables weight sharing to be implemented as layer sharing.
 |      
 |      Args:
 |        input_signature: `ShapeDtype` instance (if this layer takes one input)
 |            or list/tuple of `ShapeDtype` instances.
 |        rng: Single-use random number generator (JAX PRNG key), or `None`;
 |            if `None`, use a default computed from an integer 0 seed.
 |        use_cache: If `True`, and if this layer instance has already been
 |            initialized elsewhere in the network, then return special marker
 |            values -- tuple `(GET_WEIGHTS_FROM_CACHE, GET_STATE_FROM_CACHE)`.
 |            Else return this layer's newly initialized weights and state.
 |      
 |      Returns:
 |        A `(weights, state)` tuple.
 |  
 |  init_from_file(self, file_name, weights_only=False, input_signature=None)
 |      Initializes this layer and its sublayers from a pickled checkpoint.
 |      
 |      In the common case (`weights_only=False`), the file must be a gziped pickled
 |      dictionary containing items with keys `'flat_weights', `'flat_state'` and
 |      `'input_signature'`, which are used to initialize this layer.
 |      If `input_signature` is specified, it's used instead of the one in the file.
 |      If `weights_only` is `True`, the dictionary does not need to have the
 |      `'flat_state'` item and the state it not restored either.
 |      
 |      Args:
 |        file_name: Name/path of the pickled weights/state file.
 |        weights_only: If `True`, initialize only the layer's weights. Else
 |            initialize both weights and state.
 |        input_signature: Input signature to be used instead of the one from file.
 |      
 |      Returns:
 |        A `(weights, state)` tuple.
 |  
 |  output_signature(self, input_signature)
 |      Returns output signature this layer would give for `input_signature`.
 |  
 |  pure_fn(self, x, weights, state, rng, use_cache=False)
 |      Applies this layer as a pure function with no optional args.
 |      
 |      This method exposes the layer's computation as a pure function. This is
 |      especially useful for JIT compilation. Do not override, use `forward`
 |      instead.
 |      
 |      Args:
 |        x: Zero or more input tensors, packaged as described in the `Layer` class
 |            docstring.
 |        weights: A tuple or list of trainable weights, with one element for this
 |            layer if this layer has no sublayers, or one for each sublayer if
 |            this layer has sublayers. If a layer (or sublayer) has no trainable
 |            weights, the corresponding weights element is an empty tuple.
 |        state: Layer-specific non-parameter state that can update between batches.
 |        rng: Single-use random number generator (JAX PRNG key).
 |        use_cache: if `True`, cache weights and state in the layer object; used
 |          to implement layer sharing in combinators.
 |      
 |      Returns:
 |        A tuple of `(tensors, state)`. The tensors match the number (`n_out`)
 |        promised by this layer, and are packaged as described in the `Layer`
 |        class docstring.
 |  
 |  save_to_file(self, file_name, weights_only=False, input_signature=None)
 |      Saves this layer and its sublayers to a pickled checkpoint.
 |      
 |      Args:
 |        file_name: Name/path of the pickled weights/state file.
 |        weights_only: If `True`, save only the layer's weights. Else
 |            save both weights and state.
 |        input_signature: Input signature to be used.
 |  
 |  weights_and_state_signature(self, input_signature, unsafe=False)
 |      Return a pair containing the signatures of weights and state.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from trax.layers.base.Layer:
 |  
 |  has_backward
 |      Returns `True` if this layer provides its own custom backward pass code.
 |      
 |      A layer subclass that provides custom backward pass code (for custom
 |      gradients) must override this method to return `True`.
 |  
 |  n_in
 |      Returns how many tensors this layer expects as input.
 |  
 |  n_out
 |      Returns how many tensors this layer promises as output.
 |  
 |  name
 |      Returns the name of this layer.
 |  
 |  sublayers
 |      Returns a tuple containing this layer's sublayers; may be empty.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from trax.layers.base.Layer:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  rng
 |      Returns this layer's current single-use random number generator.
 |      
 |      Code that wants to base random samples on this generator must explicitly
 |      split off new generators from it. (See, for example, the `rng` setter code
 |      below.)
 |  
 |  state
 |      Returns a tuple containing this layer's state; may be empty.
 |      
 |      If the layer has sublayers, the state by convention will be
 |      a tuple of length `len(sublayers)` containing sublayer states.
 |      Note that in this case self._state only marks which ones are shared.
 |  
 |  weights
 |      Returns this layer's weights.
 |      
 |      Depending on the layer, the weights can be in the form of:
 |      
 |        - an empty tuple
 |        - a tensor (ndarray)
 |        - a nested structure of tuples and tensors
 |      
 |      If the layer has sublayers, the weights by convention will be
 |      a tuple of length `len(sublayers)` containing the weights of sublayers.
 |      Note that in this case self._weights only marks which ones are shared.
</code></pre>
</div>
</div>
<div id="602f09e0" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View documentation on tl.Serial</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(tl.Serial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on class Serial in module trax.layers.combinators:

class Serial(trax.layers.base.Layer)
 |  Serial(*sublayers, name=None, sublayers_to_print=None)
 |  
 |  Combinator that applies layers serially (by function composition).
 |  
 |  This combinator is commonly used to construct deep networks, e.g., like this::
 |  
 |      mlp = tl.Serial(
 |        tl.Dense(128),
 |        tl.Relu(),
 |        tl.Dense(10),
 |      )
 |  
 |  A Serial combinator uses stack semantics to manage data for its sublayers.
 |  Each sublayer sees only the inputs it needs and returns only the outputs it
 |  has generated. The sublayers interact via the data stack. For instance, a
 |  sublayer k, following sublayer j, gets called with the data stack in the
 |  state left after layer j has applied. The Serial combinator then:
 |  
 |    - takes n_in items off the top of the stack (n_in = k.n_in) and calls
 |      layer k, passing those items as arguments; and
 |  
 |    - takes layer k's n_out return values (n_out = k.n_out) and pushes
 |      them onto the data stack.
 |  
 |  A Serial instance with no sublayers acts as a special-case (but useful)
 |  1-input 1-output no-op.
 |  
 |  Method resolution order:
 |      Serial
 |      trax.layers.base.Layer
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, *sublayers, name=None, sublayers_to_print=None)
 |      Creates a partially initialized, unconnected layer instance.
 |      
 |      Args:
 |        n_in: Number of inputs expected by this layer.
 |        n_out: Number of outputs promised by this layer.
 |        name: Class-like name for this layer; for use when printing this layer.
 |        sublayers_to_print: Sublayers to display when printing out this layer;
 |          if None (the default), display all sublayers.
 |  
 |  forward(self, xs)
 |      Executes this layer as part of a forward pass through the model.
 |  
 |  init_weights_and_state(self, input_signature)
 |      Initializes weights and state for inputs with the given signature.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from trax.layers.base.Layer:
 |  
 |  __call__(self, x, weights=None, state=None, rng=None)
 |      Makes layers callable; for use in tests or interactive settings.
 |      
 |      This convenience method helps library users play with, test, or otherwise
 |      probe the behavior of layers outside of a full training environment. It
 |      presents the layer as callable function from inputs to outputs, with the
 |      option of manually specifying weights and non-parameter state per individual
 |      call. For convenience, weights and non-parameter state are cached per layer
 |      instance, starting from default values of `EMPTY_WEIGHTS` and `EMPTY_STATE`,
 |      and acquiring non-empty values either by initialization or from values
 |      explicitly provided via the weights and state keyword arguments, in which
 |      case the old weights will be preserved, and the state will be updated.
 |      
 |      Args:
 |        x: Zero or more input tensors, packaged as described in the `Layer` class
 |            docstring.
 |        weights: Weights or `None`; if `None`, use self's cached weights value.
 |        state: State or `None`; if `None`, use self's cached state value.
 |        rng: Single-use random number generator (JAX PRNG key), or `None`;
 |            if `None`, use a default computed from an integer 0 seed.
 |      
 |      Returns:
 |        Zero or more output tensors, packaged as described in the `Layer` class
 |        docstring.
 |  
 |  __repr__(self)
 |      Renders this layer as a medium-detailed string, to help in debugging.
 |      
 |      Subclasses should aim for high-signal/low-noise when overriding this
 |      method.
 |      
 |      Returns:
 |        A high signal-to-noise string representing this layer.
 |  
 |  __setattr__(self, attr, value)
 |      Sets class attributes and protects from typos.
 |      
 |      In Trax layers, we only allow to set the following public attributes::
 |      
 |        - weights
 |        - state
 |        - rng
 |      
 |      This function prevents from setting other public attributes to avoid typos,
 |      for example, this is not possible and would be without this function::
 |      
 |        [typo]   layer.weighs = some_tensor
 |      
 |      If you need to set other public attributes in a derived class (which we
 |      do not recommend as in almost all cases it suffices to use a private
 |      attribute), override self._settable_attrs to include the attribute name.
 |      
 |      Args:
 |        attr: Name of the attribute to be set.
 |        value: Value to be assigned to the attribute.
 |  
 |  backward(self, inputs, output, grad, weights, state, new_state, rng)
 |      Custom backward pass to propagate gradients in a custom way.
 |      
 |      Args:
 |        inputs: Input tensors; can be a (possibly nested) tuple.
 |        output: The result of running this layer on inputs.
 |        grad: Gradient signal computed based on subsequent layers; its structure
 |            and shape must match output.
 |        weights: This layer's weights.
 |        state: This layer's state prior to the current forward pass.
 |        new_state: This layer's state after the current forward pass.
 |        rng: Single-use random number generator (JAX PRNG key).
 |      
 |      Returns:
 |        The custom gradient signal for the input. Note that we need to return
 |        a gradient for each argument of forward, so it will usually be a tuple
 |        of signals: the gradient for inputs and weights.
 |  
 |  init(self, input_signature, rng=None, use_cache=False)
 |      Initializes weights/state of this layer and its sublayers recursively.
 |      
 |      Initialization creates layer weights and state, for layers that use them.
 |      It derives the necessary array shapes and data types from the layer's input
 |      signature, which is itself just shape and data type information.
 |      
 |      For layers without weights or state, this method safely does nothing.
 |      
 |      This method is designed to create weights/state only once for each layer
 |      instance, even if the same layer instance occurs in multiple places in the
 |      network. This enables weight sharing to be implemented as layer sharing.
 |      
 |      Args:
 |        input_signature: `ShapeDtype` instance (if this layer takes one input)
 |            or list/tuple of `ShapeDtype` instances.
 |        rng: Single-use random number generator (JAX PRNG key), or `None`;
 |            if `None`, use a default computed from an integer 0 seed.
 |        use_cache: If `True`, and if this layer instance has already been
 |            initialized elsewhere in the network, then return special marker
 |            values -- tuple `(GET_WEIGHTS_FROM_CACHE, GET_STATE_FROM_CACHE)`.
 |            Else return this layer's newly initialized weights and state.
 |      
 |      Returns:
 |        A `(weights, state)` tuple.
 |  
 |  init_from_file(self, file_name, weights_only=False, input_signature=None)
 |      Initializes this layer and its sublayers from a pickled checkpoint.
 |      
 |      In the common case (`weights_only=False`), the file must be a gziped pickled
 |      dictionary containing items with keys `'flat_weights', `'flat_state'` and
 |      `'input_signature'`, which are used to initialize this layer.
 |      If `input_signature` is specified, it's used instead of the one in the file.
 |      If `weights_only` is `True`, the dictionary does not need to have the
 |      `'flat_state'` item and the state it not restored either.
 |      
 |      Args:
 |        file_name: Name/path of the pickled weights/state file.
 |        weights_only: If `True`, initialize only the layer's weights. Else
 |            initialize both weights and state.
 |        input_signature: Input signature to be used instead of the one from file.
 |      
 |      Returns:
 |        A `(weights, state)` tuple.
 |  
 |  output_signature(self, input_signature)
 |      Returns output signature this layer would give for `input_signature`.
 |  
 |  pure_fn(self, x, weights, state, rng, use_cache=False)
 |      Applies this layer as a pure function with no optional args.
 |      
 |      This method exposes the layer's computation as a pure function. This is
 |      especially useful for JIT compilation. Do not override, use `forward`
 |      instead.
 |      
 |      Args:
 |        x: Zero or more input tensors, packaged as described in the `Layer` class
 |            docstring.
 |        weights: A tuple or list of trainable weights, with one element for this
 |            layer if this layer has no sublayers, or one for each sublayer if
 |            this layer has sublayers. If a layer (or sublayer) has no trainable
 |            weights, the corresponding weights element is an empty tuple.
 |        state: Layer-specific non-parameter state that can update between batches.
 |        rng: Single-use random number generator (JAX PRNG key).
 |        use_cache: if `True`, cache weights and state in the layer object; used
 |          to implement layer sharing in combinators.
 |      
 |      Returns:
 |        A tuple of `(tensors, state)`. The tensors match the number (`n_out`)
 |        promised by this layer, and are packaged as described in the `Layer`
 |        class docstring.
 |  
 |  save_to_file(self, file_name, weights_only=False, input_signature=None)
 |      Saves this layer and its sublayers to a pickled checkpoint.
 |      
 |      Args:
 |        file_name: Name/path of the pickled weights/state file.
 |        weights_only: If `True`, save only the layer's weights. Else
 |            save both weights and state.
 |        input_signature: Input signature to be used.
 |  
 |  weights_and_state_signature(self, input_signature, unsafe=False)
 |      Return a pair containing the signatures of weights and state.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from trax.layers.base.Layer:
 |  
 |  has_backward
 |      Returns `True` if this layer provides its own custom backward pass code.
 |      
 |      A layer subclass that provides custom backward pass code (for custom
 |      gradients) must override this method to return `True`.
 |  
 |  n_in
 |      Returns how many tensors this layer expects as input.
 |  
 |  n_out
 |      Returns how many tensors this layer promises as output.
 |  
 |  name
 |      Returns the name of this layer.
 |  
 |  sublayers
 |      Returns a tuple containing this layer's sublayers; may be empty.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from trax.layers.base.Layer:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  rng
 |      Returns this layer's current single-use random number generator.
 |      
 |      Code that wants to base random samples on this generator must explicitly
 |      split off new generators from it. (See, for example, the `rng` setter code
 |      below.)
 |  
 |  state
 |      Returns a tuple containing this layer's state; may be empty.
 |      
 |      If the layer has sublayers, the state by convention will be
 |      a tuple of length `len(sublayers)` containing sublayer states.
 |      Note that in this case self._state only marks which ones are shared.
 |  
 |  weights
 |      Returns this layer's weights.
 |      
 |      Depending on the layer, the weights can be in the form of:
 |      
 |        - an empty tuple
 |        - a tensor (ndarray)
 |        - a nested structure of tuples and tensors
 |      
 |      If the layer has sublayers, the weights by convention will be
 |      a tuple of length `len(sublayers)` containing the weights of sublayers.
 |      Note that in this case self._weights only marks which ones are shared.
</code></pre>
</div>
</div>
<ul>
<li><a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L113">tl.Embedding</a>: Layer constructor function for an embedding layer.
<ul>
<li><code>tl.Embedding(vocab_size, d_feature)</code>.</li>
<li><code>vocab_size</code> is the number of unique words in the given vocabulary.</li>
<li><code>d_feature</code> is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).</li>
</ul></li>
</ul>
<div id="dc91cf1a" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View documentation for tl.Embedding</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(tl.Embedding)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on class Embedding in module trax.layers.core:

class Embedding(trax.layers.base.Layer)
 |  Embedding(vocab_size, d_feature, use_bfloat16=False, kernel_initializer=&lt;function ScaledInitializer.&lt;locals&gt;.Init at 0x7b3f64ea63b0&gt;)
 |  
 |  Trainable layer that maps discrete tokens/IDs to vectors.
 |  
 |  Embedding layers are commonly used to map discrete data, like words in NLP,
 |  into vectors. Here is a canonical example::
 |  
 |      vocab_size = 5
 |      word_ids = np.array([1, 2, 3, 4], dtype=np.int32)  # word_ids &lt; vocab_size
 |      embedding_layer = tl.Embedding(vocab_size, 32)
 |      embedding_layer.init(trax.shapes.signature(word_ids))
 |      embedded = embedding_layer(word_ids)  # embedded.shape = (4, 32)
 |  
 |  Method resolution order:
 |      Embedding
 |      trax.layers.base.Layer
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __init__(self, vocab_size, d_feature, use_bfloat16=False, kernel_initializer=&lt;function ScaledInitializer.&lt;locals&gt;.Init at 0x7b3f64ea63b0&gt;)
 |      Returns an embedding layer with given vocabulary size and vector size.
 |      
 |      The layer clips input values (token IDs) to the range `[0, vocab_size)`.
 |      That is, negative token IDs all clip to `0` before being mapped to a
 |      vector, and token IDs with value `vocab_size` or greater all clip to
 |      `vocab_size - 1` before being mapped to a vector.
 |      
 |      Args:
 |        vocab_size: Size of the input vocabulary. The layer will assign a unique
 |          vector to each id in `range(vocab_size)`.
 |        d_feature: Dimensionality/depth of the output vectors.
 |        use_bfloat16: If `True`, use bfloat16 weights instead of the default
 |          float32; this can save memory but may (rarely) lead to numerical issues.
 |        kernel_initializer: Function that creates (random) initial vectors for
 |          the embedding.
 |  
 |  forward(self, x)
 |      Returns embedding vectors corresponding to input token IDs.
 |      
 |      Args:
 |        x: Tensor of token IDs.
 |      
 |      Returns:
 |        Tensor of embedding vectors.
 |  
 |  init_weights_and_state(self, input_signature)
 |      Randomly initializes this layer's weights.
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from trax.layers.base.Layer:
 |  
 |  __call__(self, x, weights=None, state=None, rng=None)
 |      Makes layers callable; for use in tests or interactive settings.
 |      
 |      This convenience method helps library users play with, test, or otherwise
 |      probe the behavior of layers outside of a full training environment. It
 |      presents the layer as callable function from inputs to outputs, with the
 |      option of manually specifying weights and non-parameter state per individual
 |      call. For convenience, weights and non-parameter state are cached per layer
 |      instance, starting from default values of `EMPTY_WEIGHTS` and `EMPTY_STATE`,
 |      and acquiring non-empty values either by initialization or from values
 |      explicitly provided via the weights and state keyword arguments, in which
 |      case the old weights will be preserved, and the state will be updated.
 |      
 |      Args:
 |        x: Zero or more input tensors, packaged as described in the `Layer` class
 |            docstring.
 |        weights: Weights or `None`; if `None`, use self's cached weights value.
 |        state: State or `None`; if `None`, use self's cached state value.
 |        rng: Single-use random number generator (JAX PRNG key), or `None`;
 |            if `None`, use a default computed from an integer 0 seed.
 |      
 |      Returns:
 |        Zero or more output tensors, packaged as described in the `Layer` class
 |        docstring.
 |  
 |  __repr__(self)
 |      Renders this layer as a medium-detailed string, to help in debugging.
 |      
 |      Subclasses should aim for high-signal/low-noise when overriding this
 |      method.
 |      
 |      Returns:
 |        A high signal-to-noise string representing this layer.
 |  
 |  __setattr__(self, attr, value)
 |      Sets class attributes and protects from typos.
 |      
 |      In Trax layers, we only allow to set the following public attributes::
 |      
 |        - weights
 |        - state
 |        - rng
 |      
 |      This function prevents from setting other public attributes to avoid typos,
 |      for example, this is not possible and would be without this function::
 |      
 |        [typo]   layer.weighs = some_tensor
 |      
 |      If you need to set other public attributes in a derived class (which we
 |      do not recommend as in almost all cases it suffices to use a private
 |      attribute), override self._settable_attrs to include the attribute name.
 |      
 |      Args:
 |        attr: Name of the attribute to be set.
 |        value: Value to be assigned to the attribute.
 |  
 |  backward(self, inputs, output, grad, weights, state, new_state, rng)
 |      Custom backward pass to propagate gradients in a custom way.
 |      
 |      Args:
 |        inputs: Input tensors; can be a (possibly nested) tuple.
 |        output: The result of running this layer on inputs.
 |        grad: Gradient signal computed based on subsequent layers; its structure
 |            and shape must match output.
 |        weights: This layer's weights.
 |        state: This layer's state prior to the current forward pass.
 |        new_state: This layer's state after the current forward pass.
 |        rng: Single-use random number generator (JAX PRNG key).
 |      
 |      Returns:
 |        The custom gradient signal for the input. Note that we need to return
 |        a gradient for each argument of forward, so it will usually be a tuple
 |        of signals: the gradient for inputs and weights.
 |  
 |  init(self, input_signature, rng=None, use_cache=False)
 |      Initializes weights/state of this layer and its sublayers recursively.
 |      
 |      Initialization creates layer weights and state, for layers that use them.
 |      It derives the necessary array shapes and data types from the layer's input
 |      signature, which is itself just shape and data type information.
 |      
 |      For layers without weights or state, this method safely does nothing.
 |      
 |      This method is designed to create weights/state only once for each layer
 |      instance, even if the same layer instance occurs in multiple places in the
 |      network. This enables weight sharing to be implemented as layer sharing.
 |      
 |      Args:
 |        input_signature: `ShapeDtype` instance (if this layer takes one input)
 |            or list/tuple of `ShapeDtype` instances.
 |        rng: Single-use random number generator (JAX PRNG key), or `None`;
 |            if `None`, use a default computed from an integer 0 seed.
 |        use_cache: If `True`, and if this layer instance has already been
 |            initialized elsewhere in the network, then return special marker
 |            values -- tuple `(GET_WEIGHTS_FROM_CACHE, GET_STATE_FROM_CACHE)`.
 |            Else return this layer's newly initialized weights and state.
 |      
 |      Returns:
 |        A `(weights, state)` tuple.
 |  
 |  init_from_file(self, file_name, weights_only=False, input_signature=None)
 |      Initializes this layer and its sublayers from a pickled checkpoint.
 |      
 |      In the common case (`weights_only=False`), the file must be a gziped pickled
 |      dictionary containing items with keys `'flat_weights', `'flat_state'` and
 |      `'input_signature'`, which are used to initialize this layer.
 |      If `input_signature` is specified, it's used instead of the one in the file.
 |      If `weights_only` is `True`, the dictionary does not need to have the
 |      `'flat_state'` item and the state it not restored either.
 |      
 |      Args:
 |        file_name: Name/path of the pickled weights/state file.
 |        weights_only: If `True`, initialize only the layer's weights. Else
 |            initialize both weights and state.
 |        input_signature: Input signature to be used instead of the one from file.
 |      
 |      Returns:
 |        A `(weights, state)` tuple.
 |  
 |  output_signature(self, input_signature)
 |      Returns output signature this layer would give for `input_signature`.
 |  
 |  pure_fn(self, x, weights, state, rng, use_cache=False)
 |      Applies this layer as a pure function with no optional args.
 |      
 |      This method exposes the layer's computation as a pure function. This is
 |      especially useful for JIT compilation. Do not override, use `forward`
 |      instead.
 |      
 |      Args:
 |        x: Zero or more input tensors, packaged as described in the `Layer` class
 |            docstring.
 |        weights: A tuple or list of trainable weights, with one element for this
 |            layer if this layer has no sublayers, or one for each sublayer if
 |            this layer has sublayers. If a layer (or sublayer) has no trainable
 |            weights, the corresponding weights element is an empty tuple.
 |        state: Layer-specific non-parameter state that can update between batches.
 |        rng: Single-use random number generator (JAX PRNG key).
 |        use_cache: if `True`, cache weights and state in the layer object; used
 |          to implement layer sharing in combinators.
 |      
 |      Returns:
 |        A tuple of `(tensors, state)`. The tensors match the number (`n_out`)
 |        promised by this layer, and are packaged as described in the `Layer`
 |        class docstring.
 |  
 |  save_to_file(self, file_name, weights_only=False, input_signature=None)
 |      Saves this layer and its sublayers to a pickled checkpoint.
 |      
 |      Args:
 |        file_name: Name/path of the pickled weights/state file.
 |        weights_only: If `True`, save only the layer's weights. Else
 |            save both weights and state.
 |        input_signature: Input signature to be used.
 |  
 |  weights_and_state_signature(self, input_signature, unsafe=False)
 |      Return a pair containing the signatures of weights and state.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties inherited from trax.layers.base.Layer:
 |  
 |  has_backward
 |      Returns `True` if this layer provides its own custom backward pass code.
 |      
 |      A layer subclass that provides custom backward pass code (for custom
 |      gradients) must override this method to return `True`.
 |  
 |  n_in
 |      Returns how many tensors this layer expects as input.
 |  
 |  n_out
 |      Returns how many tensors this layer promises as output.
 |  
 |  name
 |      Returns the name of this layer.
 |  
 |  sublayers
 |      Returns a tuple containing this layer's sublayers; may be empty.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from trax.layers.base.Layer:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  rng
 |      Returns this layer's current single-use random number generator.
 |      
 |      Code that wants to base random samples on this generator must explicitly
 |      split off new generators from it. (See, for example, the `rng` setter code
 |      below.)
 |  
 |  state
 |      Returns a tuple containing this layer's state; may be empty.
 |      
 |      If the layer has sublayers, the state by convention will be
 |      a tuple of length `len(sublayers)` containing sublayer states.
 |      Note that in this case self._state only marks which ones are shared.
 |  
 |  weights
 |      Returns this layer's weights.
 |      
 |      Depending on the layer, the weights can be in the form of:
 |      
 |        - an empty tuple
 |        - a tensor (ndarray)
 |        - a nested structure of tuples and tensors
 |      
 |      If the layer has sublayers, the weights by convention will be
 |      a tuple of length `len(sublayers)` containing the weights of sublayers.
 |      Note that in this case self._weights only marks which ones are shared.
</code></pre>
</div>
</div>
<div id="0f51e73a" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>tmp_embed <span class="op">=</span> tl.Embedding(vocab_size<span class="op">=</span><span class="dv">3</span>, d_feature<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>display(tmp_embed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Embedding_3_2</code></pre>
</div>
</div>
<ul>
<li><a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L276">tl.Mean</a>: Calculates means across an axis. In this case, please choose axis = 1 to get an average embedding vector (an embedding vector that is an average of all words in the vocabulary).<br>
</li>
<li>For example, if the embedding matrix is 300 elements and vocab size is 10,000 words, taking the mean of the embedding matrix along axis=1 will yield a vector of 300 elements.</li>
</ul>
<div id="50851869" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># view the documentation for tl.mean</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(tl.Mean)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on function Mean in module trax.layers.core:

Mean(axis=-1, keepdims=False)
    Returns a layer that computes mean values using one tensor axis.
    
    `Mean` uses one tensor axis to form groups of values and replaces each group
    with the mean value of that group. The resulting values can either remain
    in their own size 1 axis (`keepdims=True`), or that axis can be removed from
    the overall tensor (default `keepdims=False`), lowering the rank of the
    tensor by one.
    
    Args:
      axis: Axis along which values are grouped for computing a mean.
      keepdims: If `True`, keep the resulting size 1 axis as a separate tensor
          axis; else, remove that axis.
</code></pre>
</div>
</div>
<div id="6698e42d" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pretend the embedding matrix uses </span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2 elements for embedding the meaning of a word</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co"># and has a vocabulary size of 3</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="co"># So it has shape (2,3)</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>tmp_embed <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,],</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>                    [<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>]</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>                   ])</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a><span class="co"># take the mean along axis 0</span></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The mean along axis 0 creates a vector whose length equals the vocabulary size"</span>)</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>display(np.mean(tmp_embed,axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The mean along axis 1 creates a vector whose length equals the number of elements in a word embedding"</span>)</span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>display(np.mean(tmp_embed,axis<span class="op">=</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The mean along axis 0 creates a vector whose length equals the vocabulary size</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>Array([2.5, 3.5, 4.5], dtype=float32)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The mean along axis 1 creates a vector whose length equals the number of elements in a word embedding</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>Array([2., 5.], dtype=float32)</code></pre>
</div>
</div>
<ul>
<li><a href="https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L242">tl.LogSoftmax</a>: Implements log softmax function</li>
<li>Here, you don’t need to set any parameters for <code>LogSoftMax()</code>.</li>
</ul>
<div id="36ff5480" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(tl.LogSoftmax)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on function LogSoftmax in module trax.layers.core:

LogSoftmax(axis=-1)
    Returns a layer that applies log softmax along one tensor axis.
    
    Note that the implementation actually computes x - LogSumExp(x),
    which is mathematically equal to LogSoftmax(x).
    
    `LogSoftmax` acts on a group of values and normalizes them to look like a set
    of log probability values. (Probability values must be non-negative, and as
    a set must sum to 1. A group of log probability values can be seen as the
    natural logarithm function applied to a set of probability values.)
    
    Args:
      axis: Axis along which values are grouped for computing log softmax.
</code></pre>
</div>
</div>
<p><strong>Online documentation</strong></p>
<ul>
<li><p><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense">tl.Dense</a></p></li>
<li><p><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#module-trax.layers.combinators">tl.Serial</a></p></li>
<li><p><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding">tl.Embedding</a></p></li>
<li><p><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Mean">tl.Mean</a></p></li>
<li><p><a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax">tl.LogSoftmax</a></p></li>
</ul>
<section id="ex05" class="level3">
<h3 class="anchored" data-anchor-id="ex05">Exercise 05</h3>
<p>Implement the classifier function.</p>
<div id="e02fc891" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: classifier</span></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classifier(vocab_size<span class="op">=</span><span class="bu">len</span>(Vocab), embedding_dim<span class="op">=</span><span class="dv">256</span>, output_dim<span class="op">=</span><span class="dv">2</span>, mode<span class="op">=</span><span class="st">'train'</span>):</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create embedding layer</span></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>    embed_layer <span class="op">=</span> tl.Embedding(</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>        vocab_size<span class="op">=</span><span class="va">None</span>, <span class="co"># Size of the vocabulary</span></span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>        d_feature<span class="op">=</span><span class="va">None</span>)  <span class="co"># Embedding dimension</span></span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a mean layer, to create an "average" word embedding</span></span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>    mean_layer <span class="op">=</span> <span class="va">None</span></span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a dense layer, one unit for each output</span></span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>    dense_output_layer <span class="op">=</span> tl.Dense(n_units <span class="op">=</span> <span class="va">None</span>)</span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the log softmax layer (no parameters needed)</span></span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a>    log_softmax_layer <span class="op">=</span> <span class="va">None</span></span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use tl.Serial to combine all layers</span></span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and create the classifier</span></span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># of type trax.layers.combinators.Serial</span></span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tl.Serial(</span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>      <span class="va">None</span>, <span class="co"># embedding layer</span></span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>      <span class="va">None</span>, <span class="co"># mean layer</span></span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a>      <span class="va">None</span>, <span class="co"># dense output layer </span></span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a>      <span class="va">None</span> <span class="co"># log softmax layer</span></span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span><span class="co">     </span></span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb71-32"><a href="#cb71-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return the model of type</span></span>
<span id="cb71-33"><a href="#cb71-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="903a4b02" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>tmp_model <span class="op">=</span> classifier()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:437: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if self._mode == 'predict' and self._state[1] is not ():  # pylint: disable=literal-comparison
/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:910: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if state[0] is ():  # pylint: disable=literal-comparison
/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:437: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if self._mode == 'predict' and self._state[1] is not ():  # pylint: disable=literal-comparison
/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:910: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if state[0] is ():  # pylint: disable=literal-comparison</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[30], line 1</span>
<span class="ansi-green-fg">----&gt; 1</span> tmp_model <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">classifier</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span>

Cell <span class="ansi-green-fg">In[29], line 24</span>, in <span class="ansi-cyan-fg">classifier</span><span class="ansi-blue-fg">(vocab_size, embedding_dim, output_dim, mode)</span>
<span class="ansi-green-fg ansi-bold">     19</span>     log_softmax_layer <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span>
<span class="ansi-green-fg ansi-bold">     21</span>     <span style="font-style:italic;color:rgb(95,135,135)"># Use tl.Serial to combine all layers</span>
<span class="ansi-green-fg ansi-bold">     22</span>     <span style="font-style:italic;color:rgb(95,135,135)"># and create the classifier</span>
<span class="ansi-green-fg ansi-bold">     23</span>     <span style="font-style:italic;color:rgb(95,135,135)"># of type trax.layers.combinators.Serial</span>
<span class="ansi-green-fg">---&gt; 24</span>     model <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">tl</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">Serial</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-fg ansi-bold">     25</span> <span class="ansi-yellow-bg">      </span><span style="font-weight:bold;color:rgb(0,135,0)" class="ansi-yellow-bg">None</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="font-style:italic;color:rgb(95,135,135)" class="ansi-yellow-bg"># embedding layer</span>
<span class="ansi-green-fg ansi-bold">     26</span> <span class="ansi-yellow-bg">      </span><span style="font-weight:bold;color:rgb(0,135,0)" class="ansi-yellow-bg">None</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="font-style:italic;color:rgb(95,135,135)" class="ansi-yellow-bg"># mean layer</span>
<span class="ansi-green-fg ansi-bold">     27</span> <span class="ansi-yellow-bg">      </span><span style="font-weight:bold;color:rgb(0,135,0)" class="ansi-yellow-bg">None</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span style="font-style:italic;color:rgb(95,135,135)" class="ansi-yellow-bg"># dense output layer </span>
<span class="ansi-green-fg ansi-bold">     28</span> <span class="ansi-yellow-bg">      </span><span style="font-weight:bold;color:rgb(0,135,0)" class="ansi-yellow-bg">None</span><span class="ansi-yellow-bg"> </span><span style="font-style:italic;color:rgb(95,135,135)" class="ansi-yellow-bg"># log softmax layer</span>
<span class="ansi-green-fg ansi-bold">     29</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">     30</span> <span style="font-style:italic;color:rgb(95,135,135)">### END CODE HERE ###     </span>
<span class="ansi-green-fg ansi-bold">     31</span>     
<span class="ansi-green-fg ansi-bold">     32</span>     <span style="font-style:italic;color:rgb(95,135,135)"># return the model of type</span>
<span class="ansi-green-fg ansi-bold">     33</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> model

File <span class="ansi-green-fg">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:59</span>, in <span class="ansi-cyan-fg">Serial.__init__</span><span class="ansi-blue-fg">(self, name, sublayers_to_print, *sublayers)</span>
<span class="ansi-green-fg ansi-bold">     55</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span style="color:rgb(0,0,255)">__init__</span>(<span style="color:rgb(0,135,0)">self</span>, <span style="color:rgb(98,98,98)">*</span>sublayers, name<span style="color:rgb(98,98,98)">=</span><span style="font-weight:bold;color:rgb(0,135,0)">None</span>, sublayers_to_print<span style="color:rgb(98,98,98)">=</span><span style="font-weight:bold;color:rgb(0,135,0)">None</span>):
<span class="ansi-green-fg ansi-bold">     56</span>   <span style="color:rgb(0,135,0)">super</span>()<span style="color:rgb(98,98,98)">.</span><span style="color:rgb(0,0,255)">__init__</span>(
<span class="ansi-green-fg ansi-bold">     57</span>       name<span style="color:rgb(98,98,98)">=</span>name, sublayers_to_print<span style="color:rgb(98,98,98)">=</span>sublayers_to_print)
<span class="ansi-green-fg">---&gt; 59</span>   sublayers <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">_ensure_flat</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">sublayers</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">     60</span>   <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_sublayers <span style="color:rgb(98,98,98)">=</span> sublayers
<span class="ansi-green-fg ansi-bold">     61</span>   <span style="color:rgb(0,135,0)">self</span><span style="color:rgb(98,98,98)">.</span>_n_layers <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">len</span>(sublayers)

File <span class="ansi-green-fg">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:1110</span>, in <span class="ansi-cyan-fg">_ensure_flat</span><span class="ansi-blue-fg">(layers)</span>
<span class="ansi-green-fg ansi-bold">   1108</span> <span style="font-weight:bold;color:rgb(0,135,0)">for</span> obj <span style="font-weight:bold;color:rgb(175,0,255)">in</span> layers:
<span class="ansi-green-fg ansi-bold">   1109</span>   <span style="font-weight:bold;color:rgb(0,135,0)">if</span> <span style="font-weight:bold;color:rgb(175,0,255)">not</span> <span style="color:rgb(0,135,0)">isinstance</span>(obj, base<span style="color:rgb(98,98,98)">.</span>Layer):
<span class="ansi-green-fg">-&gt; 1110</span>     <span style="font-weight:bold;color:rgb(0,135,0)">raise</span> <span style="font-weight:bold;color:rgb(215,95,95)">ValueError</span>(
<span class="ansi-green-fg ansi-bold">   1111</span>         <span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">Found nonlayer object (</span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>obj<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">) in layers: </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>layers<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">'</span>)
<span class="ansi-green-fg ansi-bold">   1112</span> <span style="font-weight:bold;color:rgb(0,135,0)">return</span> layers

<span class="ansi-red-fg">ValueError</span>: Found nonlayer object (None) in layers: [None, None, None, None]</pre>
</div>
</div>
</div>
<div id="4fdc8b11" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(tmp_model))</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>display(tmp_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[31], line 1</span>
<span class="ansi-green-fg">----&gt; 1</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(0,135,0)">type</span>(<span class="ansi-yellow-bg">tmp_model</span>))
<span class="ansi-green-fg ansi-bold">      2</span> display(tmp_model)

<span class="ansi-red-fg">NameError</span>: name 'tmp_model' is not defined</pre>
</div>
</div>
</div>
<section id="expected-outout-2" class="level5">
<h5 class="anchored" data-anchor-id="expected-outout-2">Expected Outout</h5>
<div class="sourceCode" id="cb75"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span><span class="kw">class</span> <span class="ch">'t</span><span class="er">rax.layers.combinators.Serial</span><span class="ch">'</span><span class="op">&gt;</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>Serial<span class="op">[</span></span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>  Embedding_9088_256</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>  Mean</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>  Dense_2</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>  LogSoftmax</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
</section>
<section id="4" class="level1">
<h1>Part 4: Training</h1>
<p>To train a model on a task, Trax defines an abstraction <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask"><code>trax.supervised.training.TrainTask</code></a> which packages the train data, loss and optimizer (among other things) together into an object.</p>
<p>Similarly to evaluate a model, Trax defines an abstraction <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask"><code>trax.supervised.training.EvalTask</code></a> which packages the eval data and metrics (among other things) into another object.</p>
<p>The final piece tying things together is the <a href="https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop"><code>trax.supervised.training.Loop</code></a> abstraction that is a very simple and flexible way to put everything together and train the model, all the while evaluating it and saving checkpoints. Using <code>Loop</code> will save you a lot of code compared to always writing the training loop by hand, like you did in courses 1 and 2. More importantly, you are less likely to have a bug in that code that would ruin your training.</p>
<div id="cad1e2bc" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View documentation for trax.supervised.training.TrainTask</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(trax.supervised.training.TrainTask)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on class TrainTask in module trax.supervised.training:

class TrainTask(builtins.object)
 |  TrainTask(labeled_data, loss_layer, optimizer, lr_schedule=None, n_steps_per_checkpoint=100, n_steps_per_permanent_checkpoint=None, loss_name=None, sample_batch=None, export_prefix=None)
 |  
 |  A supervised task (labeled data + feedback mechanism) for training.
 |  
 |  Methods defined here:
 |  
 |  __init__(self, labeled_data, loss_layer, optimizer, lr_schedule=None, n_steps_per_checkpoint=100, n_steps_per_permanent_checkpoint=None, loss_name=None, sample_batch=None, export_prefix=None)
 |      Configures a training task.
 |      
 |      Args:
 |        labeled_data: Iterator of batches of labeled data tuples. Each tuple has
 |            1+ data (input value) tensors followed by 1 label (target value)
 |            tensor.  All tensors are NumPy ndarrays or their JAX counterparts.
 |        loss_layer: Layer that computes a scalar value (the "loss") by comparing
 |            model output :math:`\hat{y}=f(x)` to the target :math:`y`.
 |        optimizer: Optimizer object that computes model weight updates from
 |            loss-function gradients.
 |        lr_schedule: Learning rate schedule, a function step -&gt; learning_rate.
 |        n_steps_per_checkpoint: How many steps to run between checkpoints.
 |        n_steps_per_permanent_checkpoint: How many steps to run between permanent
 |            checkpoints.
 |        loss_name: Name for the loss metric.
 |        sample_batch: Optional sample batch for model initialization. If not
 |            provided, it will be taken from ``labeled_data``.
 |        export_prefix: Optional task name to be used as prefix for exporting
 |        metrics during training in Loop.
 |  
 |  learning_rate(self, step)
 |      Return the learning rate for the given step.
 |  
 |  next_batch(self)
 |      Returns one batch of labeled data: a tuple of input(s) plus label.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties defined here:
 |  
 |  export_prefix
 |  
 |  labeled_data
 |  
 |  loss_layer
 |  
 |  loss_name
 |  
 |  n_steps_per_checkpoint
 |  
 |  n_steps_per_permanent_checkpoint
 |  
 |  optimizer
 |  
 |  sample_batch
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
</code></pre>
</div>
</div>
<div id="2ae5f500" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View documentation for trax.supervised.training.EvalTask</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(trax.supervised.training.EvalTask)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on class EvalTask in module trax.supervised.training:

class EvalTask(builtins.object)
 |  EvalTask(labeled_data, metrics, metric_names=None, n_eval_batches=1, sample_batch=None, export_prefix=None)
 |  
 |  Labeled data plus scalar functions for (periodically) measuring a model.
 |  
 |  An eval task specifies how (``labeled_data`` + ``metrics``) and with what
 |  precision (``n_eval_batches``) to measure a model as it is training.
 |  The variance of each scalar output is reduced by measuring over multiple
 |  (``n_eval_batches``) batches and reporting the average from those
 |  measurements.
 |  
 |  Methods defined here:
 |  
 |  __init__(self, labeled_data, metrics, metric_names=None, n_eval_batches=1, sample_batch=None, export_prefix=None)
 |      Configures an eval task: named metrics run with a given data source.
 |      
 |      Args:
 |        labeled_data: Iterator of batches of labeled data tuples. Each tuple has
 |            1+ data tensors (NumPy ndarrays) followed by 1 label (target value)
 |            tensor.
 |        metrics: List of layers; each computes a scalar value per batch by
 |            comparing model output :math:`\hat{y}=f(x)` to the target :math:`y`.
 |        metric_names: List of names, one for each item in ``metrics``, in matching
 |             order, to be used when recording/reporting eval output. If ``None``,
 |             generate default names using layer names from metrics.
 |        n_eval_batches: Integer N that specifies how many eval batches to run;
 |            the output is then the average of the outputs from the N batches.
 |        sample_batch: Optional sample batch for model initialization. If not
 |            provided, it will be taken from ``labeled_data``.
 |        export_prefix: Optional task name to be used as prefix for exporting
 |            metrics during evaluation in Loop.
 |  
 |  next_batch(self)
 |      Returns one batch of labeled data: a tuple of input(s) plus label.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties defined here:
 |  
 |  export_prefix
 |  
 |  labeled_data
 |  
 |  metric_names
 |  
 |  metrics
 |  
 |  n_eval_batches
 |  
 |  sample_batch
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
</code></pre>
</div>
</div>
<div id="11ef0f9f" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View documentation for trax.supervised.training.Loop</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(trax.supervised.training.Loop)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on class Loop in module trax.supervised.training:

class Loop(builtins.object)
 |  Loop(model, tasks, eval_model=None, eval_tasks=None, output_dir=None, checkpoint_at=None, checkpoint_low_metric=None, checkpoint_high_metric=None, permanent_checkpoint_at=None, eval_at=None, which_task=None, n_devices=None, random_seed=None, loss_chunk_size=0, use_memory_efficient_trainer=False, adasum=False, callbacks=None)
 |  
 |  Loop that can run for a given number of steps to train a supervised model.
 |  
 |  Can train the model on multiple tasks by interleaving updates according to the
 |  ``which_task`` argument.
 |  
 |  The typical supervised training process randomly initializes a model and
 |  updates its weights via feedback (loss-derived gradients) from a training
 |  task, by looping through batches of labeled data. A training loop can also
 |  be configured to run periodic evals and save intermediate checkpoints.
 |  
 |  For speed, the implementation takes advantage of JAX's composable function
 |  transformations (specifically, ``jit`` and ``grad``). It creates JIT-compiled
 |  pure functions derived from variants of the core model; schematically:
 |  
 |    - training variant: `jit(grad(pure_function(model+loss)))`
 |    - evals variant: `jit(pure_function(model+evals))`
 |  
 |  In training or during evals, these variants are called with explicit
 |  arguments for all relevant input data, model weights/state, optimizer slots,
 |  and random number seeds:
 |  
 |    - batch: labeled data
 |    - model weights/state: trainable weights and input-related state (e.g., as
 |      used by batch norm)
 |    - optimizer slots: weights in the optimizer that evolve during the training
 |      process
 |    - random number seeds: JAX PRNG keys that enable high-quality, distributed,
 |      repeatable generation of pseudo-random numbers
 |  
 |  Methods defined here:
 |  
 |  __init__(self, model, tasks, eval_model=None, eval_tasks=None, output_dir=None, checkpoint_at=None, checkpoint_low_metric=None, checkpoint_high_metric=None, permanent_checkpoint_at=None, eval_at=None, which_task=None, n_devices=None, random_seed=None, loss_chunk_size=0, use_memory_efficient_trainer=False, adasum=False, callbacks=None)
 |      Configures a training ``Loop``, including a random initialization.
 |      
 |      Args:
 |        model: Trax layer, representing the core model to be trained. Loss
 |            functions and eval functions (a.k.a. metrics) are considered to be
 |            outside the core model, taking core model output and data labels as
 |            their two inputs.
 |        tasks: List of :py:class:`TrainTask` instances, which define the training
 |            data, loss function, and optimizer to be used in respective tasks in
 |            this training loop. It can also be a single :py:class:`TrainTask`
 |            instance which is treated in the same way as a singleton list.
 |        eval_model: Optional Trax layer, representing model used for evaluation,
 |            e.g., with dropout turned off. If ``None``, the training model (model)
 |            will be used.
 |        eval_tasks: List of :py:class:`EvalTask` instances which define how to
 |            evaluate the model: which validation data to use and which metrics to
 |            report. Evaluation on each of the tasks and will run and be reported
 |            separately which allows to score a model on different subtasks. This
 |            argument can also be ``None``, in which case no evals will be run, or
 |            a single :py:class:`EvalTask`, which wil be treated in the same way
 |            as a singleton list.
 |        output_dir: Path telling where to save outputs (evals and checkpoints).
 |            Can be ``None`` if both ``eval_task`` and ``checkpoint_at`` are
 |            ``None``.
 |        checkpoint_at: Function (integer --&gt; boolean) telling, for step n, whether
 |            that step should have its checkpoint saved. If ``None``, the default
 |            is periodic checkpointing at ``task.n_steps_per_checkpoint``.
 |        checkpoint_low_metric: Name of metric, or None. The metric name must
 |            be one of the metric names from the evals in ``eval_tasks``. At
 |            checkpoint times determined by ``checkpoint_at``, a separate
 |            specially named checkpoint will be saved (overwriting any previous
 |            version) if the designated metric reaches a value less than or equal
 |            to any previous recorded low value. No such checkpoint is saved if
 |            arg value is `None`.
 |        checkpoint_high_metric: Name of metric, or None. The metric name must
 |            be one of the metric names from the evals in ``eval_tasks``. At
 |            checkpoint times determined by ``checkpoint_at``, a separate
 |            specially named checkpoint will be saved (overwriting any previous
 |            version) if the designated metric reaches a value greater than or
 |            equal to any previous recorded high value. No such checkpoint is
 |            saved if arg value is `None`.
 |        permanent_checkpoint_at: Function (integer --&gt; boolean) telling,
 |            for step n, whether that step should have its checkpoint saved
 |            permanently. If ``None``, the default is periodic checkpointing at
 |            ``task.n_steps_per_permanent_checkpoint``.
 |        eval_at: Function (integer --&gt; boolean) that says, for training step n,
 |            whether that step should run evals. If ``None``, run evals on the
 |            first step and on every N'th step, as determined by the first
 |            training task.
 |        which_task: Function (integer --&gt; integer) indicating which task should be
 |            used at which training step. Can be set to ``None`` in single-task
 |            training.
 |        n_devices: integer or ``None``, the number of devices for this
 |            computation.
 |        random_seed: the random seed to use; time/os dependent if ``None``
 |            (default).
 |        loss_chunk_size: int, if &gt; 0 use chunks of this size to make loss
 |          computation more more memory-efficient.
 |        use_memory_efficient_trainer: whether to use a special memory-efficient
 |          trainer; if set to 2, the memory efficiency if very aggressive
 |        adasum: if True, use adaptive summation for multi-device gradients
 |        callbacks: List of subclasses of StepCallback to call on training
 |          steps.
 |  
 |  load_checkpoint(self, directory=None, filename=None)
 |      Loads model weights and step from a checkpoint on disk.
 |      
 |      Args:
 |        directory: Directory with the checkpoint (self._output_dir by default).
 |        filename: Checkpoint file name (model.pkl.gz by default).
 |  
 |  log_summary(self, values, summary_writer, value_prefix, log_prefix, stdout=True)
 |      Logs and saves provided metrics.
 |      
 |      Args:
 |        values: Dict from metric name to metric value.
 |        summary_writer: Jaxboard summary writer.
 |        value_prefix: String appended in front of summary_writer entries.
 |        log_prefix: String appended in front of logs.
 |        stdout: Boolean saying if logs should be logged to stdout as well.
 |  
 |  new_rng(self)
 |      Returns a new single-use random number generator (JAX PRNG key).
 |  
 |  run(self, n_steps=1)
 |      Runs this training loop for n steps.
 |      
 |      Optionally runs evals and saves checkpoints at specified points.
 |      
 |      Args:
 |        n_steps: Stop training after completing n steps.
 |  
 |  run_evals(self, summary_writers=None)
 |      Runs and records evals for this training session.
 |      
 |      Args:
 |        summary_writers: List of per-task Jaxboard summary writers to log metrics.
 |  
 |  save_checkpoint(self, basename)
 |      Saves checkpoint (multiple files) to disk for the current training step.
 |      
 |      Saving a checkpoint will overwrite any previous checkpoint saved with the
 |      same ``basename``. Use differing ``basename`` values to save multiple
 |      checkpoints or multiple copies of the same checkpoint.
 |      
 |      Args:
 |        basename: Basename for saving a checkpoint. Full file paths for the saved
 |            checkpoint will combine the output dir, basename, and relevant file
 |            extensions (e.g., `.weights.npy.gz`).
 |  
 |  update_weights_and_state(self, weights=None, state=None)
 |      Updates the weights and state of the trained model.
 |      
 |      Sends this data both to the singleton model accessible via Loop.model
 |      and to the replicated model on the accelerator.
 |      
 |      Useful when the weights or state are modified outside of training, e.g.
 |      during data collection in RL agents.
 |      
 |      Args:
 |        weights: Model weights or ``None``. If ``None``, don't set.
 |        state: Model state or ``None``. If ``None``, don't set.
 |  
 |  ----------------------------------------------------------------------
 |  Readonly properties defined here:
 |  
 |  eval_model
 |      Returns the model used for evaluation.
 |  
 |  eval_tasks
 |      Returns the evaluation tasks.
 |  
 |  history
 |      Returns history in this training session.
 |  
 |  is_chief
 |      Returns true if this Loop is the chief.
 |  
 |  model
 |      Returns the model that is training.
 |  
 |  n_devices
 |      Returns the number of devices to be used in this computation.
 |  
 |  output_dir
 |      Returns the output directory.
 |  
 |  step
 |      Returns current step number in this training session.
 |  
 |  tasks
 |      Returns the training tasks.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
</code></pre>
</div>
</div>
<div id="2acde261" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View optimizers that you could choose from</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(trax.optimizers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Help on package trax.optimizers in trax:

NAME
    trax.optimizers - Optimizers for use with Trax layers.

PACKAGE CONTENTS
    adafactor
    adam
    base
    momentum
    optimizers_test
    rms_prop
    sm3
    trainer
    trainer_test

FUNCTIONS
    opt_configure(*args, **kwargs)

FILE
    /home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/optimizers/__init__.py

</code></pre>
</div>
</div>
<p>Notice some available optimizers include:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>    adafactor</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>    adam</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>    momentum</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>    rms_prop</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>    sm3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="4.1" class="level2">
<h2 class="anchored" data-anchor-id="4.1">4.1 Training the model</h2>
<p>Now you are going to train your model.</p>
<p>Let’s define the <code>TrainTask</code>, <code>EvalTask</code> and <code>Loop</code> in preparation to train the model.</p>
<div id="38274bb2" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trax.supervised <span class="im">import</span> training</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>rnd.seed(<span class="dv">271</span>)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>train_task <span class="op">=</span> training.TrainTask(</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>    labeled_data<span class="op">=</span>train_generator(batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>    loss_layer<span class="op">=</span>tl.CrossEntropyLoss(),</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>trax.optimizers.Adam(<span class="fl">0.01</span>),</span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>    n_steps_per_checkpoint<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>eval_task <span class="op">=</span> training.EvalTask(</span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a>    labeled_data<span class="op">=</span>val_generator(batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[tl.CrossEntropyLoss(), tl.Accuracy()],</span>
<span id="cb85-16"><a href="#cb85-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb85-17"><a href="#cb85-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-18"><a href="#cb85-18" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> classifier()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[36], line 7</span>
<span class="ansi-green-fg ansi-bold">      3</span> batch_size <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(98,98,98)">16</span>
<span class="ansi-green-fg ansi-bold">      4</span> rnd<span style="color:rgb(98,98,98)">.</span>seed(<span style="color:rgb(98,98,98)">271</span>)
<span class="ansi-green-fg ansi-bold">      6</span> train_task <span style="color:rgb(98,98,98)">=</span> training<span style="color:rgb(98,98,98)">.</span>TrainTask(
<span class="ansi-green-fg">----&gt; 7</span>     labeled_data<span style="color:rgb(98,98,98)">=</span><span class="ansi-yellow-bg">train_generator</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">batch_size</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">batch_size</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">shuffle</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span style="font-weight:bold;color:rgb(0,135,0)" class="ansi-yellow-bg">True</span><span class="ansi-yellow-bg">)</span>,
<span class="ansi-green-fg ansi-bold">      8</span>     loss_layer<span style="color:rgb(98,98,98)">=</span>tl<span style="color:rgb(98,98,98)">.</span>CrossEntropyLoss(),
<span class="ansi-green-fg ansi-bold">      9</span>     optimizer<span style="color:rgb(98,98,98)">=</span>trax<span style="color:rgb(98,98,98)">.</span>optimizers<span style="color:rgb(98,98,98)">.</span>Adam(<span style="color:rgb(98,98,98)">0.01</span>),
<span class="ansi-green-fg ansi-bold">     10</span>     n_steps_per_checkpoint<span style="color:rgb(98,98,98)">=</span><span style="color:rgb(98,98,98)">10</span>,
<span class="ansi-green-fg ansi-bold">     11</span> )
<span class="ansi-green-fg ansi-bold">     13</span> eval_task <span style="color:rgb(98,98,98)">=</span> training<span style="color:rgb(98,98,98)">.</span>EvalTask(
<span class="ansi-green-fg ansi-bold">     14</span>     labeled_data<span style="color:rgb(98,98,98)">=</span>val_generator(batch_size<span style="color:rgb(98,98,98)">=</span>batch_size, shuffle<span style="color:rgb(98,98,98)">=</span><span style="font-weight:bold;color:rgb(0,135,0)">True</span>),
<span class="ansi-green-fg ansi-bold">     15</span>     metrics<span style="color:rgb(98,98,98)">=</span>[tl<span style="color:rgb(98,98,98)">.</span>CrossEntropyLoss(), tl<span style="color:rgb(98,98,98)">.</span>Accuracy()],
<span class="ansi-green-fg ansi-bold">     16</span> )
<span class="ansi-green-fg ansi-bold">     18</span> model <span style="color:rgb(98,98,98)">=</span> classifier()

Cell <span class="ansi-green-fg">In[14], line 6</span>, in <span class="ansi-cyan-fg">train_generator</span><span class="ansi-blue-fg">(batch_size, shuffle)</span>
<span class="ansi-green-fg ansi-bold">      5</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span style="color:rgb(0,0,255)">train_generator</span>(batch_size, shuffle <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">False</span>):
<span class="ansi-green-fg">----&gt; 6</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">data_generator</span>(train_pos, train_neg, batch_size, <span style="font-weight:bold;color:rgb(0,135,0)">True</span>, Vocab, shuffle)

<span class="ansi-red-fg">NameError</span>: name 'data_generator' is not defined</pre>
</div>
</div>
</div>
<p>This defines a model trained using <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss"><code>tl.CrossEntropyLoss</code></a> optimized with the <a href="https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam"><code>trax.optimizers.Adam</code></a> optimizer, all the while tracking the accuracy using <a href="https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.Accuracy"><code>tl.Accuracy</code></a> metric. We also track <code>tl.CrossEntropyLoss</code> on the validation set.</p>
<p>Now let’s make an output directory and train the model.</p>
<div id="a92a57ef" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">'~/model/'</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>output_dir_expand <span class="op">=</span> os.path.expanduser(output_dir)</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output_dir_expand)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>/home/oren/model/</code></pre>
</div>
</div>
<section id="ex06" class="level3">
<h3 class="anchored" data-anchor-id="ex06">Exercise 06</h3>
<p><strong>Instructions:</strong> Implement <code>train_model</code> to train the model (<code>classifier</code> that you wrote earlier) for the given number of training steps (<code>n_steps</code>) using <code>TrainTask</code>, <code>EvalTask</code> and <code>Loop</code>.</p>
<div id="917b0bd8" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: train_model</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(classifier, train_task, eval_task, n_steps, output_dir):</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: </span></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a><span class="co">        classifier - the model you are building</span></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a><span class="co">        train_task - Training task</span></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a><span class="co">        eval_task - Evaluation task</span></span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a><span class="co">        n_steps - the evaluation steps</span></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a><span class="co">        output_dir - folder to save your files</span></span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Output:</span></span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a><span class="co">        trainer -  trax trainer</span></span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a><span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a>    training_loop <span class="op">=</span> training.Loop(</span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a>                                <span class="va">None</span>, <span class="co"># The learning model</span></span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a>                                <span class="va">None</span>, <span class="co"># The training task</span></span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a>                                eval_task <span class="op">=</span> <span class="va">None</span>, <span class="co"># The evaluation task</span></span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a>                                output_dir <span class="op">=</span> <span class="va">None</span>) <span class="co"># The output directory</span></span>
<span id="cb88-20"><a href="#cb88-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-21"><a href="#cb88-21" aria-hidden="true" tabindex="-1"></a>    training_loop.run(n_steps <span class="op">=</span> <span class="va">None</span>)</span>
<span id="cb88-22"><a href="#cb88-22" aria-hidden="true" tabindex="-1"></a><span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb88-23"><a href="#cb88-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-24"><a href="#cb88-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the training_loop, since it has the model.</span></span>
<span id="cb88-25"><a href="#cb88-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> training_loop</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="59de6e74" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>training_loop <span class="op">=</span> train_model(model, train_task, eval_task, <span class="dv">100</span>, output_dir_expand)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[39], line 1</span>
<span class="ansi-green-fg">----&gt; 1</span> training_loop <span style="color:rgb(98,98,98)">=</span> train_model(<span class="ansi-yellow-bg">model</span>, train_task, eval_task, <span style="color:rgb(98,98,98)">100</span>, output_dir_expand)

<span class="ansi-red-fg">NameError</span>: name 'model' is not defined</pre>
</div>
</div>
</div>
<section id="expected-output-approximately" class="level5">
<h5 class="anchored" data-anchor-id="expected-output-approximately">Expected output (Approximately)</h5>
<div class="sourceCode" id="cb90"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>Step      <span class="dv">1</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.88939196</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>Step      <span class="dv">1</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.68833977</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>Step      <span class="dv">1</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">0.50000000</span></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">10</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.61036736</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">10</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.52182281</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">10</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">0.68750000</span></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">20</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.34137666</span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">20</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.20654774</span></span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">20</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">1.00000000</span></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">30</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.20208922</span></span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">30</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.21594886</span></span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">30</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">0.93750000</span></span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">40</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.19611198</span></span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">40</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.17582777</span></span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">40</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">1.00000000</span></span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">50</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.11203773</span></span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">50</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.07589275</span></span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">50</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">1.00000000</span></span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">60</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.09375446</span></span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">60</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.09290724</span></span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">60</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">1.00000000</span></span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">70</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.08785903</span></span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">70</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.09610598</span></span>
<span id="cb90-24"><a href="#cb90-24" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">70</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">1.00000000</span></span>
<span id="cb90-25"><a href="#cb90-25" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">80</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.08858261</span></span>
<span id="cb90-26"><a href="#cb90-26" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">80</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.02319432</span></span>
<span id="cb90-27"><a href="#cb90-27" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">80</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">1.00000000</span></span>
<span id="cb90-28"><a href="#cb90-28" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">90</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.05699894</span></span>
<span id="cb90-29"><a href="#cb90-29" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">90</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.01778970</span></span>
<span id="cb90-30"><a href="#cb90-30" aria-hidden="true" tabindex="-1"></a>Step     <span class="dv">90</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">1.00000000</span></span>
<span id="cb90-31"><a href="#cb90-31" aria-hidden="true" tabindex="-1"></a>Step    <span class="dv">100</span><span class="op">:</span> train CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.03663783</span></span>
<span id="cb90-32"><a href="#cb90-32" aria-hidden="true" tabindex="-1"></a>Step    <span class="dv">100</span><span class="op">:</span> eval  CrossEntropyLoss <span class="op">|</span>  <span class="fl">0.00210550</span></span>
<span id="cb90-33"><a href="#cb90-33" aria-hidden="true" tabindex="-1"></a>Step    <span class="dv">100</span><span class="op">:</span> eval          Accuracy <span class="op">|</span>  <span class="fl">1.00000000</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="4.2" class="level2">
<h2 class="anchored" data-anchor-id="4.2">4.2 Practice Making a prediction</h2>
<p>Now that you have trained a model, you can access it as <code>training_loop.model</code> object. We will actually use <code>training_loop.eval_model</code> and in the next weeks you will learn why we sometimes use a different model for evaluation, e.g., one without dropout. For now, make predictions with your model.</p>
<p>Use the training data just to see how the prediction process works.<br>
- Later, you will use validation data to evaluate your model’s performance.</p>
<div id="325d5362" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a generator object</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>tmp_train_generator <span class="op">=</span> train_generator(<span class="dv">16</span>)</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="co"># get one batch</span></span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>tmp_batch <span class="op">=</span> <span class="bu">next</span>(tmp_train_generator)</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Position 0 has the model inputs (tweets as tensors)</span></span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a><span class="co"># position 1 has the targets (the actual labels)</span></span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>tmp_inputs, tmp_targets, tmp_example_weights <span class="op">=</span> tmp_batch</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The batch is a tuple of length </span><span class="sc">{</span><span class="bu">len</span>(tmp_batch)<span class="sc">}</span><span class="ss"> because position 0 contains the tweets, and position 1 contains the targets."</span>) </span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The shape of the tweet tensors is </span><span class="sc">{</span>tmp_inputs<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (num of examples, length of tweet tensors)"</span>)</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The shape of the labels is </span><span class="sc">{</span>tmp_targets<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, which is the batch size."</span>)</span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The shape of the example_weights is </span><span class="sc">{</span>tmp_example_weights<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, which is the same as inputs/targets size."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[40], line 2</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># Create a generator object</span>
<span class="ansi-green-fg">----&gt; 2</span> tmp_train_generator <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">train_generator</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">16</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">      4</span> <span style="font-style:italic;color:rgb(95,135,135)"># get one batch</span>
<span class="ansi-green-fg ansi-bold">      5</span> tmp_batch <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">next</span>(tmp_train_generator)

Cell <span class="ansi-green-fg">In[14], line 6</span>, in <span class="ansi-cyan-fg">train_generator</span><span class="ansi-blue-fg">(batch_size, shuffle)</span>
<span class="ansi-green-fg ansi-bold">      5</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span style="color:rgb(0,0,255)">train_generator</span>(batch_size, shuffle <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">False</span>):
<span class="ansi-green-fg">----&gt; 6</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">data_generator</span>(train_pos, train_neg, batch_size, <span style="font-weight:bold;color:rgb(0,135,0)">True</span>, Vocab, shuffle)

<span class="ansi-red-fg">NameError</span>: name 'data_generator' is not defined</pre>
</div>
</div>
</div>
<div id="a8cb4ef8" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># feed the tweet tensors into the model to get a prediction</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>tmp_pred <span class="op">=</span> training_loop.eval_model(tmp_inputs)</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The prediction shape is </span><span class="sc">{</span>tmp_pred<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, num of tensor_tweets as rows"</span>)</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Column 0 is the probability of a negative sentiment (class 0)"</span>)</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Column 1 is the probability of a positive sentiment (class 1)"</span>)</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"View the prediction array"</span>)</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>tmp_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[41], line 2</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># feed the tweet tensors into the model to get a prediction</span>
<span class="ansi-green-fg">----&gt; 2</span> tmp_pred <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">training_loop</span><span style="color:rgb(98,98,98)">.</span>eval_model(tmp_inputs)
<span class="ansi-green-fg ansi-bold">      3</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">The prediction shape is </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>tmp_pred<span style="color:rgb(98,98,98)">.</span>shape<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">, num of tensor_tweets as rows</span><span style="color:rgb(175,0,0)">"</span>)
<span class="ansi-green-fg ansi-bold">      4</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">Column 0 is the probability of a negative sentiment (class 0)</span><span style="color:rgb(175,0,0)">"</span>)

<span class="ansi-red-fg">NameError</span>: name 'training_loop' is not defined</pre>
</div>
</div>
</div>
<p>To turn these probabilities into categories (negative or positive sentiment prediction), for each row:</p>
<ul>
<li>Compare the probabilities in each column.</li>
<li>If column 1 has a value greater than column 0, classify that as a positive tweet.</li>
<li>Otherwise if column 1 is less than or equal to column 0, classify that example as a negative tweet.</li>
</ul>
<div id="964708b6" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># turn probabilites into category predictions</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>tmp_is_positive <span class="op">=</span> tmp_pred[:,<span class="dv">1</span>] <span class="op">&gt;</span> tmp_pred[:,<span class="dv">0</span>]</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, p <span class="kw">in</span> <span class="bu">enumerate</span>(tmp_is_positive):</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Neg log prob </span><span class="sc">{</span>tmp_pred[i,<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ch">\t</span><span class="ss">Pos log prob </span><span class="sc">{</span>tmp_pred[i,<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ch">\t</span><span class="ss"> is positive? </span><span class="sc">{</span>p<span class="sc">}</span><span class="ch">\t</span><span class="ss"> actual </span><span class="sc">{</span>tmp_targets[i]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[42], line 2</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># turn probabilites into category predictions</span>
<span class="ansi-green-fg">----&gt; 2</span> tmp_is_positive <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">tmp_pred</span>[:,<span style="color:rgb(98,98,98)">1</span>] <span style="color:rgb(98,98,98)">&gt;</span> tmp_pred[:,<span style="color:rgb(98,98,98)">0</span>]
<span class="ansi-green-fg ansi-bold">      3</span> <span style="font-weight:bold;color:rgb(0,135,0)">for</span> i, p <span style="font-weight:bold;color:rgb(175,0,255)">in</span> <span style="color:rgb(0,135,0)">enumerate</span>(tmp_is_positive):
<span class="ansi-green-fg ansi-bold">      4</span>     <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">Neg log prob </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>tmp_pred[i,<span style="color:rgb(98,98,98)">0</span>]<span style="font-weight:bold;color:rgb(175,95,135)">:</span><span style="color:rgb(175,0,0)">.4f</span><span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="font-weight:bold;color:rgb(175,95,0)">\t</span><span style="color:rgb(175,0,0)">Pos log prob </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>tmp_pred[i,<span style="color:rgb(98,98,98)">1</span>]<span style="font-weight:bold;color:rgb(175,95,135)">:</span><span style="color:rgb(175,0,0)">.4f</span><span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="font-weight:bold;color:rgb(175,95,0)">\t</span><span style="color:rgb(175,0,0)"> is positive? </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>p<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="font-weight:bold;color:rgb(175,95,0)">\t</span><span style="color:rgb(175,0,0)"> actual </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>tmp_targets[i]<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">"</span>)

<span class="ansi-red-fg">NameError</span>: name 'tmp_pred' is not defined</pre>
</div>
</div>
</div>
<p>Notice that since you are making a prediction using a training batch, it’s more likely that the model’s predictions match the actual targets (labels).</p>
<ul>
<li>Every prediction that the tweet is positive is also matching the actual target of 1 (positive sentiment).</li>
<li>Similarly, all predictions that the sentiment is not positive matches the actual target of 0 (negative sentiment)</li>
</ul>
<p>One more useful thing to know is how to compare if the prediction is matching the actual target (label).<br>
- The result of calculation <code>is_positive</code> is a boolean. - The target is a type trax.fastmath.numpy.int32 - If you expect to be doing division, you may prefer to work with decimal numbers with the data type type trax.fastmath.numpy.int32</p>
<div id="b6825bd6" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View the array of booleans</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Array of booleans"</span>)</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>display(tmp_is_positive)</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="co"># convert boolean to type int32</span></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a><span class="co"># True is converted to 1</span></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a><span class="co"># False is converted to 0</span></span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>tmp_is_positive_int <span class="op">=</span> tmp_is_positive.astype(np.int32)</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a><span class="co"># View the array of integers</span></span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Array of integers"</span>)</span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>display(tmp_is_positive_int)</span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a><span class="co"># convert boolean to type float32</span></span>
<span id="cb94-16"><a href="#cb94-16" aria-hidden="true" tabindex="-1"></a>tmp_is_positive_float <span class="op">=</span> tmp_is_positive.astype(np.float32)</span>
<span id="cb94-17"><a href="#cb94-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-18"><a href="#cb94-18" aria-hidden="true" tabindex="-1"></a><span class="co"># View the array of floats</span></span>
<span id="cb94-19"><a href="#cb94-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Array of floats"</span>)</span>
<span id="cb94-20"><a href="#cb94-20" aria-hidden="true" tabindex="-1"></a>display(tmp_is_positive_float)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Array of booleans</code></pre>
</div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[43], line 3</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># View the array of booleans</span>
<span class="ansi-green-fg ansi-bold">      2</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">Array of booleans</span><span style="color:rgb(175,0,0)">"</span>)
<span class="ansi-green-fg">----&gt; 3</span> display(<span class="ansi-yellow-bg">tmp_is_positive</span>)
<span class="ansi-green-fg ansi-bold">      5</span> <span style="font-style:italic;color:rgb(95,135,135)"># convert boolean to type int32</span>
<span class="ansi-green-fg ansi-bold">      6</span> <span style="font-style:italic;color:rgb(95,135,135)"># True is converted to 1</span>
<span class="ansi-green-fg ansi-bold">      7</span> <span style="font-style:italic;color:rgb(95,135,135)"># False is converted to 0</span>
<span class="ansi-green-fg ansi-bold">      8</span> tmp_is_positive_int <span style="color:rgb(98,98,98)">=</span> tmp_is_positive<span style="color:rgb(98,98,98)">.</span>astype(np<span style="color:rgb(98,98,98)">.</span>int32)

<span class="ansi-red-fg">NameError</span>: name 'tmp_is_positive' is not defined</pre>
</div>
</div>
</div>
<div id="3a5221f1" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>tmp_pred.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[44], line 1</span>
<span class="ansi-green-fg">----&gt; 1</span> <span class="ansi-yellow-bg">tmp_pred</span><span style="color:rgb(98,98,98)">.</span>shape

<span class="ansi-red-fg">NameError</span>: name 'tmp_pred' is not defined</pre>
</div>
</div>
</div>
<p>Note that Python usually does type conversion for you when you compare a boolean to an integer - True compared to 1 is True, otherwise any other integer is False. - False compared to 0 is True, otherwise any ohter integer is False.</p>
<div id="ee636449" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True == 1: </span><span class="sc">{</span><span class="va">True</span> <span class="op">==</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True == 2: </span><span class="sc">{</span><span class="va">True</span> <span class="op">==</span> <span class="dv">2</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"False == 0: </span><span class="sc">{</span><span class="va">False</span> <span class="op">==</span> <span class="dv">0</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"False == 2: </span><span class="sc">{</span><span class="va">False</span> <span class="op">==</span> <span class="dv">2</span><span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True == 1: True
True == 2: False
False == 0: True
False == 2: False</code></pre>
</div>
</div>
<p>However, we recommend that you keep track of the data type of your variables to avoid unexpected outcomes. So it helps to convert the booleans into integers - Compare 1 to 1 rather than comparing True to 1.</p>
<p>Hopefully you are now familiar with what kinds of inputs and outputs the model uses when making a prediction. - This will help you implement a function that estimates the accuracy of the model’s predictions.</p>
</section>
</section>
<section id="5" class="level1">
<h1>Part 5: Evaluation</h1>
<section id="5.1" class="level2">
<h2 class="anchored" data-anchor-id="5.1">5.1 Computing the accuracy on a batch</h2>
<p>You will now write a function that evaluates your model on the validation set and returns the accuracy.</p>
<ul>
<li><code>preds</code> contains the predictions.
<ul>
<li>Its dimensions are <code>(batch_size, output_dim)</code>. <code>output_dim</code> is two in this case. Column 0 contains the probability that the tweet belongs to class 0 (negative sentiment). Column 1 contains probability that it belongs to class 1 (positive sentiment).</li>
<li>If the probability in column 1 is greater than the probability in column 0, then interpret this as the model’s prediction that the example has label 1 (positive sentiment).<br>
</li>
<li>Otherwise, if the probabilities are equal or the probability in column 0 is higher, the model’s prediction is 0 (negative sentiment).</li>
</ul></li>
<li><code>y</code> contains the actual labels.</li>
<li><code>y_weights</code> contains the weights to give to predictions.</li>
</ul>
<section id="ex07" class="level3">
<h3 class="anchored" data-anchor-id="ex07">Exercise 07</h3>
<p>Implement <code>compute_accuracy</code>.</p>
<div id="ef20b20a" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: compute_accuracy</span></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_accuracy(preds, y, y_weights):</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: </span></span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a><span class="co">        preds: a tensor of shape (dim_batch, output_dim) </span></span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a><span class="co">        y: a tensor of shape (dim_batch, output_dim) with the true labels</span></span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a><span class="co">        y_weights: a n.ndarray with the a weight for each example</span></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Output: </span></span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a><span class="co">        accuracy: a float between 0-1 </span></span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a><span class="co">        weighted_num_correct (np.float32): Sum of the weighted correct predictions</span></span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a><span class="co">        sum_weights (np.float32): Sum of the weights</span></span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb99-15"><a href="#cb99-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create an array of booleans, </span></span>
<span id="cb99-16"><a href="#cb99-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># True if the probability of positive sentiment is greater than</span></span>
<span id="cb99-17"><a href="#cb99-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the probability of negative sentiment</span></span>
<span id="cb99-18"><a href="#cb99-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># else False</span></span>
<span id="cb99-19"><a href="#cb99-19" aria-hidden="true" tabindex="-1"></a>    is_pos <span class="op">=</span>  <span class="va">None</span></span>
<span id="cb99-20"><a href="#cb99-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-21"><a href="#cb99-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert the array of booleans into an array of np.int32</span></span>
<span id="cb99-22"><a href="#cb99-22" aria-hidden="true" tabindex="-1"></a>    is_pos_int <span class="op">=</span> <span class="va">None</span></span>
<span id="cb99-23"><a href="#cb99-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb99-24"><a href="#cb99-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compare the array of predictions (as int32) with the target (labels) of type int32</span></span>
<span id="cb99-25"><a href="#cb99-25" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="va">None</span></span>
<span id="cb99-26"><a href="#cb99-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-27"><a href="#cb99-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Count the sum of the weights.</span></span>
<span id="cb99-28"><a href="#cb99-28" aria-hidden="true" tabindex="-1"></a>    sum_weights <span class="op">=</span> <span class="va">None</span></span>
<span id="cb99-29"><a href="#cb99-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb99-30"><a href="#cb99-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert the array of correct predictions (boolean) into an arrayof np.float32</span></span>
<span id="cb99-31"><a href="#cb99-31" aria-hidden="true" tabindex="-1"></a>    correct_float <span class="op">=</span> <span class="va">None</span></span>
<span id="cb99-32"><a href="#cb99-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb99-33"><a href="#cb99-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Multiply each prediction with its corresponding weight.</span></span>
<span id="cb99-34"><a href="#cb99-34" aria-hidden="true" tabindex="-1"></a>    weighted_correct_float <span class="op">=</span> <span class="va">None</span></span>
<span id="cb99-35"><a href="#cb99-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-36"><a href="#cb99-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sum up the weighted correct predictions (of type np.float32), to go in the</span></span>
<span id="cb99-37"><a href="#cb99-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># denominator.</span></span>
<span id="cb99-38"><a href="#cb99-38" aria-hidden="true" tabindex="-1"></a>    weighted_num_correct <span class="op">=</span> <span class="va">None</span></span>
<span id="cb99-39"><a href="#cb99-39" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb99-40"><a href="#cb99-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Divide the number of weighted correct predictions by the sum of the</span></span>
<span id="cb99-41"><a href="#cb99-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># weights.</span></span>
<span id="cb99-42"><a href="#cb99-42" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> <span class="va">None</span></span>
<span id="cb99-43"><a href="#cb99-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-44"><a href="#cb99-44" aria-hidden="true" tabindex="-1"></a>    <span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb99-45"><a href="#cb99-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> accuracy, weighted_num_correct, sum_weights</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b33e6701" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># test your function</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>tmp_val_generator <span class="op">=</span> val_generator(<span class="dv">64</span>)</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a><span class="co"># get one batch</span></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>tmp_batch <span class="op">=</span> <span class="bu">next</span>(tmp_val_generator)</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Position 0 has the model inputs (tweets as tensors)</span></span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a><span class="co"># position 1 has the targets (the actual labels)</span></span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>tmp_inputs, tmp_targets, tmp_example_weights <span class="op">=</span> tmp_batch</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true" tabindex="-1"></a><span class="co"># feed the tweet tensors into the model to get a prediction</span></span>
<span id="cb100-12"><a href="#cb100-12" aria-hidden="true" tabindex="-1"></a>tmp_pred <span class="op">=</span> training_loop.eval_model(tmp_inputs)</span>
<span id="cb100-13"><a href="#cb100-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-14"><a href="#cb100-14" aria-hidden="true" tabindex="-1"></a>tmp_acc, tmp_num_correct, tmp_num_predictions <span class="op">=</span> compute_accuracy(preds<span class="op">=</span>tmp_pred, y<span class="op">=</span>tmp_targets, y_weights<span class="op">=</span>tmp_example_weights)</span>
<span id="cb100-15"><a href="#cb100-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-16"><a href="#cb100-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model's prediction accuracy on a single training batch is: </span><span class="sc">{</span><span class="dv">100</span> <span class="op">*</span> tmp_acc<span class="sc">}</span><span class="ss">%"</span>)</span>
<span id="cb100-17"><a href="#cb100-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Weighted number of correct predictions </span><span class="sc">{</span>tmp_num_correct<span class="sc">}</span><span class="ss">; weighted number of total observations predicted </span><span class="sc">{</span>tmp_num_predictions<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[47], line 2</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># test your function</span>
<span class="ansi-green-fg">----&gt; 2</span> tmp_val_generator <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">val_generator</span><span class="ansi-yellow-bg">(</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">64</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">      4</span> <span style="font-style:italic;color:rgb(95,135,135)"># get one batch</span>
<span class="ansi-green-fg ansi-bold">      5</span> tmp_batch <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(0,135,0)">next</span>(tmp_val_generator)

Cell <span class="ansi-green-fg">In[14], line 10</span>, in <span class="ansi-cyan-fg">val_generator</span><span class="ansi-blue-fg">(batch_size, shuffle)</span>
<span class="ansi-green-fg ansi-bold">      9</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span style="color:rgb(0,0,255)">val_generator</span>(batch_size, shuffle <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">False</span>):
<span class="ansi-green-fg">---&gt; 10</span>     <span style="font-weight:bold;color:rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">data_generator</span>(val_pos, val_neg, batch_size, <span style="font-weight:bold;color:rgb(0,135,0)">True</span>, Vocab, shuffle)

<span class="ansi-red-fg">NameError</span>: name 'data_generator' is not defined</pre>
</div>
</div>
</div>
<section id="expected-output-approximately-1" class="level5">
<h5 class="anchored" data-anchor-id="expected-output-approximately-1">Expected output (Approximately)</h5>
<pre><code>Model's prediction accuracy on a single training batch is: 100.0%
Weighted number of correct predictions 64.0; weighted number of total observations predicted 64</code></pre>
</section>
</section>
</section>
<section id="5.2" class="level2">
<h2 class="anchored" data-anchor-id="5.2">5.2 Testing your model on Validation Data</h2>
<p>Now you will write test your model’s prediction accuracy on validation data.</p>
<p>This program will take in a data generator and your model.</p>
<ul>
<li>The generator allows you to get batches of data. You can use it with a <code>for</code> loop:</li>
</ul>
<pre><code>for batch in iterator: 
   # do something with that batch</code></pre>
<p><code>batch</code> has dimensions <code>(X, Y, weights)</code>.</p>
<ul>
<li>Column 0 corresponds to the tweet as a tensor (input).</li>
<li>Column 1 corresponds to its target (actual label, positive or negative sentiment).</li>
<li>Column 2 corresponds to the weights associated (example weights)</li>
<li>You can feed the tweet into model and it will return the predictions for the batch.</li>
</ul>
<p><a name="ex08"></a> ### Exercise 08</p>
<p><strong>Instructions:</strong> - Compute the accuracy over all the batches in the validation iterator. - Make use of <code>compute_accuracy</code>, which you recently implemented, and return the overall accuracy.</p>
<div id="322c9d82" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># UNQ_C8 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a><span class="co"># GRADED FUNCTION: test_model</span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_model(generator, model):</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Input: </span></span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a><span class="co">        generator: an iterator instance that provides batches of inputs and targets</span></span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a><span class="co">        model: a model instance </span></span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Output: </span></span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a><span class="co">        accuracy: float corresponding to the accuracy</span></span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>    total_num_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>    total_num_pred <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">### START CODE HERE (Replace instances of 'None' with your code) </span><span class="al">###</span></span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> generator: </span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb103-19"><a href="#cb103-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Retrieve the inputs from the batch</span></span>
<span id="cb103-20"><a href="#cb103-20" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> <span class="va">None</span></span>
<span id="cb103-21"><a href="#cb103-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb103-22"><a href="#cb103-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Retrieve the targets (actual labels) from the batch</span></span>
<span id="cb103-23"><a href="#cb103-23" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> <span class="va">None</span></span>
<span id="cb103-24"><a href="#cb103-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb103-25"><a href="#cb103-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Retrieve the example weight.</span></span>
<span id="cb103-26"><a href="#cb103-26" aria-hidden="true" tabindex="-1"></a>        example_weight <span class="op">=</span> <span class="va">None</span></span>
<span id="cb103-27"><a href="#cb103-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-28"><a href="#cb103-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Make predictions using the inputs</span></span>
<span id="cb103-29"><a href="#cb103-29" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> <span class="va">None</span></span>
<span id="cb103-30"><a href="#cb103-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb103-31"><a href="#cb103-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate accuracy for the batch by comparing its predictions and targets</span></span>
<span id="cb103-32"><a href="#cb103-32" aria-hidden="true" tabindex="-1"></a>        batch_accuracy, batch_num_correct, batch_num_pred <span class="op">=</span> <span class="va">None</span></span>
<span id="cb103-33"><a href="#cb103-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb103-34"><a href="#cb103-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update the total number of correct predictions</span></span>
<span id="cb103-35"><a href="#cb103-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># by adding the number of correct predictions from this batch</span></span>
<span id="cb103-36"><a href="#cb103-36" aria-hidden="true" tabindex="-1"></a>        total_num_correct <span class="op">+=</span> <span class="va">None</span></span>
<span id="cb103-37"><a href="#cb103-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb103-38"><a href="#cb103-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update the total number of predictions </span></span>
<span id="cb103-39"><a href="#cb103-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># by adding the number of predictions made for the batch</span></span>
<span id="cb103-40"><a href="#cb103-40" aria-hidden="true" tabindex="-1"></a>        total_num_pred <span class="op">+=</span> <span class="va">None</span></span>
<span id="cb103-41"><a href="#cb103-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-42"><a href="#cb103-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate accuracy over all examples</span></span>
<span id="cb103-43"><a href="#cb103-43" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> <span class="va">None</span></span>
<span id="cb103-44"><a href="#cb103-44" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb103-45"><a href="#cb103-45" aria-hidden="true" tabindex="-1"></a>    <span class="co">### </span><span class="re">END</span><span class="co"> CODE HERE </span><span class="al">###</span></span>
<span id="cb103-46"><a href="#cb103-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> accuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f4e795be" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DO NOT EDIT THIS CELL</span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="co"># testing the accuracy of your model: this takes around 20 seconds</span></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> training_loop.eval_model</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> test_model(test_generator(<span class="dv">16</span>), model)</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'The accuracy of your model on the validation set is </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">'</span>, )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[49], line 3</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># DO NOT EDIT THIS CELL</span>
<span class="ansi-green-fg ansi-bold">      2</span> <span style="font-style:italic;color:rgb(95,135,135)"># testing the accuracy of your model: this takes around 20 seconds</span>
<span class="ansi-green-fg">----&gt; 3</span> model <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">training_loop</span><span style="color:rgb(98,98,98)">.</span>eval_model
<span class="ansi-green-fg ansi-bold">      4</span> accuracy <span style="color:rgb(98,98,98)">=</span> test_model(test_generator(<span style="color:rgb(98,98,98)">16</span>), model)
<span class="ansi-green-fg ansi-bold">      6</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">The accuracy of your model on the validation set is </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>accuracy<span style="font-weight:bold;color:rgb(175,95,135)">:</span><span style="color:rgb(175,0,0)">.4f</span><span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">'</span>, )

<span class="ansi-red-fg">NameError</span>: name 'training_loop' is not defined</pre>
</div>
</div>
</div>
<section id="expected-output-approximately-2" class="level5">
<h5 class="anchored" data-anchor-id="expected-output-approximately-2">Expected Output (Approximately)</h5>
<div class="sourceCode" id="cb105"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>The accuracy of your model on the validation set is <span class="fl">0.9931</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="6" class="level1">
<h1>Part 6: Testing with your own input</h1>
<p>Finally you will test with your own input. You will see that deepnets are more powerful than the older methods you have used before. Although you go close to 100% accuracy on the first two assignments, the task was way easier.</p>
<div id="48761b60" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this is used to predict on your own sentnece</span></span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(sentence):</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> np.array(tweet_to_tensor(sentence, vocab_dict<span class="op">=</span>Vocab))</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Batch size 1, add dimension for batch, to work with the model</span></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> inputs[<span class="va">None</span>, :]  </span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict with the model</span></span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>    preds_probs <span class="op">=</span> model(inputs)</span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Turn probabilities into categories</span></span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> <span class="bu">int</span>(preds_probs[<span class="dv">0</span>, <span class="dv">1</span>] <span class="op">&gt;</span> preds_probs[<span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>    sentiment <span class="op">=</span> <span class="st">"negative"</span></span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> preds <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a>        sentiment <span class="op">=</span> <span class="st">'positive'</span></span>
<span id="cb106-17"><a href="#cb106-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-18"><a href="#cb106-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> preds, sentiment</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0a52db26" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># try a positive sentence</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>sentence <span class="op">=</span> <span class="st">"It's such a nice day, think i'll be taking Sid to Ramsgate fish and chips for lunch at Peter's fish factory and then the beach maybe"</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>tmp_pred, tmp_sentiment <span class="op">=</span> predict(sentence)</span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The sentiment of the sentence </span><span class="ch">\n</span><span class="ss">***</span><span class="ch">\n\"</span><span class="sc">{</span>sentence<span class="sc">}</span><span class="ch">\"\n</span><span class="ss">***</span><span class="ch">\n</span><span class="ss">is </span><span class="sc">{</span>tmp_sentiment<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a><span class="co"># try a negative sentence</span></span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a>sentence <span class="op">=</span> <span class="st">"I hated my day, it was the worst, I'm so sad."</span></span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>tmp_pred, tmp_sentiment <span class="op">=</span> predict(sentence)</span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The sentiment of the sentence </span><span class="ch">\n</span><span class="ss">***</span><span class="ch">\n\"</span><span class="sc">{</span>sentence<span class="sc">}</span><span class="ch">\"\n</span><span class="ss">***</span><span class="ch">\n</span><span class="ss">is </span><span class="sc">{</span>tmp_sentiment<span class="sc">}</span><span class="ss">."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TypeError</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[51], line 3</span>
<span class="ansi-green-fg ansi-bold">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># try a positive sentence</span>
<span class="ansi-green-fg ansi-bold">      2</span> sentence <span style="color:rgb(98,98,98)">=</span> <span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">It</span><span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">s such a nice day, think i</span><span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">ll be taking Sid to Ramsgate fish and chips for lunch at Peter</span><span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">s fish factory and then the beach maybe</span><span style="color:rgb(175,0,0)">"</span>
<span class="ansi-green-fg">----&gt; 3</span> tmp_pred, tmp_sentiment <span style="color:rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">predict</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">sentence</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-fg ansi-bold">      4</span> <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">The sentiment of the sentence </span><span style="font-weight:bold;color:rgb(175,95,0)">\n</span><span style="color:rgb(175,0,0)">***</span><span style="font-weight:bold;color:rgb(175,95,0)">\n</span><span style="font-weight:bold;color:rgb(175,95,0)">\"</span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>sentence<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="font-weight:bold;color:rgb(175,95,0)">\"</span><span style="font-weight:bold;color:rgb(175,95,0)">\n</span><span style="color:rgb(175,0,0)">***</span><span style="font-weight:bold;color:rgb(175,95,0)">\n</span><span style="color:rgb(175,0,0)">is </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>tmp_sentiment<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">.</span><span style="color:rgb(175,0,0)">"</span>)
<span class="ansi-green-fg ansi-bold">      6</span> <span style="color:rgb(0,135,0)">print</span>()

Cell <span class="ansi-green-fg">In[50], line 3</span>, in <span class="ansi-cyan-fg">predict</span><span class="ansi-blue-fg">(sentence)</span>
<span class="ansi-green-fg ansi-bold">      2</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span style="color:rgb(0,0,255)">predict</span>(sentence):
<span class="ansi-green-fg">----&gt; 3</span>     inputs <span style="color:rgb(98,98,98)">=</span> np<span style="color:rgb(98,98,98)">.</span>array(<span class="ansi-yellow-bg">tweet_to_tensor</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">sentence</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">vocab_dict</span><span style="color:rgb(98,98,98)" class="ansi-yellow-bg">=</span><span class="ansi-yellow-bg">Vocab</span><span class="ansi-yellow-bg">)</span>)
<span class="ansi-green-fg ansi-bold">      5</span>     <span style="font-style:italic;color:rgb(95,135,135)"># Batch size 1, add dimension for batch, to work with the model</span>
<span class="ansi-green-fg ansi-bold">      6</span>     inputs <span style="color:rgb(98,98,98)">=</span> inputs[<span style="font-weight:bold;color:rgb(0,135,0)">None</span>, :]  

Cell <span class="ansi-green-fg">In[10], line 34</span>, in <span class="ansi-cyan-fg">tweet_to_tensor</span><span class="ansi-blue-fg">(tweet, vocab_dict, unk_token, verbose)</span>
<span class="ansi-green-fg ansi-bold">     31</span>     <span style="color:rgb(0,135,0)">print</span>(<span style="color:rgb(175,0,0)">f</span><span style="color:rgb(175,0,0)">"</span><span style="color:rgb(175,0,0)">The unique integer ID for the unk_token is </span><span style="font-weight:bold;color:rgb(175,95,135)">{</span>unk_ID<span style="font-weight:bold;color:rgb(175,95,135)">}</span><span style="color:rgb(175,0,0)">"</span>)
<span class="ansi-green-fg ansi-bold">     33</span> <span style="font-style:italic;color:rgb(95,135,135)"># for each word in the list:</span>
<span class="ansi-green-fg">---&gt; 34</span> <span style="font-weight:bold;color:rgb(0,135,0)">for</span> word <span style="font-weight:bold;color:rgb(175,0,255)">in</span> word_l:
<span class="ansi-green-fg ansi-bold">     35</span>     
<span class="ansi-green-fg ansi-bold">     36</span>     <span style="font-style:italic;color:rgb(95,135,135)"># Get the unique integer ID.</span>
<span class="ansi-green-fg ansi-bold">     37</span>     <span style="font-style:italic;color:rgb(95,135,135)"># If the word doesn't exist in the vocab dictionary,</span>
<span class="ansi-green-fg ansi-bold">     38</span>     <span style="font-style:italic;color:rgb(95,135,135)"># use the unique ID for __UNK__ instead.</span>
<span class="ansi-green-fg ansi-bold">     39</span>     word_ID <span style="color:rgb(98,98,98)">=</span> <span style="font-weight:bold;color:rgb(0,135,0)">None</span>
<span class="ansi-green-fg ansi-bold">     40</span> <span style="font-style:italic;color:rgb(95,135,135)">### END CODE HERE ###</span>
<span class="ansi-green-fg ansi-bold">     41</span>     
<span class="ansi-green-fg ansi-bold">     42</span>     <span style="font-style:italic;color:rgb(95,135,135)"># Append the unique integer ID to the tensor list.</span>

<span class="ansi-red-fg">TypeError</span>: 'NoneType' object is not iterable</pre>
</div>
</div>
</div>
<p>Notice that the model works well even for complex sentences.</p>
<section id="on-deep-nets" class="level3">
<h3 class="anchored" data-anchor-id="on-deep-nets">On Deep Nets</h3>
<p>Deep nets allow you to understand and capture dependencies that you would have not been able to capture with a simple linear regression, or logistic regression.</p>
<ul>
<li>It also allows you to better use pre-trained embeddings for classification and tends to generalize better.</li>
</ul>


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2025,
  author = {Bochman, Oren},
  title = {Assignment 1: {Sentiment} with {Deep} {Neural} {Networks}},
  date = {2025-02-05},
  url = {https://orenbochman.github.io/notes-nlp/posts/c3w1/assignment.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2025. <span>“Assignment 1: Sentiment with Deep Neural
Networks.”</span> February 5, 2025. <a href="https://orenbochman.github.io/notes-nlp/posts/c3w1/assignment.html">https://orenbochman.github.io/notes-nlp/posts/c3w1/assignment.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2023-2025, Oren Bochman</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/posts/c3w1/assignment.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 💛 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"right","loop":true,"openEffect":"fade","selector":".lightbox","skin":"my-css-class"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>