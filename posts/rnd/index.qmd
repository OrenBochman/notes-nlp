---
Title: NLP RND 
Subtitle: Research Notebook on NLP
---

So I aced the course and am migrating more of the notes to this site.
I have a tendency to add more more notes. But it is probably better to 
keep most of the extra material separate.

In the intervening time there has been massive breakthroughs in NLP.
I have also learned a bit about RL. And on the advice of Richard S. Sutton
I think to create a research notebook on NLP.


## Orthogonal Action Items

1. Learning
    - [ ] Flash cards to keep everything fresh.
    - [ ] Podcasts
    - [ ] Create a small app to drill though material from all the notes repos using spaced repetition.
1. [Feynman Technique](#feynman-technique)
    - [x] Create notes on what I know about NLP. These note already cover 90%+
    - [ ] [My research questions](#sec-rq)
    - [ ] Create a list of all the areas I want to learn about.
    - [ ] Create a list of all the papers I want to read. - 
    - [ ] Create a list of all the courses I want to take.
    - [ ] Create a list of all the notebooks I want to review.
    - [ ] Create a list of all the projects I want to do.


2. Next I want to collect all the paper reviews.
4. There are some additional courses online that can be follow ups to this one
5. there are a number of notebooks from different sources that might be brought here for reference and further work.
6. I've number of ideas for Wikipedia/Wikidata related projects to try.
7. Projects around interlingual word embeddings and discourse atoms.
8. Create pure python libraries for Graph Based models (Viterbi, CYK, Earley, etc.) And better yet versions that can take advantage of GPUs SImd or Spark or Mojo


## Feynman Technique {#sec-feynman}

### Notes on stuff I know.

1. The stuff I know on search, tokenisers, baysian herircial model should be added
1. I should have some notes on Juffansky
1. I should make quick notes + podcasts on my favorite linguistics books including popular ones.
    - Juffansky
    - David Goldberg
    - Guy Deutscher ??
        - The Unfolding of Language: An Evolutionary Tour of Mankind's Greatest Invention 
            - [ ] Review
            - [ ] Podcast
        - Through the Language Glass: Why the World Looks Different in Other Languages 
            - [ ] Review
            - [ ] Podcast
    - Ornan's Morphology etc.
        - [ ] Review
        - [ ] Podcast
    - Steven Pinker - Rubs me the wrond way but is a eloquent interloqutor
        - [ ] The language instinct.
        - [ ] etc
    - James W. Pennebaker
        - Secret life of Pronouns - James W. Pennebaker

## Research Questions {#sec-rq}



- [ ]  There are now nice tutorials by Andrej Karpathy on creating GPT clones.
  - It would be interesting to some of the material in his series: at [Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
  - The tokenizers in a few notebooks c.f. [video](https://www.youtube.com/watch?v=zduSFxRajkE&ab_channel=AndrejKarpathy)

- [ ] this course is done now but I should like to get better and do follow up work and research. The best way now seems to create an online research notebook and the best way forward is to migrate the relevant material to thier own pages.

- [ ] Reformer, the efficent transformer that was covered in the course is not used in modern LLM implementations, it would be interesting to
  - [ ] understand its shortcomming based on progress made in later papers.
  - [ ] understand if one can grab the weights of some LLM, load them into a reformer and enjoy the benefits of million token context windows.