project:
  type: website
  output-dir: docs
  preview:
    port: 7780
author: "Oren Bochman"
website:
  google-analytics: "G-V0T6EFS8LY"
  open-graph: true
  # announcement: 
  #   icon: info-circle
  #   dismissable: true
  #   content: "**Alert** - Updating Papers"
  #   type: primary
  #   position: below-navbar
  title: "NLP Course Notes & Research"
  navbar:
    left:
      - href: index.qmd
        text: Home
      - about.qmd
    right:
      - about.qmd
      - icon: github
        href: https://github.com/
      - icon: twitter
        href: https://twitter.com
      - icon: rss
        href: index.xml
  site-url: https://orenbochman.github.io/notes-nlp/
  description: "Course and Research notes"
  repo-url: https://github.com/OrenBochman/notes-nlp/
  repo-actions: [edit, issue]
  #favicon: favicon.ico
  sidebar:
    #background: "#f1de67" # Arylide Yellow
    contents:
      - section: "Classification & Vector Spaces"        
        contents:                
        - section: "Logistic Regression"
          contents:  
          - href: notes/c1w1/index.qmd
            text: Notes
          - href: notes/c1w1/lab01.qmd
            text: L1 - Preprocessing
          - href: notes/c1w1/lab02.qmd
            text: L2 - Frequencies
          - href: notes/c1w1/lab03.qmd
            text: L3 - Visualizing tweets
          #- href: notes/c1w1/assignment.qmd
          #  text: A1 - Logistic Regression
        - section: "Probability & Bayes Rule"
          contents:  
          - href: notes/c1w2/index.qmd          
            text: Notes
          - href: notes/c1w2/lab01.qmd
            text: L1 - Visualizing Naive Bayes
          #- href: notes/c1w2/assignment.qmd
          #  text: A2 - Logistic Regression
        - section: "Vector Space Models & PCA"
          contents:  
          - href: notes/c1w3/index.qmd
            text: Notes
          - href: notes/c1w3/lab01.qmd
            text: L1 - Linear algebra with NumPy
          - href: notes/c1w3/lab02.qmd
            text: L2 - Manipulating word embeddings
          #- href: notes/c1w3/assignment.qmd
          #  text: A3 - Hello Vectors     
        - section: "MT & Document Search via KNN"
          contents:  
          - href: notes/c1w4/index.qmd
            text: Notes
          - href: notes/c1w3/lab01.qmd
            text: L1 - Vector manipulation
          - href: notes/c1w3/lab02.qmd
            text: L2 - Hash functions and multiplanes
          #- href: notes/c1w3/assignment.qmd
          #  text: A4 - Naive Machine Translation and LSH

      - section: "Probabilistic Models"
        contents:
        - section: "Autocorrect & Dynamic Programming"
          contents:  
          - href: notes/c2w1/index.qmd
            text: Notes
          - href: notes/c2w1/lab01.qmd
            text: L1 - Building the vocabulary
          - href: notes/c2w1/lab02.qmd
            text: L2 - Candidates from String Edits
          #- href: notes/c2w1/assignment.qmd
          #  text: A1 - Auto Correct
        - section: "POS tagging & HMMS"
          contents:  
          - href: notes/c2w2/index.qmd
            text: Notes
          - href: notes/c2w2/lab01.qmd
            text: L1 - Vocabulary with unknowns
          - href: notes/c2w2/lab02.qmd
            text: L2 - Working with tags and Numpy
          #- href: notes/c2w2/assignment.qmd
          #  text: A2 - POS tagging
        - section: "Autocomplete & Language Models"
          contents:                
          - href: notes/c2w3/index.qmd
            text: Notes
          - href: notes/c2w3/lab01.qmd
            text: L1 - N-grams Corpus preprocessing
          - href: notes/c2w3/lab02.qmd
            text: L2 - Building the language model
          - href: notes/c2w3/lab03.qmd
            text: L3 - Out of vocabulary words
          #- href: notes/c2w3/assignment.qmd
          #  text: A3 - Auto-Complete
        - section: "Word embeddings with neural networks"
          contents:              
          - href: notes/c2w4/index.qmd
            text: Notes
          - href: notes/c2w4/lab01.qmd
            text: L1 - Data preparation
          - href: notes/c2w4/lab02.qmd
            text: L2 - Intro to CBOW
          - href: notes/c2w4/lab03.qmd
            text: L3 - Training the CBOW
          #- href: notes/c2w4/assignment.qmd
          #  text: A4 - Word embeddings
      - section: "Sequence Models"
        contents:
        - section: "Neural Networks for Sentiment Analysis"
          contents:  
          - href: notes/c3w1/index.qmd
            text: Notes
          - href: notes/c3w1/lab01.qmd
            text: L1 - Introduction to Trax
          - href: notes/c3w1/lab02.qmd
            text: L2 - Classes and Subclasses
          - href: notes/c3w1/lab03.qmd
            text: L3 - Data Generators
          #- href: notes/c3w1/assignment.qmd
          #  text: A1 - Sentiment with Deep Neural Networks
        - section: "RNN for Language Modeling"
          contents:  
          - href: notes/c3w2/index.qmd
            text: Notes
          - href: notes/c3w2/lab01.qmd
            text: L1 - Hidden State Activation
          - href: notes/c3w2/lab02.qmd
            text: L2 - Calculating Perplexity
          - href: notes/c3w2/lab03.qmd
            text: L3 - Vanilla RNNs, GRUs and the scan function
          - href: notes/c3w2/lab04.qmd
            text: L4 - Creating a GRU model using Trax
          #- href: notes/c3w2/assignment.qmd
          #  text: A2 - Deep N-grams
        - section: "LSTMs and Named Entity Recognition"
          contents:  
          - href: notes/c3w3/index.qmd
            text: Notes
          - href: notes/c3w3/lab01.qmd
            text: L1 - Vanishing Gradients          
          #- href: notes/c3w3/assignment.qmd
          #  text: A3 - NER
        - section: "Siamese Networks"
          contents:  
          - href: notes/c3w4/index.qmd
            text: Notes
          - href: notes/c3w4/lab01.qmd
            text: L1 - Creating a Siamese Model using Trax
          - href: notes/c3w4/lab02.qmd
            text: L2 - Modified Triplet Loss
          - href: notes/c3w4/lab03.qmd
            text: L3 - Evaluate a Siamese Model
          #- href: notes/c3w4/assignment.qmd
          #  text: A4 - Question duplicates
      - section: "NLP with Attention Models"
        contents:
        - section: "Neural Machine Translation"
          contents:  
          - href: notes/c4w1/index.qmd
            text: Notes
          - href: notes/c4w1/lab01.qmd
            text: L1 - Stack Semantics
          - href: notes/c4w1/lab02.qmd
            text: L2 - BLEU Score
          #- href: notes/c4w1/assignment.qmd
          #  text: A4 - NMT with Attention          
        - section: "Text Summarization"
          contents:  
          - href: notes/c4w2/index.qmd
            text: Notes
          - href: notes/c4w2/lab01.qmd
            text: L1 - Attention
          - href: notes/c4w2/lab02.qmd
            text: L2 - The Transformer Decoder
          #- href: notes/c4w2/assignment.qmd
          #  text: A4 - Transformer Summarizer            
        - section: "Question Answering"
          contents:  
          - href: notes/c4w3/index.qmd
            text: Notes
          - href: notes/c4w3/lab01.qmd
            text: L1 - SentencePiece and BPE
          - href: notes/c4w3/lab02.qmd
            text: L2 - BERT Loss
          - href: notes/c4w3/lab03.qmd
            text: L3 - T5
          #- href: notes/c4w3/assignment.qmd
          #  text: A4 - Question Answering            
        - section: "Chat Bots"
          contents:  
          - href: notes/c4w4/index.qmd
            text: Notes
          - href: notes/c4w4/lab01.qmd
            text: L1 - Reformer LSH
          - href: notes/c4w4/lab02.qmd
            text: L2 - Revnet 
          #- href: notes/c4w4/assignment.qmd
          #  text: A4 - Chatbot        
      - section: "Papers"    
        contents:
        - href: reviews/paper/2014-NMT-by-jointly-learning-to-align-and-translate/
          text: NMT by Jointly Learning to Align and Translate
        - href: reviews/paper/2015-LSH/index.qmd
          text: Practical & Optimal LSH for Angular Distance
        - href: reviews/paper/2015-effective-approaches-to-attention-based-NMT/
          text: Effective Approaches to Attention-based NMT
        - href: reviews/paper/2016-coverage-embedding-models-for-NMT/index.qmd
          text: Coverage Embedding Models for NMT
        - href: reviews/paper/2016-neural-morphological-segmentation/index.qmd
          text: Neural Morphological Analysis Encoding-Decoding Canonical Segments
        - href: reviews/paper/2017-attention-is-all-you-need/index.qmd
          text: Attention is all you need
        - href: reviews/paper/2017-data-augmentation-low-resource-NMT/index.qmd
          text: Data augmentation for low-resource NMT
        - href: reviews/paper/2018-ELMo/index.qmd
          text: ELMO
        - href: reviews/paper/2018-BERT/index.qmd
          text: BERT
        - href: reviews/paper/2018-understanding-back-translation/index.qmd
          text: Understanding back translation
        - href: reviews/paper/2019-morphological-embeddings/index.qmd
          text: Morphological embeddings

  page-footer:
    right: "This page is built with ðŸ’› and [Quarto](https://quarto.org/)."
    left: "&copy; Copyright 2023-2025, Oren Bochman"
    background: "#AB0520" # AZ Red

date-format: full
date: last-modified

format:
  html:
    theme:
      light: [flatly]
      dark: [darkly]
      #light: [flatly, style/isl.scss]
      #dark: [darkly,  style/isl.scss, style/dark.scss]
    css: styles.css
    grid:
      sidebar-width: 300px
      body-width: 1600px
      margin-width: 420px
      gutter-width: 1.5rem
    toc: true
    page-layout: full
    from: "markdown+emoji"
    reference-location: margin
    citation: true
    citation-location: document
    ipynb-shell-interactivity: all 
    anchor-sections: true
    code-fold: false
    html-math-method: katex
    link-external-icon: true
    link-external-newwindow: true
    link-external-filter: '^(?:http:|https:)\/\/www\.quarto\.org\/custom'
    smooth-scroll: true
    image: images/nlp-brain-wordcloud.jpg
    #title-block-banner: images/banner_black_3.jpg
    image-placeholder: images/dnn_cover.png
    title-block-banner: images/banner_deep.jpg


bibliography: references.bib

editor: 
  markdown: 
    wrap: sentence
    #wrap: 72    

execute:
  freeze: auto
  cache: true

  # options specified here will apply to all posts in this folder

# freeze computational output
# (see https://quarto.org/docs/projects/code-execution.html#freeze)
freeze: true

# Enable banner style title blocks
title-block-banner: true
lightbox:
  match: auto
  effect: fade
  desc-position: right
  loop: true
  #css-class: "my-css-class"
crossref:
    #lof-title: "List of Figures"
    custom:
    - kind: float
      reference-prefix: Video
      key: vid
    - kind: float
      reference-prefix: Supplementary Figure
      key: sup
    - kind: float
      reference-prefix: Definition
      key: def
