---
date: 2021-05-08
title: "Reformer: The Efficient Transformer"
subtitle: "Atte"
description: 'review of the 2020 paper "Reformer The Efficient Transformer" on improving the transformer architecture for the deeplearning.ai NLP specialization.'
categories: [NLP, Paper, Attention, Deep learning, Review, Stub]
draft: true
---

![Litrature review](/images/literature-review-open-book.jpg){.column-margin}

# Reformer: The Efficient Transformer

Reformer presents some innovations which allow a more more efficient transformer.
Location sensitive hashing allows attending back to distances of 1,000,000 positions back in the sequence.

# Introduction



## The Paper

![paper](./paper.pdf){.col-page width=800px height=1000px group="slides"}



