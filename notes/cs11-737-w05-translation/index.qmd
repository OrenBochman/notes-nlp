---
date: 2022-01-24
title: "Translation and Translation Data"
subtitle: "CMU CS11-737: Multilingual NLP"
description: "This week we will cover the practice of translation, machine translation, translation evaluation metrics, translation data sources, and bi-text extraction/filtering."
categories: 
    - Attention
    - Multilingual NLP
    - NLP
    - Notes
---

![course banner](/images/tiling.png){.column-margin .nolightbox width="200px"}

::: {#vid-01 .column-margin}
{{< video https://www.youtube.com/watch?v=uDiiGWlU4K4&list=PL8PYTP1V4I8BhCpzfdKKdd1OnTfLcyZr7&index=17&ab_channel=GrahamNeubig >}}

Lesson Video
:::

::: {#sup-slide-deck .column-margin group="slides"}
![This week's slides](slides.pdf){width="420px" height="340px" style="@page {size: 16in 9in;  margin: 0;}" group="slides"}
:::

::: {.callout-note}
## Learning Objectives  {.unnumbered}

- The Practice of Translation
- Machine Translation
- Translation Evaluation Metrics
- Translation Data Sources
- Bi-text Extraction/Filtering
:::

::: {.callout-note collapse="true"}
### Transcript {.unnumbered}
<!-- Transcript here is machine generated no punctuation and I edited it a but but it needs more work and I don't see the benefits unless I can run it through some tool. -->

## Intro

> This time we're going to be talking 
less about models and more about the
actual phenomenon of translation itself
and so translation i mean i barely need
to introduce what translation is i'm
sure everybody knows but you know
basically
it's the conversion of content in one
language into content in another
language
uh
for the purpose of making that content
understandable to somebody who doesn't
know the original language of course
and that can be anything from you know
translating novels like harry potter
um to you know any other variety of
translation that happens and this time
i'm going to be talking about how this
translation happens
a little bit about machine translation
and then also about machine translation
data sources and empty evaluation

## Translation vs Interpretation

> There's actually two types of conversion of language between
uh different languages there are two
main types
one is translation another is
interpretation
and translation is basically the
conversion of written word from one
language to another
and interpretation is conversion of
spoken language from one language to
another
and
they're very different in the
requirements for them uh also how people
work and the type of type of people who
work uh in these areas
so uh translation in general is usually
less time constrained you may still have
a deadline uh for when your translation
results are required but usually it's on
the order
of you know like a day
somebody gives you a translated document
and they uh they say i want this back in
a day
whereas an interpreter
may interpret while the content is being
produced you know while i'm talking an
interpreter may be interpreting my
speech into another language that's
simultaneous interpretation
uh you can also do consecutive
interpretation which is basically like i
speak for a while then the interpreter
speaks for a while i speak for a while
interpreter speaks for a while
um translators a high degree of accuracy
and fluent very fluent natural output is
necessary
and partially because of this
uh translators
in
may translate all kinds of things but
very often they specialize in a single
area like i'm a medical translator or
i'm a patent translator or something
like that
on the other hand interpreters
may specialize in an area but more
commonly they're generalists who can
interpret lots of different things
um i actually worked as an interpreter
and translator for about a year and a
half and i did both of them because i
was kind of in a position um that was a
little bit less specialized i worked at
a local government in japan
they additionally had a single uh
translator in a single interpreter
um and
it's very interesting because uh
personalities are also very different
translators are are often somewhat
introverted uh you know they like
working on their own they really like
being precise whereas interpreters have
to be really good at talking because
they spend their whole day talking they
tend to be very extroverted
um you know uh like talking to people in
general not just interpreting between
languages so
um both of these jobs are very hard i
found interpretation harder because um
of the time pressure in the constraints
and it's not uh it's you know
you can't get 100 accuracy in a
situation where you're expected to
interpret things so you just need to do
as well as you can

## Translation Industry

> How much translation is done the
language services market
is 56.1 billion dollars that's a lot of
dollars
and there's 640 000 translators
worldwide
about 75 of them are working freelance
and the other ones are employed by a
specific uh
organization
interestingly europe owns 49 of the
market share so 49 of the people about
half the people are working in europe
um
and one interesting thing is you might
think that as machine translation
technology is getting better that was
you know threatening translators in
their jobs and you know reducing the
value of the industry
actually the con the contrary is true
um you know more translation is being
done than ever
both machine translation and human
translation and the value of the
industry is
doing nothing but improving so in a way
you know more language is being
translated now than ever
another thing is that the translation
industry is
becoming more technological so 88 of
full-time translators use some variety
of computer-aided translation which
means that they're using machine
translation they're using something like
translation memory that allows you to
look up uh other related translations
uh the most common tool is something
called Tranos uh and
uh basically it has translation memory
it has integrated empty
uh it has terminology e management
software other things like this and a
lot of translation agencies require
uh that you use Tranos in order to be
able to work with them
there's also other ones that i'm less
familiar with but basically
if you have this idea of like
human translators versus machine
translators in reality it's not the case
anymore it's now a hybrid of humans and
machines working together
um some people like this some people
don't like this some people would prefer
not to be told what to translate by
their translation memory but you know in
order to improve efficiency people now
have to do this as part of their life

### Why people don't like translation

> The reason why some people don't like translation computer aided translation
is i think they feel it stifles their
creativity or it um
because they can do it more efficiently
now the requirement is that they do do
it more efficiently so they have less
time to sit and think about the perfect
translation and just have to crank out
content basically so
i think those are the main reasons why
people are
like
resistant to technology but nonetheless
88 of people are using it so even if
they don't like it they're using it
because they you know uh have to in
order to keep up with the amount they're
expected to produce
a lot of people do like it so it's not
everybody yeah
so from the modeling type of view the
biggest difference is whether speech is
your input or text is your input
um another big difference is
interpretation sometimes you're expected
to do it in real time so that's called
simultaneous translation
so you need to create the output before
you've like read the whole document
essentially
that's a very interesting topic it might
be a topic that some people in this
class want to work on
if you like the speech you like the
translation it's a very hot topic right
now
cool
so now uh what about difficulty in
translation why is this hard
um so this is an example i i cannot read
this example i inherited it with uh from
someone else uh but it's basically a
um
an old uh chinese poem
and uh the reason why it's difficult to
translate in general is because there's
divergences in
uh lexical uh information so words in
structure
so this is an alignment of the glosses
in chinese with the words in english if
you don't know what a gloss is it's
basically a word by word translation in
the same order as the original
sentence so
um
this is uh what it looked like in
chinese unfortunately i don't have the
chinese characters above for all the
chinese speakers but you can kind of see
what it looks like
and basically if you look at the chinese
it's like daiyu alone on bed top think
uh baochai which gets translated into as
she lay there alone daiu's thoughts
turned about uh
and um
you can see that the ordering is
different between the two also um you
know some words exist in the chinese but
don't exist in the english even more so
in the next sentence so
um
you need to get the words uh right you
need to get the words in the right order
and this is that non-trivial when you
know the translations are different
between the two languages

### Translation Ease

> Here's another example from german
which might be a little bit easier to
parse if you're not a chinese speaker
so if you have um
uh
here you can see the gray gloss on top
which is in the
in city exploded uh car bomb
and the uh
the kind of canonical english
translation that's listed here is a car
bomb exploded downtown so you can see
that the word order changed
also in uh in german some things like
uh car bomb is a single word here it's
multiple words here
um there's also a phenomenon called
translation ease and what translation
eases is it's
not
exactly natural in the language you're
translating into but it's a translation
that is direct and kind of maintains the
original characteristics of the original
language
um there's actually a fair amount of
computational study of translations
seeing how
like which language you're translating
from affects the output
and you can even take translation ease
cluster it together and you get a very
nice reproduction of the language family
tree
uh that the languages came from so
basically the effects on translationese
very strongly inherit the effects
of
of the original language and even you
know are similar between similar
languages etc so you can see there's a
very clear effect and here
um in the inner city there exploded a
car bomb would be a very like literal
translation that you can understand in
english but it's also not natural
english it's not like what an english
speaker would produce

## Lexical Ambiguity

> Another issue is not just structure but
also lexical ambiguities
so
this is an example from jarefsky and
martin speech and language processing
where basically you have leg and foot
and paw
and how they are
how they are translated in different
ways based on whether it's a an animal
leg
a leg of a journey a leg of a human a
leg of a chair a bird foot or a human
foot etc etc

## Literary Translation

> I also thought i had another example but in order to handle all
these things you'll have to handle um
you know syntactic differences lexical
differences
um
how idiomatic the output is so um you
know there's lots of
issues here and then if you start
talking about literary literary
translation it becomes even harder right
you know you want to
translate a poem or something like this
as we had in the assignments uh for the
discussion today
um and suddenly you need to think about
rhyming you need to think about like
beauty of the expressions that you're
using so um lots of depth in uh doing
translation
um any questions there before i talk
about uh mt quickly yeah is there any
criteria
so um the criteria
that i would use to define translations
there might be a different formal
definition but i think this is basically
right is
it is language that only occurs because
you're translating from another language
and would not normally be
you know
how you would how a native speaker would
express the same content in that
language so it's kind of like structural
or lexical influences of the original
language of the produced language
it doesn't need to be like the effect of
translation of the output could be very
subtle um and often for a good
translator it is very subtle but it's
still
like there i have no confidence
um i'm a native speaker of english i'm
very good at japanese but i have no
confidence that i can produce english
that sounds like my natural english when
i'm transmitting to japanese for example
um any other things
okay cool
um under the machine translation so
machine translation um a checked is a
three billion dollar market
um
they're uh
oh actually i should mention that some
of the statistics i got here are from
this very very nice blog of the
translation industry in 2021 um
if you uh didn't look at this on the
page uh i would definitely take a look
it summarizes a whole bunch of
statistics and was
insightful to me as well
um these statistics are also uh from
there which is
machine translation is a three billion
dollar market now so it has about five
percent of the market share of the
language services industry overall
um the top providers of it are google
um amazon and
l
uh so google uh i think a lot of people
know
uh amazon
and aws web services uh provide
translation for a lot of businesses for
example
and uh deepel is a
startup that many people might have
heard of but it has actually very good
translation accuracy
um
they haven't revealed all of their
secrets but one of the things is that
they um use uh like cleaner training
data they have good
training data cleaning strategies and
they also consider context uh
in a better way than other things like
google do
another thing about machine translation
is these are the markets that machine
translation is used in you can see that
the most common ones
are uh healthcare automotive and
military and defense markets but it's
kind of spread out pretty widely
including e-commerce
and other things like that
um there's a very interesting uh paper
that examined the effect of translation
on e-commerce that i don't have in the
references but i can share
uh which demonstrated that when ebay i
believe introduced automatic translation
between spanish and english the number
of sales
from
uh
latin america to the us
basically started increasing immediately
after that so
uh you can see also that you know mt has
real world
consequences impact uh etc
so these are the lists this is maybe a
slightly old list of languages uh
supported by google translate uh it's
pretty impressive you know at least 100
languages maybe it's uh nearing 200 now
um one thing that i like to mention to
people uh whenever you look at this list
is just because there's a hundred
languages on this list doesn't mean that
mt is equally good for all of the
languages on this list um
you know
it may be obvious if you think about it
a little bit but sometimes you think
well you know it's on this list google
released a product for it it must work
um that's definitely not the case uh and
uh you know
if you try to use it to understand
articles you'll see a very big uh very
big difference

## Human Translators

> There are some reports that mt is now at
the level of human professionals um
in some areas like for example uh news
translation between very high resource
languages like chinese and english.
> I didn't believe this at first when
microsoft first put out an article 
that said this essentially um and
i went in and like analyzed their data
looked at their data and they actually
their outputs are quite good
and human translator outputs are not perfect
either so for example
um let's say you hire a human translator
on a freelancing site and tell them i
want you to translate these new news
articles
uh because
i would like to create training data for
a machine translation system
um if you do that the translator will
say sure i want your money um
i want your money i will i'll be happy
to do that but they're not going to be
super motivated and if you say
instead to the translator say
i'm going to be asking you to translate
these news articles for cnn
and
uh or the new york times and a hundred
thousand people are going to read your
article
you're pretty sure they're going to do a
good job right they're not going to make
a mistake so
which human translator you're trans
comparing people to also makes a big
difference in these uh these outputs and
not even just which human translator but
how motivated that human translator is
so
i have a feeling that um
mt systems and high resource languages
are almost as good as moderately
motivated good professional human
translators but they're not as good as
somebody who's translating for the new
york times for like 100 000 people for
example

## Translation

oh yeah so so sorry here are my other
examples uh this is from google
translate
um i basically put in the first uh
sorry i had animation on this until i
had to switch computers but i put in the
first
um sentence from the wikipedia article
on translation
and i'll put it through google translate
which said translation refers to the act
of replacing what is expressed in the
form of a in a language
uh with the form of b that corresponds
to that meaning uh specifically in
natural language it refers to the act of
converting a sentence in a in the source
language into a sentence in another
target language
um i did a few small edits here the the
red stuff are my edits
that i think would make it a little bit
better but it's pretty good
um
here's another example of machine
translation
i entered a lexically ambiguous word um
kodo
in japanese which can be either code
chord or chord
depending on you know the context
and it does a pretty good job at
disambiguating like electrical cord uh
code for the program chord for the on
the score
um but if i wrote as a musician i am
good at reading chords
um it made a mistake with that
in java i wrote
a chord that displays the chord of a
guitar um that should have been code up
here so you can see that it
you know is not perfect for doing this
as well
um
so
you know translation is is hard even
good things like google translate are
not perfect but they're pretty good in
high resource languages anyway
um so why do these work i'm gonna be
talking more about translation models
next class um but basically i'd like to
go through a little bit of uh you know
history into how
um
these were conceptualized
and um from 1968 there's this famous
thing called the vaqua triangle
and basically what it is saying is
there's multiple ways to do translation
um you can go from words
directly to words so you can basically
replace words by words
you can go up to the syntactic structure
of languages and then generate from the
syntactic structure you can go up to
semantics in the language convert the
semantics between the languages and go
down and you can go up to uh something
called an interlingua with lingua which
is like
universal semantics for all languages

## Direct Transfer

um so what does this look like direct
transfer looks like a word by word
translation
um so you would just be translating
directly from word words to words
syntactic transfer would be
like analyzing the syntax of the
sentence and then using that to
translate
you could also generate a syntax of the
target sentence or
translate from syntax of the source
sentence to the target sentence and
generate the output

## Semantics

You could also have something like
semantics which is a logical form which
basically says
well something was detonated what was
detonated it was a bomb

like a car bomb uh it was that
mediated downtown and that was in the
past tense
and then you generate the output based
on that

## Interlingua

You could do other things and then there's also
an interlingua which basically says
nothing about the
uh you know individual languages and
instead is completely in kind of a form
a logical form
um
so each of these methods has their own
advantages and disadvantages
um the advantage of
going directly is like let's say we have
a language like
spanish and italian which are very very
similar in words and structure and other
things like this
there you could basically do a word by
word translation and do a pretty good
job
um however if you
have very different languages
you know you're going to have a lot of
trouble
you need to have very basically a very
powerful model to allow you to do this
and uh you know before neural networks
we didn't have any model that really did
this very convincingly well

## Neural Models

> Neural models now you can kind of view them as models that map word by word they take in a whole bunch of words they generate a whole bunch of words
but you can also view them maybe as a
interlingua based model where
you know they're taking in words and
they're generating hidden vectors
they correspond to the meaning of all of
those words and then they're generating
from that you know like interlingua between the
the languages so where exactly we lie now on the spot
triangle is kind of
you know
unclear but uh
you know
it's kind of an interesting question uh
as well and you know maybe considering
syntax or other things like that would
help us generalize better in the
resource languages for example

## Data

> I realize i have a lot of slides left and i don't want to take all of the time.
> Maybe i'll just go through the data part and leave the evaluation part till
next time um
but are there any questions uh so far
okay
cool
so um i'd like to talk a little bit
about data because data is very
important for training
our um
mt models
and um
so
basically all models including you know
like google translate amazon dpel any of
the things that people are using are
using machine learning based methods
and basically the way they work is
they're trained from parallel data
sources
um where you have one language and then
another language
one language and then another language
um this is an example that you can
actually do yourself if you're
uh like interested in trying a puzzle
which is basically like take this
parallel corpus and then try to
translate this sentence at the bottom
yourself and
uh you'll see that you need to like form
associations between words you need to
understand about what the syntax of the
language looks like but it's definitely
possible from this uh this small
parallel corpus

## Parallelcorpora

> No i think these are made up
yeah i'm pretty sure
um
so where can we get parallel corpora
basically it's anywhere that translators
are doing lots of translation
um this is an example from the united
nations uh from a few days ago uh
and you can see that this is translated
into
you know three languages here it's
actually six languages uh i believe it's
the official languages of the um
um

## Languages

> another good source that we love using
for um like very low resource languages
is the bible because the bible is
translated into more languages than any
other text as far as i know

## Books

> You can also get uh books of course or other other things this is harry potter and english and chinese Restaurants
> when you go to a restaurant if you're
not chinese you can go to your favorite
chinese restaurant if you're uh chinese
you can go to your favorite
indian restaurant i don't know something
else
um and uh get the menu and that's a very
good parallel purpose for you to try
your
your own learning skills on

## Web Data

> you can also harvest data from the web
like you can harvest data from micro uh
micro blogs twitter uh social media
other things like this so um
this can give you you know more informal
language and that's why you know google
doesn't completely fall over when it
tries to translate twitter uh for
example

## Opus

> and the canonical place to get data for
any of these models now is this place
called opus
and what opus does is it collects a
whole bunch of open parallel corpora
in many many different languages
language pairs and across many domains
so if you want to train models
this is your best place to get it
um so to leave some time for the
discussion i think i'll uh move the
evaluation part to tomorrow but are
there any questions about stuff we
talked about so far
:::


## Discussion Question:

> Use Google translate to back-translate the text via a pivot language, e.g., "English → Spanish → English" or "English → L1 → L2 → English", where L1 and L2 are typologically different from English and from each other.Compare the original text and its English back-translation, and share your observations. For example, (1) what information got lost in the process of translation? (2) are there translation errors associated with linguistic properties of pivot languages and with linguistic divergences across languages?
>
> Try different pivot languages: can you provide insights about the quality of MT for those language pairs?

## Resources:

- https://redokun.com/blog/translation-statistics
