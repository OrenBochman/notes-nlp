{
  "hash": "9c6895d3333fc2611e0534aed5566563",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: 2020-10-06\ntitle: Visualizing Naive Bayes\njupyter: python3\ncategories: \n  - NLP \n  - Coursera \n  - Lab\n  - Logistic regression\n  - Sentiment analysis task\n  - Classification & Vector Spaces\n# execute: \n#     error: true\n---\n\n\n![course banner](/images/Course-Logo-1-3.webp){#fig-00 .column-margin .nolightbox}\n\nIn this lab, we will cover an essential part of data analysis that has not been included in the lecture videos. As we stated in the previous module, data visualization gives insight into the expected performance of any model. \n\nIn the following exercise, we are going to make a visual inspection of the tweets dataset using the Naïve Bayes features. We will see how we can understand the log-likelihood ratio explained in the videos as a pair of numerical features that can be fed in a machine learning algorithm. \n\nAt the end of this lab, we will introduce the concept of __confidence ellipse__ as a tool for representing the Naïve Bayes model visually.\n\n::: {#beafe23e .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np # Library for linear algebra and math utils\nimport pandas as pd # Dataframe library\n\nimport matplotlib.pyplot as plt # Library for plots\nfrom utils import confidence_ellipse # Function to add confidence ellipses to charts\n```\n:::\n\n\n ## Calculate the likelihoods for each tweet\n\nFor each tweet, we have calculated the likelihood of the tweet to be positive and the likelihood to be negative. We have calculated in different columns the numerator and denominator of the likelihood ratio introduced previously.  \n\n$$\nlog \\frac{P(tweet|pos)}{P(tweet|neg)} = log(P(tweet|pos)) - log(P(tweet|neg)) \n$$\n\n$$\npositive = log(P(tweet|pos)) = \\sum_{i=0}^{n}{log P(W_i|pos)}\n$$\n\n$$\nnegative = log(P(tweet|neg)) = \\sum_{i=0}^{n}{log P(W_i|neg)}\n$$\n\nWe did not include the code because this is part of this week's assignment.  The __'bayes_features.csv'__ file contains the final result of this process. \n\nThe cell below loads the table in a dataframe. Dataframes are data structures that simplify the manipulation of data, allowing filtering, slicing, joining, and summarization.\n\n::: {#da19cdd4 .cell execution_count=3}\n``` {.python .cell-code}\ndata = pd.read_csv('bayes_features.csv'); # Load the data from the csv file\n\ndata.head(5) # Print the first 5 tweets features. Each row represents a tweet\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>positive</th>\n      <th>negative</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-45.763393</td>\n      <td>-63.351354</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-105.491568</td>\n      <td>-114.204862</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-57.028078</td>\n      <td>-67.216467</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-10.055885</td>\n      <td>-18.589057</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-125.749270</td>\n      <td>-138.334845</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#2f9eed6d .cell execution_count=4}\n``` {.python .cell-code}\n# Plot the samples using columns 1 and 2 of the matrix\n\nfig, ax = plt.subplots(figsize = (8, 8)) #Create a new figure with a custom size\n\ncolors = ['red', 'green'] # Define a color palete\n\n# Color base on sentiment\nax.scatter(data.positive, data.negative, \n    c=[colors[int(k)] for k in data.sentiment], s = 0.1, marker='*')  # Plot a dot for each tweet\n\n# Custom limits for this chart\nplt.xlim(-250,0)\nplt.ylim(-250,0)\n\nplt.xlabel(\"Positive\") # x-axis label\nplt.ylabel(\"Negative\") # y-axis label\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nText(0.5, 0, 'Positive')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nText(0, 0.5, 'Negative')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab01_files/figure-html/cell-4-output-3.png){width=683 height=656}\n:::\n:::\n\n\n# Using Confidence Ellipses to interpret Naïve Bayes\n\nIn this section, we will use the [confidence ellipse]( https://matplotlib.org/3.1.1/gallery/statistics/confidence_ellipse.html#sphx-glr-gallery-statistics-confidence-ellipse-py) to give us an idea of what the Naïve Bayes model see.\n\nA confidence ellipse is a way to visualize a 2D random variable. It is a better way than plotting the points over a cartesian plane because, with big datasets, the points can overlap badly and hide the real distribution of the data. Confidence ellipses summarize the information of the dataset with only four parameters: \n\n* Center: It is the numerical mean of the attributes\n* Height and width: Related with the variance of each attribute. The user must specify the desired amount of standard deviations used to plot the ellipse. \n* Angle: Related with the covariance among attributes.\n\nThe parameter __n_std__ stands for the number of standard deviations bounded by the ellipse. Remember that for normal random distributions:\n\n* About 68% of the area under the curve falls within 1 standard deviation around the mean.\n* About 95% of the area under the curve falls within 2 standard deviations around the mean.\n* About 99.7% of the area under the curve falls within 3 standard deviations around the mean.\n\n[standard normal](img/st·d.jpg){width=\"400\" }\n\nIn the next chart, we will plot the data and its corresponding confidence ellipses using 2 std and 3 std. \n\n::: {#df6765cf .cell execution_count=5}\n``` {.python .cell-code}\n# Plot the samples using columns 1 and 2 of the matrix\nfig, ax = plt.subplots(figsize = (8, 8))\n\ncolors = ['red', 'green'] # Define a color palete\n\n# Color base on sentiment\n\nax.scatter(data.positive, data.negative, c=[colors[int(k)] for k in data.sentiment], s = 0.1, marker='*')  # Plot a dot for tweet\n\n# Custom limits for this chart\nplt.xlim(-200,40)  \nplt.ylim(-200,40)\n\nplt.xlabel(\"Positive\") # x-axis label\nplt.ylabel(\"Negative\") # y-axis label\n\ndata_pos = data[data.sentiment == 1] # Filter only the positive samples\ndata_neg = data[data.sentiment == 0] # Filter only the negative samples\n\n# Print confidence ellipses of 2 std\nconfidence_ellipse(data_pos.positive, data_pos.negative, ax, n_std=2, edgecolor='black', label=r'$2\\sigma$' )\nconfidence_ellipse(data_neg.positive, data_neg.negative, ax, n_std=2, edgecolor='orange')\n\n# Print confidence ellipses of 3 std\nconfidence_ellipse(data_pos.positive, data_pos.negative, ax, n_std=3, edgecolor='black', linestyle=':', label=r'$3\\sigma$')\nconfidence_ellipse(data_neg.positive, data_neg.negative, ax, n_std=3, edgecolor='orange', linestyle=':')\nax.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nText(0.5, 0, 'Positive')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nText(0, 0.5, 'Negative')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab01_files/figure-html/cell-5-output-3.png){width=679 height=651}\n:::\n:::\n\n\nIn the next cell, we will modify the features of the samples with positive sentiment (1), in a way that the two distributions overlap. In this case, the Naïve Bayes method will produce a lower accuracy than with the original data.\n\n::: {#7b5c9de0 .cell execution_count=6}\n``` {.python .cell-code}\ndata2 = data.copy() # Copy the whole data frame\n\n# The following 2 lines only modify the entries in the data frame where sentiment == 1\ndata2.negative[data.sentiment == 1] =  data2.negative * 1.5 + 50 # Modify the negative attribute\ndata2.positive[data.sentiment == 1] =  data2.positive / 1.5 - 50 # Modify the positive attribute \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/tmp/ipykernel_128077/2253601370.py:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data2.negative[data.sentiment == 1] =  data2.negative * 1.5 + 50 # Modify the negative attribute\n/tmp/ipykernel_128077/2253601370.py:5: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data2.positive[data.sentiment == 1] =  data2.positive / 1.5 - 50 # Modify the positive attribute\n```\n:::\n:::\n\n\nNow let us plot the two distributions and the confidence ellipses\n\n::: {#bd53f832 .cell execution_count=7}\n``` {.python .cell-code}\n# Plot the samples using columns 1 and 2 of the matrix\nfig, ax = plt.subplots(figsize = (8, 8))\n\ncolors = ['red', 'green'] # Define a color palete\n\n# Color base on sentiment\n\n#data.negative[data.sentiment == 1] =  data.negative * 2\n\nax.scatter(data2.positive, data2.negative, c=[colors[int(k)] for k in data2.sentiment], s = 0.1, marker='*')  # Plot a dot for tweet\n# Custom limits for this chart\nplt.xlim(-200,40)  \nplt.ylim(-200,40)\n\nplt.xlabel(\"Positive\") # x-axis label\nplt.ylabel(\"Negative\") # y-axis label\n\ndata_pos = data2[data2.sentiment == 1] # Filter only the positive samples\ndata_neg = data[data2.sentiment == 0] # Filter only the negative samples\n\n# Print confidence ellipses of 2 std\nconfidence_ellipse(data_pos.positive, data_pos.negative, ax, n_std=2, edgecolor='black', label=r'$2\\sigma$' )\nconfidence_ellipse(data_neg.positive, data_neg.negative, ax, n_std=2, edgecolor='orange')\n\n# Print confidence ellipses of 3 std\nconfidence_ellipse(data_pos.positive, data_pos.negative, ax, n_std=3, edgecolor='black', linestyle=':', label=r'$3\\sigma$')\nconfidence_ellipse(data_neg.positive, data_neg.negative, ax, n_std=3, edgecolor='orange', linestyle=':')\nax.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nText(0.5, 0, 'Positive')\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nText(0, 0.5, 'Negative')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab01_files/figure-html/cell-7-output-3.png){width=679 height=651}\n:::\n:::\n\n\nTo give away: Understanding the data allows us to predict if the method will perform well or not. Alternatively, it will allow us to understand why it worked well or bad.\n\n",
    "supporting": [
      "lab01_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}