{
  "hash": "d884931964efbc7400393c6f8d4de132",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: 2020-10-16\ntitle: 'Building the vocabulary'\njupyter: python3\ncategories: \n  - NLP \n  - Coursera \n  - Lab\n  - Logistic regression\n  - Sentiment analysis task\n  - Classification & Vector Spaces\n---\n\n\n\n\n::: {.column-margin .nolightbox}\n![course banner](/images/Course-Logo-2-3.webp)\n:::\n\nEstimated Time: 10 minutes\n\n# Vocabulary Creation \n\nCreate a tiny vocabulary from a tiny corpus\n\nIt's time to start small !\n\n### Imports and Data\n\n::: {#aecd2326 .cell execution_count=1}\n``` {.python .cell-code}\n# imports\nimport re # regular expression library; for tokenization of words\nfrom collections import Counter # collections library; counter: dict subclass for counting hashable objects\nimport matplotlib.pyplot as plt # for data visualization\n```\n:::\n\n\n::: {#f8623c1a .cell execution_count=2}\n``` {.python .cell-code}\n# the tiny corpus of text ! \ntext = 'red pink pink blue blue yellow ORANGE BLUE BLUE PINK' # ðŸŒˆ\nprint(text)\nprint('string length : ',len(text))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nred pink pink blue blue yellow ORANGE BLUE BLUE PINK\nstring length :  52\n```\n:::\n:::\n\n\n### Preprocessing\n\n::: {#ba4ce564 .cell execution_count=3}\n``` {.python .cell-code}\n# convert all letters to lower case\ntext_lowercase = text.lower()\nprint(text_lowercase)\nprint('string length : ',len(text_lowercase))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nred pink pink blue blue yellow orange blue blue pink\nstring length :  52\n```\n:::\n:::\n\n\n::: {#5a0d1801 .cell execution_count=4}\n``` {.python .cell-code}\n# some regex to tokenize the string to words and return them in a list\nwords = re.findall(r'\\w+', text_lowercase)\nprint(words)\nprint('count : ',len(words))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['red', 'pink', 'pink', 'blue', 'blue', 'yellow', 'orange', 'blue', 'blue', 'pink']\ncount :  10\n```\n:::\n:::\n\n\n### Create Vocabulary\nOption 1 : A set of distinct words from the text\n\n::: {#67b7c116 .cell execution_count=5}\n``` {.python .cell-code}\n# create vocab\nvocab = set(words)\nprint(vocab)\nprint('count : ',len(vocab))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'blue', 'red', 'yellow', 'orange', 'pink'}\ncount :  5\n```\n:::\n:::\n\n\n### Add Information with Word Counts\nOption 2 : Two alternatives for including the word count as well\n\n::: {#5c35386a .cell execution_count=6}\n``` {.python .cell-code}\n# create vocab including word count\ncounts_a = dict()\nfor w in words:\n    counts_a[w] = counts_a.get(w,0)+1\nprint(counts_a)\nprint('count : ',len(counts_a))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n{'red': 1, 'pink': 3, 'blue': 4, 'yellow': 1, 'orange': 1}\ncount :  5\n```\n:::\n:::\n\n\n::: {#831afac0 .cell execution_count=7}\n``` {.python .cell-code}\n# create vocab including word count using collections.Counter\ncounts_b = dict()\ncounts_b = Counter(words)\nprint(counts_b)\nprint('count : ',len(counts_b))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCounter({'blue': 4, 'pink': 3, 'red': 1, 'yellow': 1, 'orange': 1})\ncount :  5\n```\n:::\n:::\n\n\n::: {#4f7094d6 .cell execution_count=8}\n``` {.python .cell-code}\n# barchart of sorted word counts\nd = {'blue': counts_b['blue'], 'pink': counts_b['pink'], 'red': counts_b['red'], 'yellow': counts_b['yellow'], 'orange': counts_b['orange']}\nplt.bar(range(len(d)), list(d.values()), align='center', color=d.keys())\n_ = plt.xticks(range(len(d)), list(d.keys()))\n```\n\n::: {.cell-output .cell-output-display}\n![](lab01_files/figure-html/cell-9-output-1.png){width=571 height=411}\n:::\n:::\n\n\n### Ungraded Exercise\nNote that `counts_b`, above, returned by `collections.Counter` is sorted by word count\n\nCan we modify the tiny corpus of ***text*** so that a new color appears \nbetween ***pink*** and ***red*** in `counts_b` ?\n\nDo we need to run all the cells again, or just specific ones ? \n\n::: {#076cf570 .cell execution_count=9}\n``` {.python .cell-code}\nprint('counts_b : ', counts_b)\nprint('count : ', len(counts_b))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncounts_b :  Counter({'blue': 4, 'pink': 3, 'red': 1, 'yellow': 1, 'orange': 1})\ncount :  5\n```\n:::\n:::\n\n\nExpected Outcome:\n\ncounts_b : Counter({'blue': 4, 'pink': 3, **'your_new_color_here': 2**, red': 1, 'yellow': 1, 'orange': 1})\n<br>\ncount :  6\n\n### Summary\n\nThis is a tiny example but the methodology scales very well.\n<br>\nIn the assignment we will create a large vocabulary of thousands of words, from a corpus\n<br>\nof tens of thousands or words! But the mechanics are exactly the same. \n<br> \nThe only extra things to pay attention to should be; run time, memory management and the vocab data structure.\n<br> \nSo the choice of approach used in code blocks `counts_a` vs `counts_b`, above, will be important.\n\n",
    "supporting": [
      "lab01_files"
    ],
    "filters": [],
    "includes": {}
  }
}