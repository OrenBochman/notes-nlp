{
  "hash": "4d5e3be7c474d038fec5ff4368d0d6d7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Candidates from String Edits'\njupyter: python3\ncategories: \n  - NLP \n  - Coursera \n  - Lab\n  - Logistic regression\n  - Sentiment analysis task\n  - Classification & Vector Spaces\n---\n\n\n\n\n::: {#fig-00 .column-margin .nolightbox}\n![course banner](/images/Course-Logo-2-3.webp)\n:::\n\nEstimated Time: 20 minutes\n\n\nCreate a list of candidate strings by applying an edit operation\n\n### Imports and Data\n\n::: {#9d2d5249 .cell execution_count=2}\n``` {.python .cell-code}\n# data\nword = 'dearz' # ðŸ¦Œ\n```\n:::\n\n\n### Splits\n\nFind all the ways we can split a word into 2 parts !\n\n::: {#d5375973 .cell execution_count=3}\n``` {.python .cell-code}\n# splits with a loop\nsplits_a = []\nfor i in range(len(word)+1):\n    splits_a.append([word[:i],word[i:]])\n\nfor i in splits_a:\n    print(i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['', 'dearz']\n['d', 'earz']\n['de', 'arz']\n['dea', 'rz']\n['dear', 'z']\n['dearz', '']\n```\n:::\n:::\n\n\n::: {#c7f00f40 .cell execution_count=4}\n``` {.python .cell-code}\n# same splits, done using a list comprehension\nsplits_b = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n\nfor i in splits_b:\n    print(i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n('', 'dearz')\n('d', 'earz')\n('de', 'arz')\n('dea', 'rz')\n('dear', 'z')\n('dearz', '')\n```\n:::\n:::\n\n\n### Delete Edit\n\nDelete a letter from each string in the `splits` list.\n\n\nWhat this does is effectivly delete each possible letter from the original word being edited. \n\n::: {#a588f51e .cell execution_count=5}\n``` {.python .cell-code}\n# deletes with a loop\nsplits = splits_a\ndeletes = []\n\nprint('word : ', word)\nfor L,R in splits:\n    if R:\n        print(L + R[1:], ' <-- delete ', R[0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nword :  dearz\nearz  <-- delete  d\ndarz  <-- delete  e\nderz  <-- delete  a\ndeaz  <-- delete  r\ndear  <-- delete  z\n```\n:::\n:::\n\n\nIt's worth taking a closer look at how this is excecuting a 'delete'.\n\n\nTaking the first item from the `splits` list :\n\n::: {#354a589c .cell execution_count=6}\n``` {.python .cell-code}\n# breaking it down\nprint('word : ', word)\none_split = splits[0]\nprint('first item from the splits list : ', one_split)\nL = one_split[0]\nR = one_split[1]\nprint('L : ', L)\nprint('R : ', R)\nprint('*** now implicit delete by excluding the leading letter ***')\nprint('L + R[1:] : ',L + R[1:], ' <-- delete ', R[0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nword :  dearz\nfirst item from the splits list :  ['', 'dearz']\nL :  \nR :  dearz\n*** now implicit delete by excluding the leading letter ***\nL + R[1:] :  earz  <-- delete  d\n```\n:::\n:::\n\n\nSo the end result transforms **'dearz'** to **'earz'** by deleting the first character.\n\n\nAnd we use a **loop** (code block above) or a **list comprehension** (code block below) to do this for the entire `splits` list.\n\n::: {#d1d93258 .cell execution_count=7}\n``` {.python .cell-code}\n# deletes with a list comprehension\nsplits = splits_a\ndeletes = [L + R[1:] for L, R in splits if R]\n\nprint(deletes)\nprint('*** which is the same as ***')\nfor i in deletes:\n    print(i)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['earz', 'darz', 'derz', 'deaz', 'dear']\n*** which is the same as ***\nearz\ndarz\nderz\ndeaz\ndear\n```\n:::\n:::\n\n\n### Ungraded Exercise\nWe now have a list of ***candidate strings*** created after performing a **delete** edit.\n<br>\nNext step will be to filter this list for ***candidate words*** found in a vocabulary.\n<br>\nGiven the example vocab below, can we think of a way to create a list of candidate words ? \n<br>\nRemember, we already have a list of candidate strings, some of which are certainly not actual words we might find in your vocabulary !\n<br>\n<br>\nSo from the above list **earz, darz, derz, deaz, dear**. \n<br>\nYou're really only interested in **dear**.\n\n::: {#3de94eb9 .cell execution_count=8}\n``` {.python .cell-code}\nvocab = ['dean','deer','dear','fries','and','coke']\nedits = list(deletes)\n\nprint('vocab : ', vocab)\nprint('edits : ', edits)\n\ncandidates=[]\n\n### START CODE HERE ###\ncandidates = set(vocab).intersection(edits)  # hint: 'set.intersection'\n### END CODE HERE ###\n\nprint('candidate words : ', candidates)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nvocab :  ['dean', 'deer', 'dear', 'fries', 'and', 'coke']\nedits :  ['earz', 'darz', 'derz', 'deaz', 'dear']\ncandidate words :  {'dear'}\n```\n:::\n:::\n\n\nExpected Outcome:\n\nvocab :  ['dean', 'deer', 'dear', 'fries', 'and', 'coke']\n\nedits :  ['earz', 'darz', 'derz', 'deaz', 'dear']\n\n\ncandidate words :  {'dear'}\n\n### Summary\nYou've unpacked an integral part of the assignment by breaking down **splits** and **edits**, specifically looking at **deletes** here.\n\n\nImplementation of the other edit types (insert, replace, switch) follows a similar methodology and should now feel somewhat familiar when we see them.\n\n\n\nThis bit of the code isn't as intuitive as other sections, so well done!\n\n\nWe should now feel confident facing some of the more technical parts of the assignment at the end of the week.\n\n",
    "supporting": [
      "lab02_files"
    ],
    "filters": [],
    "includes": {}
  }
}