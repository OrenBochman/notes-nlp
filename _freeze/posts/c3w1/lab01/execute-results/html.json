{
  "hash": "e44643f09805cc6017a78343eac58557",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ndate: 2020-10-24\ntitle: 'Trax : Ungraded Lecture Notebook'\nsubtitle: \"Sequence Models\"\n#description: \"we cover Neural networks for deep learning, then build a tweet classifier that places tweets into positive or negative sentiment categories, using a DNN.\"\ncategories: \n  - NLP \n  - Coursera \n  - Lab\n  - Sequence Models\njupyter:\n  jupytext:\n    encoding: '# -*- coding: utf-8 -*-'\n    formats: ipynb,py:percent\n    main_language: python\n  kernelspec:\n    display_name: Python 3\n    language: python\n    name: python3\n---\n\n\n\n\n![course banner](/images/Course-Logo-3-3.webp){.column-margin .nolightbox} \n\nIn this notebook you'll get to know about the Trax framework and learn about some of its basic building blocks.\n\n## Background\n\n### Why Trax and not TensorFlow or PyTorch?\n\n`TensorFlow` and `PyTorch` are both extensive frameworks that can do almost anything in deep learning. They offer a lot of flexibility, but that often means verbosity of syntax and extra time to code.\n\n`Trax` is much more concise. It runs on a TensorFlow backend but allows you to train models with 1 line commands. `Trax` also runs end to end, allowing you to get data, model and train all with a single terse statements. This means you can focus on learning, instead of spending hours on the idiosyncrasies of big framework implementation.\n\n### Why not Keras then?\n\n`Keras` is now part of `Tensorflow` itself from 2.0 onwards. Also, `Trax` is good for implementing new state of the art algorithms like Transformers, Reformers, BERT because it is actively maintained by Google Brain Team for advanced deep learning tasks. It runs smoothly on CPUs, GPUs and TPUs as well with comparatively lesser modifications in code.\n\n### How to Code in Trax\n\nBuilding models in `Trax `relies on 2 key concepts:\n\n- **layers** and \n- **combinators**.\n\nTrax layers are simple objects that process data and perform computations. They can be chained together into composite layers using Trax combinators, allowing you to build layers and models of any complexity.\n\n### Trax, JAX, TensorFlow and Tensor2Tensor\n\nYou already know that `Trax` uses `Tensorflow` as a backend, but it also uses the `JAX` library to speed up computation too. You can view `JAX` as an enhanced and optimized version of numpy. \n\n**Watch out for assignments which import `import trax.fastmath.numpy as np`. If you see this line, remember that when calling `np` you are really calling Traxâ€™s version of numpy that is compatible with JAX.**\n\nAs a result of this, where you used to encounter the type `numpy.ndarray` now you will find the type `jax.interpreters.xla.DeviceArray`.\n\nTensor2Tensor is another name you might have heard. It started as an end to end solution much like how Trax is designed, but it grew unwieldy and complicated. So you can view Trax as the new improved version that operates much faster and simpler.\n\n### Resources\n\n- Trax source code can be found on Github: [Trax](https://github.com/google/trax)\n- JAX library: [JAX](https://jax.readthedocs.io/en/latest/index.html)\n\n## Installing Trax\n\nTrax has dependencies on JAX and some libraries like JAX which are yet to be supported in [Windows](https://github.com/google/jax/blob/1bc5896ee4eab5d7bb4ec6f161d8b2abb30557be/README.md#installation) but work well in Ubuntu and MacOS. We would suggest that if you are working on Windows, try to install Trax on WSL2. \n\nOfficial maintained documentation - [trax-ml](https://trax-ml.readthedocs.io/en/latest/) not to be confused with this [TraX](https://trax.readthedocs.io/en/latest/index.html)\n\n::: {#fcb0aaec .cell execution_count=2}\n``` {.python .cell-code}\n#!pip install trax==1.3.1 Use this version for this notebook \n```\n:::\n\n\n## Imports\n\n::: {#48e9356a .cell tags='[]' execution_count=3}\n``` {.python .cell-code}\nimport numpy as np  # regular ol' numpy\n\nfrom trax import layers as tl  # core building block\nfrom trax import shapes  # data signatures: dimensionality and type\nfrom trax import fastmath  # uses jax, offers numpy on steroids\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2025-02-05 15:33:48.710339: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1738762428.771770  458013 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1738762428.791235  458013 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n```\n:::\n:::\n\n\n::: {#16d711e8 .cell tags='[]' execution_count=4}\n``` {.python .cell-code}\n# Trax version 1.3.1 or better \n!pip list | grep trax\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntrax                         1.4.1\r\n```\n:::\n:::\n\n\n## Layers\n\nLayers are the core building blocks in Trax or as mentioned in the lectures, they are the base classes.\n\nThey take inputs, compute functions/custom calculations and return outputs.\n\nYou can also inspect layer properties. Let me show you some examples.\n\n### Relu Layer\n\nFirst I'll show you how to build a relu activation function as a layer. A layer like this is one of the simplest types. Notice there is no object initialization so it works just like a math function.\n\n**Note: Activation functions are also layers in Trax, which might look odd if you have been using other frameworks for a longer time.**\n\n::: {#7a5beca0 .cell tags='[]' execution_count=5}\n``` {.python .cell-code}\n# Layers\n# Create a relu trax layer\nrelu = tl.Relu()\n\n# Inspect properties\nprint(\"-- Properties --\")\nprint(\"name :\", relu.name)\nprint(\"expected inputs :\", relu.n_in)\nprint(\"promised outputs :\", relu.n_out, \"\\n\")\n\n# Inputs\nx = np.array([-2, -1, 0, 1, 2])\nprint(\"-- Inputs --\")\nprint(\"x :\", x, \"\\n\")\n\n# Outputs\ny = relu(x)\nprint(\"-- Outputs --\")\nprint(\"y :\", y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-- Properties --\nname : Serial\nexpected inputs : 1\npromised outputs : 1 \n\n-- Inputs --\nx : [-2 -1  0  1  2] \n\n-- Outputs --\ny : [0 0 0 1 2]\n```\n:::\n:::\n\n\n### Concatenate Layer\n\nNow I'll show you how to build a layer that takes 2 inputs. Notice the change in the expected inputs property from 1 to 2.\n\n::: {#ed137c2c .cell tags='[]' execution_count=6}\n``` {.python .cell-code}\n# Create a concatenate trax layer\nconcat = tl.Concatenate()\nprint(\"-- Properties --\")\nprint(\"name :\", concat.name)\nprint(\"expected inputs :\", concat.n_in)\nprint(\"promised outputs :\", concat.n_out, \"\\n\")\n\n# Inputs\nx1 = np.array([-10, -20, -30])\nx2 = x1 / -10\nprint(\"-- Inputs --\")\nprint(\"x1 :\", x1)\nprint(\"x2 :\", x2, \"\\n\")\n\n# Outputs\ny = concat([x1, x2])\nprint(\"-- Outputs --\")\nprint(\"y :\", y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-- Properties --\nname : Concatenate\nexpected inputs : 2\npromised outputs : 1 \n\n-- Inputs --\nx1 : [-10 -20 -30]\nx2 : [1. 2. 3.] \n\n-- Outputs --\ny : [-10. -20. -30.   1.   2.   3.]\n```\n:::\n:::\n\n\n## Layers are Configurable\n\nYou can change the default settings of layers. For example, you can change the expected inputs for a concatenate layer from 2 to 3 using the optional parameter `n_items`.\n\n::: {#93bf3a48 .cell tags='[]' execution_count=7}\n``` {.python .cell-code}\n# Configure a concatenate layer\nconcat_3 = tl.Concatenate(n_items=3)  # configure the layer's expected inputs\nprint(\"-- Properties --\")\nprint(\"name :\", concat_3.name)\nprint(\"expected inputs :\", concat_3.n_in)\nprint(\"promised outputs :\", concat_3.n_out, \"\\n\")\n\n# Inputs\nx1 = np.array([-10, -20, -30])\nx2 = x1 / -10\nx3 = x2 * 0.99\nprint(\"-- Inputs --\")\nprint(\"x1 :\", x1)\nprint(\"x2 :\", x2)\nprint(\"x3 :\", x3, \"\\n\")\n\n# Outputs\ny = concat_3([x1, x2, x3])\nprint(\"-- Outputs --\")\nprint(\"y :\", y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-- Properties --\nname : Concatenate\nexpected inputs : 3\npromised outputs : 1 \n\n-- Inputs --\nx1 : [-10 -20 -30]\nx2 : [1. 2. 3.]\nx3 : [0.99 1.98 2.97] \n\n-- Outputs --\ny : [-10.   -20.   -30.     1.     2.     3.     0.99   1.98   2.97]\n```\n:::\n:::\n\n\n**Note: At any point,if you want to refer the function help/ look up the [documentation](https://trax-ml.readthedocs.io/en/latest/) or use help function.**\n\n::: {#9a056bf4 .cell execution_count=8}\n``` {.python .cell-code}\n#help(tl.Concatenate) #Uncomment this to see the function docstring with explaination\n```\n:::\n\n\n## Layers can have Weights\nSome layer types include mutable weights and biases that are used in computation and training. Layers of this type require initialization before use.\n\nFor example the `LayerNorm` layer calculates normalized data, that is also scaled by weights and biases. During initialization you pass the data shape and data type of the inputs, so the layer can initialize compatible arrays of weights and biases.\n\n::: {#49f76633 .cell execution_count=9}\n``` {.python .cell-code}\n# Uncomment any of them to see information regarding the function\n# help(tl.LayerNorm)\n# help(shapes.signature)\n```\n:::\n\n\n::: {#e1597a55 .cell tags='[]' execution_count=10}\n``` {.python .cell-code}\n# Layer initialization\nnorm = tl.LayerNorm()\n# You first must know what the input data will look like\nx = np.array([0, 1, 2, 3], dtype=\"float\")\n\n# Use the input data signature to get shape and type for initializing weights and biases\nnorm.init(shapes.signature(x)) # We need to convert the input datatype from usual tuple to trax ShapeDtype\n\nprint(\"Normal shape:\",x.shape, \"Data Type:\",type(x.shape))\nprint(\"Shapes Trax:\",shapes.signature(x),\"Data Type:\",type(shapes.signature(x)))\n\n# Inspect properties\nprint(\"-- Properties --\")\nprint(\"name :\", norm.name)\nprint(\"expected inputs :\", norm.n_in)\nprint(\"promised outputs :\", norm.n_out)\n# Weights and biases\nprint(\"weights :\", norm.weights[0])\nprint(\"biases :\", norm.weights[1], \"\\n\")\n\n# Inputs\nprint(\"-- Inputs --\")\nprint(\"x :\", x)\n\n# Outputs\ny = norm(x)\nprint(\"-- Outputs --\")\nprint(\"y :\", y)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/normalization.py:141: UserWarning: Explicitly requested dtype float64 requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n  scale = jnp.ones(features, dtype=input_signature.dtype)\n/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/normalization.py:142: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n  bias = jnp.zeros(features, dtype=input_signature.dtype)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n((Array([1., 1., 1., 1.], dtype=float32),\n  Array([0., 0., 0., 0.], dtype=float32)),\n ())\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNormal shape: (4,) Data Type: <class 'tuple'>\nShapes Trax: ShapeDtype{shape:(4,), dtype:float64} Data Type: <class 'trax.shapes.ShapeDtype'>\n-- Properties --\nname : LayerNorm\nexpected inputs : 1\npromised outputs : 1\nweights : [1. 1. 1. 1.]\nbiases : [0. 0. 0. 0.] \n\n-- Inputs --\nx : [0. 1. 2. 3.]\n-- Outputs --\ny : [-1.3416404  -0.44721344  0.44721344  1.3416404 ]\n```\n:::\n:::\n\n\n## Custom Layers\n\nThis is where things start getting more interesting!\nYou can create your own custom layers too and define custom functions for computations by using `tl.Fn`. Let me show you how.\n\n::: {#6d4188d5 .cell execution_count=11}\n``` {.python .cell-code}\nhelp(tl.Fn)\n```\n\n::: {.cell-output .cell-output-stdout}\n``````````\nHelp on function Fn in module trax.layers.base:\n\nFn(name, f, n_out=1)\n    Returns a layer with no weights that applies the function `f`.\n    \n    `f` can take and return any number of arguments, and takes only positional\n    arguments -- no default or keyword arguments. It often uses JAX-numpy (`jnp`).\n    The following, for example, would create a layer that takes two inputs and\n    returns two outputs -- element-wise sums and maxima:\n    \n        `Fn('SumAndMax', lambda x0, x1: (x0 + x1, jnp.maximum(x0, x1)), n_out=2)`\n    \n    The layer's number of inputs (`n_in`) is automatically set to number of\n    positional arguments in `f`, but you must explicitly set the number of\n    outputs (`n_out`) whenever it's not the default value 1.\n    \n    Args:\n      name: Class-like name for the resulting layer; for use in debugging.\n      f: Pure function from input tensors to output tensors, where each input\n          tensor is a separate positional arg, e.g., `f(x0, x1) --> x0 + x1`.\n          Output tensors must be packaged as specified in the `Layer` class\n          docstring.\n      n_out: Number of outputs promised by the layer; default value 1.\n    \n    Returns:\n      Layer executing the function `f`.\n\n``````````\n:::\n:::\n\n\n::: {#c9d75ca0 .cell tags='[]' execution_count=12}\n``` {.python .cell-code}\n# Define a custom layer\n# In this example you will create a layer to calculate the input times 2\n\ndef TimesTwo():\n    layer_name = \"TimesTwo\" #don't forget to give your custom layer a name to identify\n\n    # Custom function for the custom layer\n    def func(x):\n        return x * 2\n\n    return tl.Fn(layer_name, func)\n\n\n# Test it\ntimes_two = TimesTwo()\n\n# Inspect properties\nprint(\"-- Properties --\")\nprint(\"name :\", times_two.name)\nprint(\"expected inputs :\", times_two.n_in)\nprint(\"promised outputs :\", times_two.n_out, \"\\n\")\n\n# Inputs\nx = np.array([1, 2, 3])\nprint(\"-- Inputs --\")\nprint(\"x :\", x, \"\\n\")\n\n# Outputs\ny = times_two(x)\nprint(\"-- Outputs --\")\nprint(\"y :\", y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-- Properties --\nname : TimesTwo\nexpected inputs : 1\npromised outputs : 1 \n\n-- Inputs --\nx : [1 2 3] \n\n-- Outputs --\ny : [2 4 6]\n```\n:::\n:::\n\n\n## Combinators\n\nYou can combine layers to build more complex layers. Trax provides a set of objects named combinator layers to make this happen. Combinators are themselves layers, so behavior commutes.\n\n\n### Serial Combinator\n\nThis is the most common and easiest to use. For example could build a simple neural network by combining layers into a single layer using the `Serial` combinator. This new layer then acts just like a single layer, so you can inspect intputs, outputs and weights. Or even combine it into another layer! Combinators can then be used as trainable models. _Try adding more layers_\n\n**Note:As you must have guessed, if there is serial combinator, there must be a parallel combinator as well. Do try to explore about combinators and other layers from the trax documentation and look at the repo to understand how these layers are written.**\n\n::: {#b553fe04 .cell execution_count=13}\n``` {.python .cell-code}\n# help(tl.Serial)\n# help(tl.Parallel)\n```\n:::\n\n\n::: {#91f78f7a .cell tags='[]' execution_count=14}\n``` {.python .cell-code}\n# Serial combinator\nserial = tl.Serial(\n    tl.LayerNorm(),         # normalize input\n    tl.Relu(),              # convert negative values to zero\n    times_two,              # the custom layer you created above, multiplies the input recieved from above by 2\n    \n    ### START CODE HERE\n#     tl.Dense(n_units=2),  # try adding more layers. eg uncomment these lines\n#     tl.Dense(n_units=1),  # Binary classification, maybe? uncomment at your own peril\n#     tl.LogSoftmax()       # Yes, LogSoftmax is also a layer\n    ### END CODE HERE\n)\n\n# Initialization\nx = np.array([-2, -1, 0, 1, 2]) #input\nserial.init(shapes.signature(x)) #initialising serial instance\n\nprint(\"-- Serial Model --\")\nprint(serial,\"\\n\")\nprint(\"-- Properties --\")\nprint(\"name :\", serial.name)\nprint(\"sublayers :\", serial.sublayers)\nprint(\"expected inputs :\", serial.n_in)\nprint(\"promised outputs :\", serial.n_out)\nprint(\"weights & biases:\", serial.weights, \"\\n\")\n\n# Inputs\nprint(\"-- Inputs --\")\nprint(\"x :\", x, \"\\n\")\n\n# Outputs\ny = serial(x)\nprint(\"-- Outputs --\")\nprint(\"y :\", y)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/normalization.py:141: UserWarning: Explicitly requested dtype int64 requested in ones is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n  scale = jnp.ones(features, dtype=input_signature.dtype)\n/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/normalization.py:142: UserWarning: Explicitly requested dtype int64 requested in zeros is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n  bias = jnp.zeros(features, dtype=input_signature.dtype)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n(((Array([1, 1, 1, 1, 1], dtype=int32), Array([0, 0, 0, 0, 0], dtype=int32)),\n  ((), (), ()),\n  ()),\n ((), ((), (), ()), ()))\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n-- Serial Model --\nSerial[\n  LayerNorm\n  Serial[\n    Relu\n  ]\n  TimesTwo\n] \n\n-- Properties --\nname : Serial\nsublayers : [LayerNorm, Serial[\n  Relu\n], TimesTwo]\nexpected inputs : 1\npromised outputs : 1\nweights & biases: ((Array([1, 1, 1, 1, 1], dtype=int32), Array([0, 0, 0, 0, 0], dtype=int32)), ((), (), ()), ()) \n\n-- Inputs --\nx : [-2 -1  0  1  2] \n\n-- Outputs --\ny : [0.        0.        0.        1.4142132 2.8284264]\n```\n:::\n:::\n\n\n## JAX\n\nJust remember to lookout for which numpy you are using, the regular ol' numpy or Trax's JAX compatible numpy. Both tend to use the alias np so watch those import blocks.\n\n**Note:There are certain things which are still not possible in fastmath.numpy which can be done in numpy so you will see in assignments we will switch between them to get our work done.**\n\n::: {#b3c82aac .cell tags='[]' execution_count=15}\n``` {.python .cell-code}\n# Numpy vs fastmath.numpy have different data types\n# Regular ol' numpy\nx_numpy = np.array([1, 2, 3])\nprint(\"good old numpy : \", type(x_numpy), \"\\n\")\n\n# Fastmath and jax numpy\nx_jax = fastmath.numpy.array([1, 2, 3])\nprint(\"jax trax numpy : \", type(x_jax))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ngood old numpy :  <class 'numpy.ndarray'> \n\njax trax numpy :  <class 'jaxlib.xla_extension.ArrayImpl'>\n```\n:::\n:::\n\n\n## Summary\n\nTrax is a concise framework, built on TensorFlow, for end to end machine learning. The key building blocks are layers and combinators. This notebook is just a taste, but sets you up with some key inuitions to take forward into the rest of the course and assignments where you will build end to end models.\n\n",
    "supporting": [
      "lab01_files"
    ],
    "filters": [],
    "includes": {}
  }
}