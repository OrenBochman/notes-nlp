{
  "hash": "2b485324de3bb63e3972e1a869b76040",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Assignment 3: Question Answering'\nsubtitle: \"NLP with Attention Models\"\ncategories: \n  - NLP \n  - Coursera \n  - Lab\n  - NLP with Attention Models\njupyter: python3\nexecute: \n    error: true\n---\n\n\n![course banner](/images/Course-Logo-4-1.webp){.column-margin .nolightbox}\n\n::: {.callout}\n## Honor code alert\n\nDue to the Coursera Honor Code, I cannot provide the solutions to the assignments. \n\n- This notebook is the original notebook provided by the course\n- It is setup to run without stopping for errors. \n- It is also likely to be out of date as the course has had some updates since I took it.\n- Although I aced the course this assignment was the most time consuming.\n- Good luck with the assignment it should make we a better programmer.\n- It is also a good idea to go over it a few times until we can do it easily.\n:::\n\n\nWelcome to this week's assignment of course 4. In this you will explore question answering. You will implement the \"Text to Text Transfer from Transformers\" (better known as T5). Since you implemented transformers from scratch last week you will now be able to use them. \n\n![Q&A](img/qa.png)\n\n## Outline\n\n- [Overview](#0)\n- [Part 0: Importing the Packages](#01)\n- [Part 1: C4 Dataset](#1)\n    - [1.1 Pre-Training Objective](#1.1)\n    - [1.2 Process C4](#1.2)\n        - [1.2.1 Decode to natural language](#1.2.1)\n    - [1.3 Tokenizing and Masking](#1.3)\n        - [Exercise 01](#ex01)\n    - [1.4 Creating the Pairs](#1.4)\n- [Part 2: Transformer](#2)\n    - [2.1 Transformer Encoder](#2.1)\n        - [2.1.1 The Feedforward Block](#2.1.1)\n            - [Exercise 02](#ex02)\n        - [2.1.2 The Encoder Block](#2.1.2)\n            - [Exercise 03](#ex03)\n        - [2.1.3 The Transformer Encoder](#2.1.3)            \n            - [Exercise 04](#ex04)\n\n### Overview {#0}\n\nThis assignment will be different from the two previous ones. Due to memory and time constraints of this environment you will not be able to train a model and use it for inference. Instead you will create the necessary building blocks for the transformer encoder model and will use a pretrained version of the same model in two ungraded labs after this assignment.\n\nAfter completing these 3 (1 graded and 2 ungraded) labs you will:\n* Implement the code necessary for Bidirectional Encoder Representation from Transformer (BERT).\n* Understand how the C4 dataset is structured.\n* Use a pretrained model for inference.\n* Understand how the \"Text to Text Transfer from Transformers\" or T5 model works. \n\n\n## Part 0: Importing the Packages {#01}\n\n::: {#7ab5b9e4 .cell execution_count=2}\n``` {.python .cell-code}\nimport ast\nimport string\nimport textwrap\nimport itertools\nimport numpy as np\n\nimport trax \nfrom trax import layers as tl\nfrom trax.supervised import decoding\n\n# Will come handy later.\nwrapper = textwrap.TextWrapper(width=70)\n\n# Set random seed\nnp.random.seed(42)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2025-02-07 10:42:57.851714: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1738917777.865628   47593 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1738917777.870007   47593 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n```\n:::\n:::\n\n\n## Part 1: C4 Dataset {#1}\n\nThe [C4](https://www.tensorflow.org/datasets/catalog/c4) is a huge data set. For the purpose of this assignment you will use a few examples out of it which are present in `data.txt`. C4 is based on the [common crawl](https://commoncrawl.org/) project. Feel free to read more on their website. \n\nRun the cell below to see how the examples look like. \n\n::: {#90a172a6 .cell execution_count=3}\n``` {.python .cell-code}\n# load example jsons\nexample_jsons = list(map(ast.literal_eval, open('data.txt')))\n\n# Printing the examples to see how the data looks like\nfor i in range(5):\n    print(f'example number {i+1}: \\n\\n{example_jsons[i]} \\n')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nexample number 1: \n\n{'content-length': b'1970', 'content-type': b'text/plain', 'text': b'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.', 'timestamp': b'2019-04-25T12:57:54Z', 'url': b'https://klyq.com/beginners-bbq-class-taking-place-in-missoula/'} \n\nexample number 2: \n\n{'content-length': b'12064', 'content-type': b'text/plain', 'text': b'Discussion in \\'Mac OS X Lion (10.7)\\' started by axboi87, Jan 20, 2012.\\nI\\'ve got a 500gb internal drive and a 240gb SSD.\\nWhen trying to restore using disk utility i\\'m given the error \"Not enough space on disk ____ to restore\"\\nBut I shouldn\\'t have to do that!!!\\nAny ideas or workarounds before resorting to the above?\\nUse Carbon Copy Cloner to copy one drive to the other. I\\'ve done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won\\'t be bootable. CCC usually works in \"file mode\" and it can easily copy a larger drive (that\\'s mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\\nI\\'ve actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn\\'t fit is there was slightly more than 4 GB of data.', 'timestamp': b'2019-04-21T10:07:13Z', 'url': b'https://forums.macrumors.com/threads/restore-from-larger-disk-to-smaller-disk.1311329/'} \n\nexample number 3: \n\n{'content-length': b'5235', 'content-type': b'text/plain', 'text': b'Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.', 'timestamp': b'2019-04-25T10:40:23Z', 'url': b'https://awishcometrue.com/Catalogs/Clearance/Tweens/V1960-Find-A-Way'} \n\nexample number 4: \n\n{'content-length': b'4967', 'content-type': b'text/plain', 'text': b\"How many backlinks per day for new site?\\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\\n2) how long do I have to let my site age before I can start making more blinks?\\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have?\", 'timestamp': b'2019-04-21T12:46:19Z', 'url': b'https://www.blackhatworld.com/seo/how-many-backlinks-per-day-for-new-site.258615/'} \n\nexample number 5: \n\n{'content-length': b'4499', 'content-type': b'text/plain', 'text': b'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what\\xe2\\x80\\x99s included in the mill levy measure.', 'timestamp': b'2019-04-20T14:33:21Z', 'url': b'http://bond.dpsk12.org/category/news/'} \n\n```\n:::\n:::\n\n\nNotice the `b` before each string? This means that this data comes as bytes rather than strings. Strings are actually lists of bytes so for the rest of the assignments the name `strings` will be used to describe the data. \n\nTo check this run the following cell:\n\n::: {#34f222e7 .cell execution_count=4}\n``` {.python .cell-code}\ntype(example_jsons[0].get('text'))\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nbytes\n```\n:::\n:::\n\n\n###  1.1 Pre-Training Objective {#1.1}\n\n**Note:** The word \"mask\" will be used throughout this assignment in context of hiding/removing word(s)\n\nYou will be implementing the BERT loss as shown in the following image. \n\n![loss](img/loss.png){width=\"600\" height=\"400\"}\n\nAssume you have the following text: <span style = \"color:blue\"> **Thank you <span style = \"color:red\">for inviting </span> me to your party <span style = \"color:red\">last</span>  week** </span> \n\n\nNow as input you will mask the words in red in the text: \n\n<span style = \"color:blue\"> **Input:**</span> Thank you  **X** me to your party **Y** week.\n\n<span style = \"color:blue\">**Output:**</span> The model should predict the words(s) for **X** and **Y**. \n\n**Z** is used to represent the end.\n\n### 1.2 Process C4 {#1.2}\n\nC4 only has the plain string `text` field, so you will tokenize and have `inputs` and `targets` out of it for supervised learning. Given your inputs, the goal is to predict the targets during training. \n\nYou will now take the `text` and convert it to `inputs` and `targets`.\n\n::: {#93c82a78 .cell execution_count=5}\n``` {.python .cell-code}\n# Grab text field from dictionary\nnatural_language_texts = [example_json['text'] for example_json in example_jsons]\n```\n:::\n\n\n::: {#6abfd621 .cell execution_count=6}\n``` {.python .cell-code}\n# First text example\nnatural_language_texts[4]\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nb'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what\\xe2\\x80\\x99s included in the mill levy measure.'\n```\n:::\n:::\n\n\n#### 1.2.1 Decode to natural language {#1.2.1}\n\nThe following functions will help you `detokenize` and`tokenize` the text data.  \n\nThe `sentencepiece` vocabulary was used to convert from text to ids. This vocabulary file is loaded and used in this helper functions.\n\n`natural_language_texts` has the text from the examples we gave you. \n\nRun the cells below to see what is going on. \n\n::: {#e4de626d .cell execution_count=7}\n``` {.python .cell-code}\n# Special tokens\nPAD, EOS, UNK = 0, 1, 2\n\ndef detokenize(np_array):\n    return trax.data.detokenize(\n        np_array,\n        vocab_type='sentencepiece',\n        vocab_file='sentencepiece.model',\n        vocab_dir='.')\n\ndef tokenize(s):\n  # The trax.data.tokenize function operates on streams,\n  # that's why we have to create 1-element stream with iter\n  # and later retrieve the result with next.\n    return next(trax.data.tokenize(\n        iter([s]),\n        vocab_type='sentencepiece',\n        vocab_file='sentencepiece.model',\n        vocab_dir='.'))\n```\n:::\n\n\n::: {#2054aabc .cell execution_count=8}\n``` {.python .cell-code}\n# printing the encoding of each word to see how subwords are tokenized\ntokenized_text = [(tokenize(word).tolist(), word) for word in natural_language_texts[0].split()]\nprint(tokenized_text, '\\n')\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ImportError</span>                               Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[7], line 2</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># printing the encoding of each word to see how subwords are tokenized</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span> tokenized_text <span style=\"color:rgb(98,98,98)\">=</span> [(tokenize(word)<span style=\"color:rgb(98,98,98)\">.</span>tolist(), word) <span style=\"font-weight:bold;color:rgb(0,135,0)\">for</span> word <span style=\"font-weight:bold;color:rgb(175,0,255)\">in</span> natural_language_texts[<span style=\"color:rgb(98,98,98)\">0</span>]<span style=\"color:rgb(98,98,98)\">.</span>split()]\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"color:rgb(0,135,0)\">print</span>(tokenized_text, <span style=\"color:rgb(175,0,0)\">'</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"color:rgb(175,0,0)\">'</span>)\n\nCell <span class=\"ansi-green-fg\">In[7], line 2</span>, in <span class=\"ansi-cyan-fg\">&lt;listcomp&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># printing the encoding of each word to see how subwords are tokenized</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span> tokenized_text <span style=\"color:rgb(98,98,98)\">=</span> [(<span class=\"ansi-yellow-bg\">tokenize</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">word</span><span class=\"ansi-yellow-bg\">)</span><span style=\"color:rgb(98,98,98)\">.</span>tolist(), word) <span style=\"font-weight:bold;color:rgb(0,135,0)\">for</span> word <span style=\"font-weight:bold;color:rgb(175,0,255)\">in</span> natural_language_texts[<span style=\"color:rgb(98,98,98)\">0</span>]<span style=\"color:rgb(98,98,98)\">.</span>split()]\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"color:rgb(0,135,0)\">print</span>(tokenized_text, <span style=\"color:rgb(175,0,0)\">'</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"color:rgb(175,0,0)\">'</span>)\n\nCell <span class=\"ansi-green-fg\">In[6], line 15</span>, in <span class=\"ansi-cyan-fg\">tokenize</span><span class=\"ansi-blue-fg\">(s)</span>\n<span class=\"ansi-green-fg ansi-bold\">     11</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">tokenize</span>(s):\n<span class=\"ansi-green-fg ansi-bold\">     12</span>   <span style=\"font-style:italic;color:rgb(95,135,135)\"># The trax.data.tokenize function operates on streams,</span>\n<span class=\"ansi-green-fg ansi-bold\">     13</span>   <span style=\"font-style:italic;color:rgb(95,135,135)\"># that's why we have to create 1-element stream with iter</span>\n<span class=\"ansi-green-fg ansi-bold\">     14</span>   <span style=\"font-style:italic;color:rgb(95,135,135)\"># and later retrieve the result with next.</span>\n<span class=\"ansi-green-fg\">---&gt; 15</span>     <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> <span style=\"color:rgb(0,135,0)\" class=\"ansi-yellow-bg\">next</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">trax</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">data</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">tokenize</span><span class=\"ansi-yellow-bg\">(</span>\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span class=\"ansi-yellow-bg\">        </span><span style=\"color:rgb(0,135,0)\" class=\"ansi-yellow-bg\">iter</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">[</span><span class=\"ansi-yellow-bg\">s</span><span class=\"ansi-yellow-bg\">]</span><span class=\"ansi-yellow-bg\">)</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span class=\"ansi-yellow-bg\">        </span><span class=\"ansi-yellow-bg\">vocab_type</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">sentencepiece</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span class=\"ansi-yellow-bg\">        </span><span class=\"ansi-yellow-bg\">vocab_file</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">sentencepiece.model</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">     19</span> <span class=\"ansi-yellow-bg\">        </span><span class=\"ansi-yellow-bg\">vocab_dir</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">.</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">)</span><span class=\"ansi-yellow-bg\">)</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/data/tf_inputs.py:432</span>, in <span class=\"ansi-cyan-fg\">tokenize</span><span class=\"ansi-blue-fg\">(stream, keys, vocab_type, vocab_file, vocab_dir, n_reserved_ids)</span>\n<span class=\"ansi-green-fg ansi-bold\">    404</span> <span style=\"color:rgb(175,0,255)\">@debug_data_pipeline</span><span style=\"color:rgb(98,98,98)\">.</span>debug_pipeline\n<span class=\"ansi-green-fg ansi-bold\">    405</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">tokenize</span>(stream,\n<span class=\"ansi-green-fg ansi-bold\">    406</span>              keys<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>,\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">    409</span>              vocab_dir<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>,\n<span class=\"ansi-green-fg ansi-bold\">    410</span>              n_reserved_ids<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">0</span>):\n<span class=\"ansi-green-fg ansi-bold\">    411</span> <span style=\"color:rgb(188,188,188)\">  </span><span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Tokenize examples from the stream.</span>\n<span class=\"ansi-green-fg ansi-bold\">    412</span> \n<span class=\"ansi-green-fg ansi-bold\">    413</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">  This function assumes that `stream` generates either strings or tuples/dicts</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">    430</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">    integers -- the tokenized version of these strings.</span>\n<span class=\"ansi-green-fg ansi-bold\">    431</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">  \"\"\"</span>\n<span class=\"ansi-green-fg\">--&gt; 432</span>   vocab <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">_get_vocab</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">vocab_type</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">vocab_file</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">vocab_dir</span><span class=\"ansi-yellow-bg\">)</span>\n<span class=\"ansi-green-fg ansi-bold\">    433</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">for</span> example <span style=\"font-weight:bold;color:rgb(175,0,255)\">in</span> stream:\n<span class=\"ansi-green-fg ansi-bold\">    434</span>     <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> <span style=\"color:rgb(0,135,0)\">isinstance</span>(example, (<span style=\"color:rgb(0,135,0)\">list</span>, <span style=\"color:rgb(0,135,0)\">tuple</span>)):\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/data/tf_inputs.py:603</span>, in <span class=\"ansi-cyan-fg\">_get_vocab</span><span class=\"ansi-blue-fg\">(vocab_type, vocab_file, vocab_dir, extra_ids)</span>\n<span class=\"ansi-green-fg ansi-bold\">    600</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> text_encoder<span style=\"color:rgb(98,98,98)\">.</span>BertEncoder(path, do_lower_case<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">True</span>)\n<span class=\"ansi-green-fg ansi-bold\">    602</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">assert</span> vocab_type <span style=\"color:rgb(98,98,98)\">==</span> <span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">sentencepiece</span><span style=\"color:rgb(175,0,0)\">'</span>\n<span class=\"ansi-green-fg\">--&gt; 603</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> <span class=\"ansi-yellow-bg\">t5_data</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">)</span><span style=\"color:rgb(98,98,98)\">.</span>SentencePieceVocabulary(sentencepiece_model_file<span style=\"color:rgb(98,98,98)\">=</span>path,\n<span class=\"ansi-green-fg ansi-bold\">    604</span>                                          extra_ids<span style=\"color:rgb(98,98,98)\">=</span>extra_ids)\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/data/tf_inputs.py:53</span>, in <span class=\"ansi-cyan-fg\">t5_data</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-fg ansi-bold\">     51</span> module <span style=\"color:rgb(98,98,98)\">=</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>\n<span class=\"ansi-green-fg ansi-bold\">     52</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">try</span>:\n<span class=\"ansi-green-fg\">---&gt; 53</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span>  <span style=\"font-style:italic;color:rgb(95,135,135)\"># pylint: disable=g-import-not-at-top</span>\n<span class=\"ansi-green-fg ansi-bold\">     54</span>   module <span style=\"color:rgb(98,98,98)\">=</span> t5<span style=\"color:rgb(98,98,98)\">.</span>data\n<span class=\"ansi-green-fg ansi-bold\">     55</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">except</span> <span style=\"font-weight:bold;color:rgb(215,95,95)\">AttributeError</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span> e:\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/t5/__init__.py:17</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Copyright 2023 The T5 Authors.</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">#</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     12</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># See the License for the specific language governing permissions and</span>\n<span class=\"ansi-green-fg ansi-bold\">     13</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># limitations under the License.</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Import API modules.\"\"\"</span>\n<span class=\"ansi-green-fg\">---&gt; 17</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">evaluation</span>\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Version number.</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/t5/data/__init__.py:17</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Import data modules.\"\"\"</span>\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># pylint:disable=wildcard-import,g-bad-import-order</span>\n<span class=\"ansi-green-fg\">---&gt; 17</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">dataset_providers</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> <span style=\"color:rgb(98,98,98)\">*</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">glue_utils</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> <span style=\"color:rgb(98,98,98)\">*</span>\n<span class=\"ansi-green-fg ansi-bold\">     19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">postprocessors</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/t5/data/dataset_providers.py:28</span>\n<span class=\"ansi-green-fg ansi-bold\">     25</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">collections</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">abc</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> Mapping\n<span class=\"ansi-green-fg ansi-bold\">     26</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">re</span>\n<span class=\"ansi-green-fg\">---&gt; 28</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span>\n<span class=\"ansi-green-fg ansi-bold\">     29</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> utils\n<span class=\"ansi-green-fg ansi-bold\">     30</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">tensorflow</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">compat</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">v2</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">tf</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/seqio/__init__.py:19</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Import to top-level API.\"\"\"</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># pylint:disable=wildcard-import,g-bad-import-order,g-import-not-at-top</span>\n<span class=\"ansi-green-fg\">---&gt; 19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">dataset_providers</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> <span style=\"color:rgb(98,98,98)\">*</span>\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> evaluation\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> experimental\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/seqio/dataset_providers.py:36</span>\n<span class=\"ansi-green-fg ansi-bold\">     33</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">typing</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> Any, Callable, Iterable, List, Mapping, MutableMapping, Optional, Sequence, Set, Tuple, Type, Union\n<span class=\"ansi-green-fg ansi-bold\">     35</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">absl</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> logging\n<span class=\"ansi-green-fg\">---&gt; 36</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">clu</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">metrics</span>\n<span class=\"ansi-green-fg ansi-bold\">     37</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">editdistance</span>\n<span class=\"ansi-green-fg ansi-bold\">     38</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">numpy</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">np</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/clu/metrics.py:66</span>\n<span class=\"ansi-green-fg ansi-bold\">     64</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">clu</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">internal</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> utils\n<span class=\"ansi-green-fg ansi-bold\">     65</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">clu</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">values</span>\n<span class=\"ansi-green-fg\">---&gt; 66</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">flax</span>\n<span class=\"ansi-green-fg ansi-bold\">     67</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span>\n<span class=\"ansi-green-fg ansi-bold\">     68</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">numpy</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jnp</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/flax/__init__.py:19</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Copyright 2022 The Flax Authors.</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">#</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     14</span> \n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Lint as: python 3</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Flax API.\"\"\"</span>\n<span class=\"ansi-green-fg\">---&gt; 19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> core\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> linen\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> optim\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/flax/core/__init__.py:15</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Copyright 2022 The Flax Authors.</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">#</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     12</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># See the License for the specific language governing permissions and</span>\n<span class=\"ansi-green-fg ansi-bold\">     13</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># limitations under the License.</span>\n<span class=\"ansi-green-fg\">---&gt; 15</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">axes_scan</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> broadcast\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">frozen_dict</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> FrozenDict, freeze, unfreeze\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">tracers</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> current_trace, trace_level, check_trace_level\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/flax/core/axes_scan.py:22</span>\n<span class=\"ansi-green-fg ansi-bold\">     19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> lax\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">interpreters</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> partial_eval <span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span> pe\n<span class=\"ansi-green-fg\">---&gt; 22</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> linear_util <span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span> lu\n<span class=\"ansi-green-fg ansi-bold\">     24</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">typing</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> Union, Optional, Callable, Any\n<span class=\"ansi-green-fg ansi-bold\">     26</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">numpy</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">np</span>\n\n<span class=\"ansi-red-fg\">ImportError</span>: cannot import name 'linear_util' from 'jax' (/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/jax/__init__.py)</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#9297c157 .cell execution_count=9}\n``` {.python .cell-code}\n# We can see that detokenize successfully undoes the tokenization\nprint(f\"tokenized: {tokenize('Beginners')}\\ndetokenized: {detokenize(tokenize('Beginners'))}\")\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ImportError</span>                               Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[8], line 2</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># We can see that detokenize successfully undoes the tokenization</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span> <span style=\"color:rgb(0,135,0)\">print</span>(<span style=\"color:rgb(175,0,0)\">f</span><span style=\"color:rgb(175,0,0)\">\"</span><span style=\"color:rgb(175,0,0)\">tokenized: </span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span><span class=\"ansi-yellow-bg\">tokenize</span><span class=\"ansi-yellow-bg\">(</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">Beginners</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">)</span><span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"color:rgb(175,0,0)\">detokenized: </span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span>detokenize(tokenize(<span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">Beginners</span><span style=\"color:rgb(175,0,0)\">'</span>))<span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"color:rgb(175,0,0)\">\"</span>)\n\nCell <span class=\"ansi-green-fg\">In[6], line 15</span>, in <span class=\"ansi-cyan-fg\">tokenize</span><span class=\"ansi-blue-fg\">(s)</span>\n<span class=\"ansi-green-fg ansi-bold\">     11</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">tokenize</span>(s):\n<span class=\"ansi-green-fg ansi-bold\">     12</span>   <span style=\"font-style:italic;color:rgb(95,135,135)\"># The trax.data.tokenize function operates on streams,</span>\n<span class=\"ansi-green-fg ansi-bold\">     13</span>   <span style=\"font-style:italic;color:rgb(95,135,135)\"># that's why we have to create 1-element stream with iter</span>\n<span class=\"ansi-green-fg ansi-bold\">     14</span>   <span style=\"font-style:italic;color:rgb(95,135,135)\"># and later retrieve the result with next.</span>\n<span class=\"ansi-green-fg\">---&gt; 15</span>     <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> <span style=\"color:rgb(0,135,0)\" class=\"ansi-yellow-bg\">next</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">trax</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">data</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">tokenize</span><span class=\"ansi-yellow-bg\">(</span>\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span class=\"ansi-yellow-bg\">        </span><span style=\"color:rgb(0,135,0)\" class=\"ansi-yellow-bg\">iter</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">[</span><span class=\"ansi-yellow-bg\">s</span><span class=\"ansi-yellow-bg\">]</span><span class=\"ansi-yellow-bg\">)</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span class=\"ansi-yellow-bg\">        </span><span class=\"ansi-yellow-bg\">vocab_type</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">sentencepiece</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span class=\"ansi-yellow-bg\">        </span><span class=\"ansi-yellow-bg\">vocab_file</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">sentencepiece.model</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">     19</span> <span class=\"ansi-yellow-bg\">        </span><span class=\"ansi-yellow-bg\">vocab_dir</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">.</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">)</span><span class=\"ansi-yellow-bg\">)</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/data/tf_inputs.py:432</span>, in <span class=\"ansi-cyan-fg\">tokenize</span><span class=\"ansi-blue-fg\">(stream, keys, vocab_type, vocab_file, vocab_dir, n_reserved_ids)</span>\n<span class=\"ansi-green-fg ansi-bold\">    404</span> <span style=\"color:rgb(175,0,255)\">@debug_data_pipeline</span><span style=\"color:rgb(98,98,98)\">.</span>debug_pipeline\n<span class=\"ansi-green-fg ansi-bold\">    405</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">tokenize</span>(stream,\n<span class=\"ansi-green-fg ansi-bold\">    406</span>              keys<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>,\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">    409</span>              vocab_dir<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>,\n<span class=\"ansi-green-fg ansi-bold\">    410</span>              n_reserved_ids<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">0</span>):\n<span class=\"ansi-green-fg ansi-bold\">    411</span> <span style=\"color:rgb(188,188,188)\">  </span><span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Tokenize examples from the stream.</span>\n<span class=\"ansi-green-fg ansi-bold\">    412</span> \n<span class=\"ansi-green-fg ansi-bold\">    413</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">  This function assumes that `stream` generates either strings or tuples/dicts</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">    430</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">    integers -- the tokenized version of these strings.</span>\n<span class=\"ansi-green-fg ansi-bold\">    431</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">  \"\"\"</span>\n<span class=\"ansi-green-fg\">--&gt; 432</span>   vocab <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">_get_vocab</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">vocab_type</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">vocab_file</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">vocab_dir</span><span class=\"ansi-yellow-bg\">)</span>\n<span class=\"ansi-green-fg ansi-bold\">    433</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">for</span> example <span style=\"font-weight:bold;color:rgb(175,0,255)\">in</span> stream:\n<span class=\"ansi-green-fg ansi-bold\">    434</span>     <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> <span style=\"color:rgb(0,135,0)\">isinstance</span>(example, (<span style=\"color:rgb(0,135,0)\">list</span>, <span style=\"color:rgb(0,135,0)\">tuple</span>)):\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/data/tf_inputs.py:603</span>, in <span class=\"ansi-cyan-fg\">_get_vocab</span><span class=\"ansi-blue-fg\">(vocab_type, vocab_file, vocab_dir, extra_ids)</span>\n<span class=\"ansi-green-fg ansi-bold\">    600</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> text_encoder<span style=\"color:rgb(98,98,98)\">.</span>BertEncoder(path, do_lower_case<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">True</span>)\n<span class=\"ansi-green-fg ansi-bold\">    602</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">assert</span> vocab_type <span style=\"color:rgb(98,98,98)\">==</span> <span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">sentencepiece</span><span style=\"color:rgb(175,0,0)\">'</span>\n<span class=\"ansi-green-fg\">--&gt; 603</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> <span class=\"ansi-yellow-bg\">t5_data</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">)</span><span style=\"color:rgb(98,98,98)\">.</span>SentencePieceVocabulary(sentencepiece_model_file<span style=\"color:rgb(98,98,98)\">=</span>path,\n<span class=\"ansi-green-fg ansi-bold\">    604</span>                                          extra_ids<span style=\"color:rgb(98,98,98)\">=</span>extra_ids)\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/data/tf_inputs.py:53</span>, in <span class=\"ansi-cyan-fg\">t5_data</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-fg ansi-bold\">     51</span> module <span style=\"color:rgb(98,98,98)\">=</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>\n<span class=\"ansi-green-fg ansi-bold\">     52</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">try</span>:\n<span class=\"ansi-green-fg\">---&gt; 53</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span>  <span style=\"font-style:italic;color:rgb(95,135,135)\"># pylint: disable=g-import-not-at-top</span>\n<span class=\"ansi-green-fg ansi-bold\">     54</span>   module <span style=\"color:rgb(98,98,98)\">=</span> t5<span style=\"color:rgb(98,98,98)\">.</span>data\n<span class=\"ansi-green-fg ansi-bold\">     55</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">except</span> <span style=\"font-weight:bold;color:rgb(215,95,95)\">AttributeError</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span> e:\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/t5/__init__.py:17</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Copyright 2023 The T5 Authors.</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">#</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     12</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># See the License for the specific language governing permissions and</span>\n<span class=\"ansi-green-fg ansi-bold\">     13</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># limitations under the License.</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Import API modules.\"\"\"</span>\n<span class=\"ansi-green-fg\">---&gt; 17</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">evaluation</span>\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Version number.</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/t5/data/__init__.py:17</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Import data modules.\"\"\"</span>\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># pylint:disable=wildcard-import,g-bad-import-order</span>\n<span class=\"ansi-green-fg\">---&gt; 17</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">dataset_providers</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> <span style=\"color:rgb(98,98,98)\">*</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">glue_utils</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> <span style=\"color:rgb(98,98,98)\">*</span>\n<span class=\"ansi-green-fg ansi-bold\">     19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">postprocessors</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/t5/data/dataset_providers.py:28</span>\n<span class=\"ansi-green-fg ansi-bold\">     25</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">collections</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">abc</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> Mapping\n<span class=\"ansi-green-fg ansi-bold\">     26</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">re</span>\n<span class=\"ansi-green-fg\">---&gt; 28</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span>\n<span class=\"ansi-green-fg ansi-bold\">     29</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> utils\n<span class=\"ansi-green-fg ansi-bold\">     30</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">tensorflow</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">compat</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">v2</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">tf</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/seqio/__init__.py:19</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Import to top-level API.\"\"\"</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># pylint:disable=wildcard-import,g-bad-import-order,g-import-not-at-top</span>\n<span class=\"ansi-green-fg\">---&gt; 19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">dataset_providers</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> <span style=\"color:rgb(98,98,98)\">*</span>\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> evaluation\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> experimental\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/seqio/dataset_providers.py:36</span>\n<span class=\"ansi-green-fg ansi-bold\">     33</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">typing</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> Any, Callable, Iterable, List, Mapping, MutableMapping, Optional, Sequence, Set, Tuple, Type, Union\n<span class=\"ansi-green-fg ansi-bold\">     35</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">absl</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> logging\n<span class=\"ansi-green-fg\">---&gt; 36</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">clu</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">metrics</span>\n<span class=\"ansi-green-fg ansi-bold\">     37</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">editdistance</span>\n<span class=\"ansi-green-fg ansi-bold\">     38</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">numpy</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">np</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/clu/metrics.py:66</span>\n<span class=\"ansi-green-fg ansi-bold\">     64</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">clu</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">internal</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> utils\n<span class=\"ansi-green-fg ansi-bold\">     65</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">clu</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">values</span>\n<span class=\"ansi-green-fg\">---&gt; 66</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">flax</span>\n<span class=\"ansi-green-fg ansi-bold\">     67</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span>\n<span class=\"ansi-green-fg ansi-bold\">     68</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">numpy</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jnp</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/flax/__init__.py:19</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Copyright 2022 The Flax Authors.</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">#</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     14</span> \n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Lint as: python 3</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Flax API.\"\"\"</span>\n<span class=\"ansi-green-fg\">---&gt; 19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> core\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> linen\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> optim\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/flax/core/__init__.py:15</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Copyright 2022 The Flax Authors.</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">#</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     12</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># See the License for the specific language governing permissions and</span>\n<span class=\"ansi-green-fg ansi-bold\">     13</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># limitations under the License.</span>\n<span class=\"ansi-green-fg\">---&gt; 15</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">axes_scan</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> broadcast\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">frozen_dict</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> FrozenDict, freeze, unfreeze\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">tracers</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> current_trace, trace_level, check_trace_level\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/flax/core/axes_scan.py:22</span>\n<span class=\"ansi-green-fg ansi-bold\">     19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> lax\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">interpreters</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> partial_eval <span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span> pe\n<span class=\"ansi-green-fg\">---&gt; 22</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> linear_util <span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span> lu\n<span class=\"ansi-green-fg ansi-bold\">     24</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">typing</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> Union, Optional, Callable, Any\n<span class=\"ansi-green-fg ansi-bold\">     26</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">numpy</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">np</span>\n\n<span class=\"ansi-red-fg\">ImportError</span>: cannot import name 'linear_util' from 'jax' (/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/jax/__init__.py)</pre>\n```\n:::\n\n:::\n:::\n\n\nAs you can see above, you were able to take a piece of string and tokenize it. \n\nNow you will create `input` and `target` pairs that will allow you to train your model. T5 uses the ids at the end of the vocab file as sentinels. For example, it will replace: \n   - `vocab_size - 1` by `<Z>`\n   - `vocab_size - 2` by `<Y>`\n   - and so forth. \n   \nIt assigns every word a `chr`.\n\nThe `pretty_decode` function below, which you will use in a bit, helps in handling the type when decoding. Take a look and try to understand what the function is doing.\n\nNotice that:\n\n```python\nstring.ascii_letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n```\n\n**NOTE:** Targets may have more than the 52 sentinels we replace, but this is just to give you an idea of things.\n\n::: {#c28035f6 .cell execution_count=10}\n``` {.python .cell-code}\nvocab_size = trax.data.vocab_size(\n    vocab_type='sentencepiece',\n    vocab_file='sentencepiece.model',\n    vocab_dir='.')\n\ndef get_sentinels(vocab_size=vocab_size, display=False):\n    sentinels = {}\n    for i, char in enumerate(reversed(string.ascii_letters), 1):\n        decoded_text = detokenize([vocab_size - i]) \n        \n        # Sentinels, ex: <Z> - <a>\n        sentinels[decoded_text] = f'<{char}>'    \n    \n        if display:\n            print(f'The sentinel is <{char}> and the decoded token is:', decoded_text)\n\n    return sentinels\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ImportError</span>                               Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[9], line 1</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span> vocab_size <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">trax</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">data</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">vocab_size</span><span class=\"ansi-yellow-bg\">(</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span class=\"ansi-yellow-bg\">    </span><span class=\"ansi-yellow-bg\">vocab_type</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">sentencepiece</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span class=\"ansi-yellow-bg\">    </span><span class=\"ansi-yellow-bg\">vocab_file</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">sentencepiece.model</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">      4</span> <span class=\"ansi-yellow-bg\">    </span><span class=\"ansi-yellow-bg\">vocab_dir</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">.</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">)</span>\n<span class=\"ansi-green-fg ansi-bold\">      6</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">get_sentinels</span>(vocab_size<span style=\"color:rgb(98,98,98)\">=</span>vocab_size, display<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">False</span>):\n<span class=\"ansi-green-fg ansi-bold\">      7</span>     sentinels <span style=\"color:rgb(98,98,98)\">=</span> {}\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/data/tf_inputs.py:570</span>, in <span class=\"ansi-cyan-fg\">vocab_size</span><span class=\"ansi-blue-fg\">(vocab_type, vocab_file, vocab_dir, n_reserved_ids)</span>\n<span class=\"ansi-green-fg ansi-bold\">    550</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">vocab_size</span>(vocab_type<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">subword</span><span style=\"color:rgb(175,0,0)\">'</span>,\n<span class=\"ansi-green-fg ansi-bold\">    551</span>                vocab_file<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>,\n<span class=\"ansi-green-fg ansi-bold\">    552</span>                vocab_dir<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>,\n<span class=\"ansi-green-fg ansi-bold\">    553</span>                n_reserved_ids<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">0</span>):\n<span class=\"ansi-green-fg ansi-bold\">    554</span> <span style=\"color:rgb(188,188,188)\">  </span><span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Returns the size of the vocabulary (number of symbols used).</span>\n<span class=\"ansi-green-fg ansi-bold\">    555</span> \n<span class=\"ansi-green-fg ansi-bold\">    556</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">  This function can be used to set the size of the final layers of a model that</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">    568</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">    An integer, the number of symbols used (including reserved IDs).</span>\n<span class=\"ansi-green-fg ansi-bold\">    569</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">  \"\"\"</span>\n<span class=\"ansi-green-fg\">--&gt; 570</span>   vocab <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">_get_vocab</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">vocab_type</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">vocab_file</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">vocab_dir</span><span class=\"ansi-yellow-bg\">)</span>\n<span class=\"ansi-green-fg ansi-bold\">    571</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> vocab<span style=\"color:rgb(98,98,98)\">.</span>vocab_size <span style=\"color:rgb(98,98,98)\">+</span> n_reserved_ids\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/data/tf_inputs.py:603</span>, in <span class=\"ansi-cyan-fg\">_get_vocab</span><span class=\"ansi-blue-fg\">(vocab_type, vocab_file, vocab_dir, extra_ids)</span>\n<span class=\"ansi-green-fg ansi-bold\">    600</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> text_encoder<span style=\"color:rgb(98,98,98)\">.</span>BertEncoder(path, do_lower_case<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">True</span>)\n<span class=\"ansi-green-fg ansi-bold\">    602</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">assert</span> vocab_type <span style=\"color:rgb(98,98,98)\">==</span> <span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">sentencepiece</span><span style=\"color:rgb(175,0,0)\">'</span>\n<span class=\"ansi-green-fg\">--&gt; 603</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> <span class=\"ansi-yellow-bg\">t5_data</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">)</span><span style=\"color:rgb(98,98,98)\">.</span>SentencePieceVocabulary(sentencepiece_model_file<span style=\"color:rgb(98,98,98)\">=</span>path,\n<span class=\"ansi-green-fg ansi-bold\">    604</span>                                          extra_ids<span style=\"color:rgb(98,98,98)\">=</span>extra_ids)\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/data/tf_inputs.py:53</span>, in <span class=\"ansi-cyan-fg\">t5_data</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-fg ansi-bold\">     51</span> module <span style=\"color:rgb(98,98,98)\">=</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>\n<span class=\"ansi-green-fg ansi-bold\">     52</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">try</span>:\n<span class=\"ansi-green-fg\">---&gt; 53</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span>  <span style=\"font-style:italic;color:rgb(95,135,135)\"># pylint: disable=g-import-not-at-top</span>\n<span class=\"ansi-green-fg ansi-bold\">     54</span>   module <span style=\"color:rgb(98,98,98)\">=</span> t5<span style=\"color:rgb(98,98,98)\">.</span>data\n<span class=\"ansi-green-fg ansi-bold\">     55</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">except</span> <span style=\"font-weight:bold;color:rgb(215,95,95)\">AttributeError</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span> e:\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/t5/__init__.py:17</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Copyright 2023 The T5 Authors.</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">#</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     12</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># See the License for the specific language governing permissions and</span>\n<span class=\"ansi-green-fg ansi-bold\">     13</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># limitations under the License.</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Import API modules.\"\"\"</span>\n<span class=\"ansi-green-fg\">---&gt; 17</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">evaluation</span>\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Version number.</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/t5/data/__init__.py:17</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Import data modules.\"\"\"</span>\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># pylint:disable=wildcard-import,g-bad-import-order</span>\n<span class=\"ansi-green-fg\">---&gt; 17</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">dataset_providers</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> <span style=\"color:rgb(98,98,98)\">*</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">glue_utils</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> <span style=\"color:rgb(98,98,98)\">*</span>\n<span class=\"ansi-green-fg ansi-bold\">     19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">postprocessors</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/t5/data/dataset_providers.py:28</span>\n<span class=\"ansi-green-fg ansi-bold\">     25</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">collections</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">abc</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> Mapping\n<span class=\"ansi-green-fg ansi-bold\">     26</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">re</span>\n<span class=\"ansi-green-fg\">---&gt; 28</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span>\n<span class=\"ansi-green-fg ansi-bold\">     29</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">t5</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">data</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> utils\n<span class=\"ansi-green-fg ansi-bold\">     30</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">tensorflow</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">compat</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">v2</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">tf</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/seqio/__init__.py:19</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Import to top-level API.\"\"\"</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># pylint:disable=wildcard-import,g-bad-import-order,g-import-not-at-top</span>\n<span class=\"ansi-green-fg\">---&gt; 19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">dataset_providers</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> <span style=\"color:rgb(98,98,98)\">*</span>\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> evaluation\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">seqio</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> experimental\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/seqio/dataset_providers.py:36</span>\n<span class=\"ansi-green-fg ansi-bold\">     33</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">typing</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> Any, Callable, Iterable, List, Mapping, MutableMapping, Optional, Sequence, Set, Tuple, Type, Union\n<span class=\"ansi-green-fg ansi-bold\">     35</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">absl</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> logging\n<span class=\"ansi-green-fg\">---&gt; 36</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">clu</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">metrics</span>\n<span class=\"ansi-green-fg ansi-bold\">     37</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">editdistance</span>\n<span class=\"ansi-green-fg ansi-bold\">     38</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">numpy</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">np</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/clu/metrics.py:66</span>\n<span class=\"ansi-green-fg ansi-bold\">     64</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">clu</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">internal</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> utils\n<span class=\"ansi-green-fg ansi-bold\">     65</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">clu</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">values</span>\n<span class=\"ansi-green-fg\">---&gt; 66</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">flax</span>\n<span class=\"ansi-green-fg ansi-bold\">     67</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span>\n<span class=\"ansi-green-fg ansi-bold\">     68</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">numpy</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jnp</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/flax/__init__.py:19</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Copyright 2022 The Flax Authors.</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">#</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     14</span> \n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Lint as: python 3</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Flax API.\"\"\"</span>\n<span class=\"ansi-green-fg\">---&gt; 19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> core\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> linen\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> optim\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/flax/core/__init__.py:15</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Copyright 2022 The Flax Authors.</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">#</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     12</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># See the License for the specific language governing permissions and</span>\n<span class=\"ansi-green-fg ansi-bold\">     13</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># limitations under the License.</span>\n<span class=\"ansi-green-fg\">---&gt; 15</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">axes_scan</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> broadcast\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">frozen_dict</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> FrozenDict, freeze, unfreeze\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">tracers</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> current_trace, trace_level, check_trace_level\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/flax/core/axes_scan.py:22</span>\n<span class=\"ansi-green-fg ansi-bold\">     19</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> lax\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">.</span><span style=\"font-weight:bold;color:rgb(0,0,255)\">interpreters</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> partial_eval <span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span> pe\n<span class=\"ansi-green-fg\">---&gt; 22</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">jax</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> linear_util <span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span> lu\n<span class=\"ansi-green-fg ansi-bold\">     24</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">from</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">typing</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span> Union, Optional, Callable, Any\n<span class=\"ansi-green-fg ansi-bold\">     26</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">import</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">numpy</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,135,0)\">as</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"font-weight:bold;color:rgb(0,0,255)\">np</span>\n\n<span class=\"ansi-red-fg\">ImportError</span>: cannot import name 'linear_util' from 'jax' (/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/jax/__init__.py)</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#4739101b .cell execution_count=11}\n``` {.python .cell-code}\nsentinels = get_sentinels(vocab_size, display=True)\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[10], line 1</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span> sentinels <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">get_sentinels</span>(vocab_size, display<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">True</span>)\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'get_sentinels' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#08b1116a .cell execution_count=12}\n``` {.python .cell-code}\ndef pretty_decode(encoded_str_list, sentinels=sentinels):\n    # If already a string, just do the replacements.\n    if isinstance(encoded_str_list, (str, bytes)):\n        for token, char in sentinels.items():\n            encoded_str_list = encoded_str_list.replace(token, char)\n        return encoded_str_list\n  \n    # We need to decode and then prettyfy it.\n    return pretty_decode(detokenize(encoded_str_list))\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[11], line 1</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">pretty_decode</span>(encoded_str_list, sentinels<span style=\"color:rgb(98,98,98)\">=</span><span class=\"ansi-yellow-bg\">sentinels</span>):\n<span class=\"ansi-green-fg ansi-bold\">      2</span>     <span style=\"font-style:italic;color:rgb(95,135,135)\"># If already a string, just do the replacements.</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span>     <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> <span style=\"color:rgb(0,135,0)\">isinstance</span>(encoded_str_list, (<span style=\"color:rgb(0,135,0)\">str</span>, <span style=\"color:rgb(0,135,0)\">bytes</span>)):\n<span class=\"ansi-green-fg ansi-bold\">      4</span>         <span style=\"font-weight:bold;color:rgb(0,135,0)\">for</span> token, char <span style=\"font-weight:bold;color:rgb(175,0,255)\">in</span> sentinels<span style=\"color:rgb(98,98,98)\">.</span>items():\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'sentinels' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#4c04b06a .cell execution_count=13}\n``` {.python .cell-code}\npretty_decode(\"I want to dress up as an Intellectual this halloween.\")\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[12], line 1</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span> <span class=\"ansi-yellow-bg\">pretty_decode</span>(<span style=\"color:rgb(175,0,0)\">\"</span><span style=\"color:rgb(175,0,0)\">I want to dress up as an Intellectual this halloween.</span><span style=\"color:rgb(175,0,0)\">\"</span>)\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'pretty_decode' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\nThe functions above make your `inputs` and `targets` more readable. For example, you might see something like this once you implement the masking function below. \n\n- [Input sentence:]{style=\"color:red\"} Younes and Lukasz were working together in the lab yesterday after lunch. \n- [Input:]{style=\"color:red\"} Younes and Lukasz  **Z** together in the **Y** yesterday after lunch.\n- [Target:]{style=\"color:red\"} **Z** were working **Y** lab.\n\n### 1.3 Tokenizing and Masking {#1.3}\n\nYou will now implement the `tokenize_and_mask` function. This function  will allow you to tokenize and mask input words with a noise probability. We usually mask 15% of the words.\n\n### Exercise 01 {#ex01}\n\n::: {#03656699 .cell execution_count=14}\n``` {.python .cell-code}\n# UNQ_C1\n# GRADED FUNCTION: tokenize_and_mask\ndef tokenize_and_mask(text, vocab_size=vocab_size, noise=0.15, \n                      randomizer=np.random.uniform, tokenize=tokenize):\n    \"\"\"Tokenizes and masks a given input.\n\n    Args:\n        text (str or bytes): Text input.\n        vocab_size (int, optional): Size of the vocabulary. Defaults to vocab_size.\n        noise (float, optional): Probability of masking a token. Defaults to 0.15.\n        randomizer (function, optional): Function that generates random values. Defaults to np.random.uniform.\n        tokenize (function, optional): Tokenizer function. Defaults to tokenize.\n\n    Returns:\n        tuple: Tuple of lists of integers associated to inputs and targets.\n    \"\"\"\n    \n    # current sentinel number (starts at 0)\n    cur_sentinel_num = 0\n    # inputs\n    inps = []\n    # targets\n    targs = []\n    \n    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n    \n    # prev_no_mask is True if the previous token was NOT masked, False otherwise\n    # set prev_no_mask to True\n    prev_no_mask = None\n    \n    # loop through tokenized `text`\n    for token in tokenize(text):\n        # check if the `noise` is greater than a random value (weighted coin flip)\n        if randomizer() < noise:\n            # check to see if the previous token was not masked\n            if prev_no_mask==True: # add new masked token at end_id\n                # number of masked tokens increases by 1\n                cur_sentinel_num += None\n                # compute `end_id` by subtracting current sentinel value out of the total vocabulary size\n                end_id = None - None\n                # append `end_id` at the end of the targets\n                targs.append(None)\n                # append `end_id` at the end of the inputs\n                inps.append(None)\n            # append `token` at the end of the targets\n            targs.append(None)\n            # set prev_no_mask accordingly\n            prev_no_mask = None\n        \n        else: # don't have two masked tokens in a row\n            # append `token ` at the end of the inputs\n            inps.append(None)\n            # set prev_no_mask accordingly\n            prev_no_mask = None\n            \n    ### END CODE HERE ###\n    \n    return inps, targs\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[13], line 3</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># UNQ_C1</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># GRADED FUNCTION: tokenize_and_mask</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">tokenize_and_mask</span>(text, vocab_size<span style=\"color:rgb(98,98,98)\">=</span><span class=\"ansi-yellow-bg\">vocab_size</span>, noise<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">0.15</span>, \n<span class=\"ansi-green-fg ansi-bold\">      4</span>                       randomizer<span style=\"color:rgb(98,98,98)\">=</span>np<span style=\"color:rgb(98,98,98)\">.</span>random<span style=\"color:rgb(98,98,98)\">.</span>uniform, tokenize<span style=\"color:rgb(98,98,98)\">=</span>tokenize):\n<span class=\"ansi-green-fg ansi-bold\">      5</span> <span style=\"color:rgb(188,188,188)\">    </span><span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Tokenizes and masks a given input.</span>\n<span class=\"ansi-green-fg ansi-bold\">      6</span> \n<span class=\"ansi-green-fg ansi-bold\">      7</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">    Args:</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     15</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">        tuple: Tuple of lists of integers associated to inputs and targets.</span>\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">    \"\"\"</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span>     <span style=\"font-style:italic;color:rgb(95,135,135)\"># current sentinel number (starts at 0)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'vocab_size' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#dc93409f .cell execution_count=15}\n``` {.python .cell-code}\n# Some logic to mock a np.random value generator\n# Needs to be in the same cell for it to always generate same output\ndef testing_rnd():\n    def dummy_generator():\n        vals = np.linspace(0, 1, 10)\n        cyclic_vals = itertools.cycle(vals)\n        for _ in range(100):\n            yield next(cyclic_vals)\n\n    dumr = itertools.cycle(dummy_generator())\n\n    def dummy_randomizer():\n        return next(dumr)\n    \n    return dummy_randomizer\n\ninput_str = natural_language_texts[0]\nprint(f\"input string:\\n\\n{input_str}\\n\")\ninps, targs = tokenize_and_mask(input_str, randomizer=testing_rnd())\nprint(f\"tokenized inputs:\\n\\n{inps}\\n\")\nprint(f\"targets:\\n\\n{targs}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ninput string:\n\nb'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.'\n\n```\n:::\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[14], line 19</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> input_str <span style=\"color:rgb(98,98,98)\">=</span> natural_language_texts[<span style=\"color:rgb(98,98,98)\">0</span>]\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span style=\"color:rgb(0,135,0)\">print</span>(<span style=\"color:rgb(175,0,0)\">f</span><span style=\"color:rgb(175,0,0)\">\"</span><span style=\"color:rgb(175,0,0)\">input string:</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span>input_str<span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"color:rgb(175,0,0)\">\"</span>)\n<span class=\"ansi-green-fg\">---&gt; 19</span> inps, targs <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">tokenize_and_mask</span>(input_str, randomizer<span style=\"color:rgb(98,98,98)\">=</span>testing_rnd())\n<span class=\"ansi-green-fg ansi-bold\">     20</span> <span style=\"color:rgb(0,135,0)\">print</span>(<span style=\"color:rgb(175,0,0)\">f</span><span style=\"color:rgb(175,0,0)\">\"</span><span style=\"color:rgb(175,0,0)\">tokenized inputs:</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span>inps<span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"color:rgb(175,0,0)\">\"</span>)\n<span class=\"ansi-green-fg ansi-bold\">     21</span> <span style=\"color:rgb(0,135,0)\">print</span>(<span style=\"color:rgb(175,0,0)\">f</span><span style=\"color:rgb(175,0,0)\">\"</span><span style=\"color:rgb(175,0,0)\">targets:</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span>targs<span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"color:rgb(175,0,0)\">\"</span>)\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'tokenize_and_mask' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n#### **Expected Output:**\n\n```CPP\nb'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.'\n\ntokenized inputs:\n\n[31999, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 31998, 531, 25, 241, 12, 129, 394, 44, 492, 31997, 58, 148, 56, 43, 8, 1004, 6, 474, 31996, 39, 4793, 230, 5, 2721, 6, 1600, 1630, 31995, 1150, 4501, 15068, 16127, 6, 9137, 2659, 5595, 31994, 782, 3624, 14627, 15, 12612, 277, 5, 216, 31993, 2119, 3, 9, 19529, 593, 853, 21, 921, 31992, 12, 129, 394, 28, 70, 17712, 1098, 5, 31991, 3884, 25, 762, 25, 174, 12, 214, 12, 31990, 3, 9, 3, 23405, 4547, 15068, 2259, 6, 31989, 6, 5459, 6, 13618, 7, 6, 3604, 1801, 31988, 6, 303, 24190, 11, 1472, 251, 5, 37, 31987, 36, 16, 8, 853, 19, 25264, 399, 568, 31986, 21, 21380, 7, 34, 19, 339, 5, 15746, 31985, 8, 583, 56, 36, 893, 3, 9, 3, 31984, 9486, 42, 3, 9, 1409, 29, 11, 25, 31983, 12246, 5977, 13, 284, 3604, 24, 19, 2657, 31982]\n\ntargets:\n\n[31999, 12847, 277, 31998, 9, 55, 31997, 3326, 15068, 31996, 48, 30, 31995, 727, 1715, 31994, 45, 301, 31993, 56, 36, 31992, 113, 2746, 31991, 216, 56, 31990, 5978, 16, 31989, 379, 2097, 31988, 11, 27856, 31987, 583, 12, 31986, 6, 11, 31985, 26, 16, 31984, 17, 18, 31983, 56, 36, 31982, 5]\n```\n\nYou will now use the inputs and the targets from the `tokenize_and_mask` function you implemented above. Take a look at the masked sentence using your `inps` and `targs` from the sentence above. \n\n::: {#f87ef31e .cell execution_count=16}\n``` {.python .cell-code}\nprint('Inputs: \\n\\n', pretty_decode(inps))\nprint('\\nTargets: \\n\\n', pretty_decode(targs))\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[15], line 1</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span> <span style=\"color:rgb(0,135,0)\">print</span>(<span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">Inputs: </span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"color:rgb(175,0,0)\">'</span>, <span class=\"ansi-yellow-bg\">pretty_decode</span>(inps))\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"color:rgb(0,135,0)\">print</span>(<span style=\"color:rgb(175,0,0)\">'</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"color:rgb(175,0,0)\">Targets: </span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"font-weight:bold;color:rgb(175,95,0)\">\\n</span><span style=\"color:rgb(175,0,0)\">'</span>, pretty_decode(targs))\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'pretty_decode' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n### 1.4 Creating the Pairs {#1.4}\n\nYou will now create pairs using your dataset. You will iterate over your data and create (inp, targ) pairs using the functions that we have given you. \n\n::: {#2ed04b55 .cell execution_count=17}\n``` {.python .cell-code}\n# Apply tokenize_and_mask\ninputs_targets_pairs = [tokenize_and_mask(text) for text in natural_language_texts]\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[16], line 2</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Apply tokenize_and_mask</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span> inputs_targets_pairs <span style=\"color:rgb(98,98,98)\">=</span> [tokenize_and_mask(text) <span style=\"font-weight:bold;color:rgb(0,135,0)\">for</span> text <span style=\"font-weight:bold;color:rgb(175,0,255)\">in</span> natural_language_texts]\n\nCell <span class=\"ansi-green-fg\">In[16], line 2</span>, in <span class=\"ansi-cyan-fg\">&lt;listcomp&gt;</span><span class=\"ansi-blue-fg\">(.0)</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Apply tokenize_and_mask</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span> inputs_targets_pairs <span style=\"color:rgb(98,98,98)\">=</span> [<span class=\"ansi-yellow-bg\">tokenize_and_mask</span>(text) <span style=\"font-weight:bold;color:rgb(0,135,0)\">for</span> text <span style=\"font-weight:bold;color:rgb(175,0,255)\">in</span> natural_language_texts]\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'tokenize_and_mask' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#363fa981 .cell execution_count=18}\n``` {.python .cell-code}\ndef display_input_target_pairs(inputs_targets_pairs):\n    for i, inp_tgt_pair in enumerate(inputs_targets_pairs, 1):\n        inps, tgts = inp_tgt_pair\n        inps, tgts = pretty_decode(inps), pretty_decode(tgts)\n        print(f'[{i}]\\n\\n'\n              f'inputs:\\n{wrapper.fill(text=inps)}\\n\\n'\n              f'targets:\\n{wrapper.fill(text=tgts)}\\n\\n\\n\\n')\n```\n:::\n\n\n::: {#1f044cfa .cell execution_count=19}\n``` {.python .cell-code}\ndisplay_input_target_pairs(inputs_targets_pairs)\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[18], line 1</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span> display_input_target_pairs(<span class=\"ansi-yellow-bg\">inputs_targets_pairs</span>)\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'inputs_targets_pairs' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n# Part 2: Transfomer {#2}\n\nWe now load a Transformer model checkpoint that has been pre-trained using the above C4 dataset and decode from it. This will save you a lot of time rather than have to train your model yourself. Later in this notebook, we will show you how to fine-tune your model.\n\n![transformer](img/transformer.png){ width=\"300\" height = \"600\" }\n\n\nStart by loading in the model. We copy the checkpoint to local dir for speed, otherwise initialization takes a very long time. Last week you implemented the decoder part for the transformer. Now you will implement the encoder part. Concretely you will implement the following. \n\n![encoder](img/encoder.png){ width=\"300\" height = \"600\" }\n\n### 2.1 Transformer Encoder {#2.1}\n\nYou will now implement the transformer encoder. Concretely you will implement two functions. The first function is `FeedForwardBlock`.\n\n#### 2.1.1 The Feedforward Block {#2.1.1}\n\nThe `FeedForwardBlock` function is an important one so you will start by implementing it. To do so, you need to return a list of the following: \n\n- [`tl.LayerNorm()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) = layer normalization.\n- [`tl.Dense(d_ff)`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) = fully connected layer.\n- [`activation`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.activation_fns.Relu) = activation relu, tanh, sigmoid etc. \n- `dropout_middle` = we gave you this function (don't worry about its implementation).\n- [`tl.Dense(d_model)`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) = fully connected layer with same dimension as the model.\n- `dropout_final` = we gave you this function (don't worry about its implementation).\n\nYou can always take a look at [trax documentation](https://trax-ml.readthedocs.io/en/latest/) if needed.\n\n**Instructions**: Implement the feedforward part of the transformer. You will be returning a list. \n\n### Exercise 02 {#ex02}\n\n::: {#0e1f89dc .cell execution_count=20}\n``` {.python .cell-code}\n# UNQ_C2\n# GRADED FUNCTION: FeedForwardBlock\ndef FeedForwardBlock(d_model, d_ff, dropout, dropout_shared_axes, mode, activation):\n    \"\"\"Returns a list of layers implementing a feed-forward block.\n    Args:\n        d_model: int:  depth of embedding\n        d_ff: int: depth of feed-forward layer\n        dropout: float: dropout rate (how much to drop out)\n        dropout_shared_axes: list of integers, axes to share dropout mask\n        mode: str: 'train' or 'eval'\n        activation: the non-linearity in feed-forward layer\n    Returns:\n        A list of layers which maps vectors to vectors.\n    \"\"\"\n    \n    dropout_middle = tl.Dropout(rate=dropout,\n                                shared_axes=dropout_shared_axes, \n                                mode=mode)\n  \n    dropout_final = tl.Dropout(rate=dropout, \n                               shared_axes=dropout_shared_axes, \n                               mode=mode)\n\n    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n    \n    ff_block = [ \n        # trax Layer normalization \n        None,\n        # trax Dense layer using `d_ff`\n        None,\n        # activation() layer - you need to call (use parentheses) this func!\n        None,\n        # dropout middle layer\n        None,\n        # trax Dense layer using `d_model`\n        None,\n        # dropout final layer\n        None,\n    ]\n    \n    ### END CODE HERE ###\n    \n    return ff_block\n```\n:::\n\n\n::: {#515993b3 .cell execution_count=21}\n``` {.python .cell-code}\n# Print the block layout\nfeed_forward_example = FeedForwardBlock(d_model=512, d_ff=2048, dropout=0.8, dropout_shared_axes=0, mode = 'train', activation = tl.Relu)\nprint(feed_forward_example)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[None, None, None, None, None, None]\n```\n:::\n:::\n\n\n#### **Expected Output:**\n```CPP\n [LayerNorm, Dense_2048, Relu, Dropout, Dense_512, Dropout]\n```\n\n#### 2.1.2 The Encoder Block {#2.1.2}\n\nThe encoder block will use the `FeedForwardBlock`. \n\nYou will have to build two residual connections. Inside the first residual connection you will have the `tl.layerNorm()`, `attention`, and `dropout_` layers. The second residual connection will have the `feed_forward`.  \n\nYou will also need to implement `feed_forward`, `attention` and `dropout_` blocks. \n\nSo far you haven't seen the [`tl.Attention()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.Attention) and [`tl.Residual()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) layers so you can check the docs by clicking on them.\n\n### Exercise 03 {#ex03}\n\n::: {#d4aa20dd .cell execution_count=22}\n``` {.python .cell-code}\n# UNQ_C3\n# GRADED FUNCTION: EncoderBlock\ndef EncoderBlock(d_model, d_ff, n_heads, dropout, dropout_shared_axes,\n                  mode, ff_activation, FeedForwardBlock=FeedForwardBlock):\n    \"\"\"\n    Returns a list of layers that implements a Transformer encoder block.\n    The input to the layer is a pair, (activations, mask), where the mask was\n    created from the original source tokens to prevent attending to the padding\n    part of the input.\n    \n    Args:\n        d_model (int): depth of embedding.\n        d_ff (int): depth of feed-forward layer.\n        n_heads (int): number of attention heads.\n        dropout (float): dropout rate (how much to drop out).\n        dropout_shared_axes (int): axes on which to share dropout mask.\n        mode (str): 'train' or 'eval'.\n        ff_activation (function): the non-linearity in feed-forward layer.\n        FeedForwardBlock (function): A function that returns the feed forward block.\n    Returns:\n        list: A list of layers that maps (activations, mask) to (activations, mask).\n        \n    \"\"\"\n    \n    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n    \n    # Attention block\n    attention = tl.Attention( \n        # Use dimension of the model\n        d_feature=None,\n        # Set it equal to number of attention heads\n        n_heads=None,\n        # Set it equal `dropout`\n        dropout=None,\n        # Set it equal `mode`\n        mode=None\n    )\n    \n    # Call the function `FeedForwardBlock` (implemented before) and pass in the parameters\n    feed_forward = FeedForwardBlock( \n        None,\n        None,\n        None,\n        None,\n        None,\n        None\n    )\n    \n    # Dropout block\n    dropout_ = tl.Dropout( \n        # set it equal to `dropout`\n        rate=None,\n        # set it equal to the axes on which to share dropout mask\n        shared_axes=None,\n        # set it equal to `mode`\n        mode=None\n    )\n    \n    encoder_block = [ \n        # add `Residual` layer\n        tl.Residual(\n            # add norm layer\n            None,\n            # add attention\n            None,\n            # add dropout\n            None,\n        ),\n        # add another `Residual` layer\n        tl.Residual(\n            # add feed forward\n            None,\n        ),\n    ]\n    \n    ### END CODE HERE ###\n    \n    return encoder_block\n```\n:::\n\n\n::: {#037fc94c .cell execution_count=23}\n``` {.python .cell-code}\n# Print the block layout\nencoder_example = EncoderBlock(d_model=512, d_ff=2048, n_heads=6, dropout=0.8, dropout_shared_axes=0, mode = 'train', ff_activation=tl.Relu)\nprint(encoder_example)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:437: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n  if self._mode == 'predict' and self._state[1] is not ():  # pylint: disable=literal-comparison\n/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:910: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n  if state[0] is ():  # pylint: disable=literal-comparison\n/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:437: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n  if self._mode == 'predict' and self._state[1] is not ():  # pylint: disable=literal-comparison\n/home/oren/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:910: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n  if state[0] is ():  # pylint: disable=literal-comparison\n```\n:::\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[22], line 2</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Print the block layout</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span> encoder_example <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">EncoderBlock</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">d_model</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">512</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">d_ff</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">2048</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">n_heads</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">6</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">dropout</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">0.8</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">dropout_shared_axes</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">0</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">mode</span><span class=\"ansi-yellow-bg\"> </span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span class=\"ansi-yellow-bg\"> </span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">train</span><span style=\"color:rgb(175,0,0)\" class=\"ansi-yellow-bg\">'</span><span class=\"ansi-yellow-bg\">,</span><span class=\"ansi-yellow-bg\"> </span><span class=\"ansi-yellow-bg\">ff_activation</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">=</span><span class=\"ansi-yellow-bg\">tl</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">Relu</span><span class=\"ansi-yellow-bg\">)</span>\n<span class=\"ansi-green-fg ansi-bold\">      3</span> <span style=\"color:rgb(0,135,0)\">print</span>(encoder_example)\n\nCell <span class=\"ansi-green-fg\">In[21], line 61</span>, in <span class=\"ansi-cyan-fg\">EncoderBlock</span><span class=\"ansi-blue-fg\">(d_model, d_ff, n_heads, dropout, dropout_shared_axes, mode, ff_activation, FeedForwardBlock)</span>\n<span class=\"ansi-green-fg ansi-bold\">     49</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Dropout block</span>\n<span class=\"ansi-green-fg ansi-bold\">     50</span> dropout_ <span style=\"color:rgb(98,98,98)\">=</span> tl<span style=\"color:rgb(98,98,98)\">.</span>Dropout( \n<span class=\"ansi-green-fg ansi-bold\">     51</span>     <span style=\"font-style:italic;color:rgb(95,135,135)\"># set it equal to `dropout`</span>\n<span class=\"ansi-green-fg ansi-bold\">     52</span>     rate<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>,\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     56</span>     mode<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>\n<span class=\"ansi-green-fg ansi-bold\">     57</span> )\n<span class=\"ansi-green-fg ansi-bold\">     59</span> encoder_block <span style=\"color:rgb(98,98,98)\">=</span> [ \n<span class=\"ansi-green-fg ansi-bold\">     60</span>     <span style=\"font-style:italic;color:rgb(95,135,135)\"># add `Residual` layer</span>\n<span class=\"ansi-green-fg\">---&gt; 61</span>     <span class=\"ansi-yellow-bg\">tl</span><span style=\"color:rgb(98,98,98)\" class=\"ansi-yellow-bg\">.</span><span class=\"ansi-yellow-bg\">Residual</span><span class=\"ansi-yellow-bg\">(</span>\n<span class=\"ansi-green-fg ansi-bold\">     62</span> <span class=\"ansi-yellow-bg\">        </span><span style=\"font-style:italic;color:rgb(95,135,135)\" class=\"ansi-yellow-bg\"># add norm layer</span>\n<span class=\"ansi-green-fg ansi-bold\">     63</span> <span class=\"ansi-yellow-bg\">        </span><span style=\"font-weight:bold;color:rgb(0,135,0)\" class=\"ansi-yellow-bg\">None</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">     64</span> <span class=\"ansi-yellow-bg\">        </span><span style=\"font-style:italic;color:rgb(95,135,135)\" class=\"ansi-yellow-bg\"># add attention</span>\n<span class=\"ansi-green-fg ansi-bold\">     65</span> <span class=\"ansi-yellow-bg\">        </span><span style=\"font-weight:bold;color:rgb(0,135,0)\" class=\"ansi-yellow-bg\">None</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">     66</span> <span class=\"ansi-yellow-bg\">        </span><span style=\"font-style:italic;color:rgb(95,135,135)\" class=\"ansi-yellow-bg\"># add dropout</span>\n<span class=\"ansi-green-fg ansi-bold\">     67</span> <span class=\"ansi-yellow-bg\">        </span><span style=\"font-weight:bold;color:rgb(0,135,0)\" class=\"ansi-yellow-bg\">None</span><span class=\"ansi-yellow-bg\">,</span>\n<span class=\"ansi-green-fg ansi-bold\">     68</span> <span class=\"ansi-yellow-bg\">    </span><span class=\"ansi-yellow-bg\">)</span>,\n<span class=\"ansi-green-fg ansi-bold\">     69</span>     <span style=\"font-style:italic;color:rgb(95,135,135)\"># add another `Residual` layer</span>\n<span class=\"ansi-green-fg ansi-bold\">     70</span>     tl<span style=\"color:rgb(98,98,98)\">.</span>Residual(\n<span class=\"ansi-green-fg ansi-bold\">     71</span>         <span style=\"font-style:italic;color:rgb(95,135,135)\"># add feed forward</span>\n<span class=\"ansi-green-fg ansi-bold\">     72</span>         <span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>,\n<span class=\"ansi-green-fg ansi-bold\">     73</span>     ),\n<span class=\"ansi-green-fg ansi-bold\">     74</span> ]\n<span class=\"ansi-green-fg ansi-bold\">     76</span> <span style=\"font-style:italic;color:rgb(95,135,135)\">### END CODE HERE ###</span>\n<span class=\"ansi-green-fg ansi-bold\">     78</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> encoder_block\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:715</span>, in <span class=\"ansi-cyan-fg\">Residual</span><span class=\"ansi-blue-fg\">(shortcut, *layers)</span>\n<span class=\"ansi-green-fg ansi-bold\">    701</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">Residual</span>(<span style=\"color:rgb(98,98,98)\">*</span>layers, shortcut<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>):\n<span class=\"ansi-green-fg ansi-bold\">    702</span> <span style=\"color:rgb(188,188,188)\">  </span><span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"Wraps a series of layers with a residual connection.</span>\n<span class=\"ansi-green-fg ansi-bold\">    703</span> \n<span class=\"ansi-green-fg ansi-bold\">    704</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">  Args:</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">    713</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">      A layer representing a residual connection paired with a layer series.</span>\n<span class=\"ansi-green-fg ansi-bold\">    714</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">  \"\"\"</span>\n<span class=\"ansi-green-fg\">--&gt; 715</span>   layers <span style=\"color:rgb(98,98,98)\">=</span> <span class=\"ansi-yellow-bg\">_ensure_flat</span><span class=\"ansi-yellow-bg\">(</span><span class=\"ansi-yellow-bg\">layers</span><span class=\"ansi-yellow-bg\">)</span>\n<span class=\"ansi-green-fg ansi-bold\">    716</span>   layer <span style=\"color:rgb(98,98,98)\">=</span> layers[<span style=\"color:rgb(98,98,98)\">0</span>] <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> <span style=\"color:rgb(0,135,0)\">len</span>(layers) <span style=\"color:rgb(98,98,98)\">==</span> <span style=\"color:rgb(98,98,98)\">1</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">else</span> Serial(layers)\n<span class=\"ansi-green-fg ansi-bold\">    717</span>   <span style=\"font-style:italic;color:rgb(95,135,135)\"># TODO(jonni): Should we require layer.n_out = 1 and shortcut.n_out = 1?</span>\n\nFile <span class=\"ansi-green-fg\">~/work/notes/notes-nlp/.venv/lib/python3.10/site-packages/trax/layers/combinators.py:1110</span>, in <span class=\"ansi-cyan-fg\">_ensure_flat</span><span class=\"ansi-blue-fg\">(layers)</span>\n<span class=\"ansi-green-fg ansi-bold\">   1108</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">for</span> obj <span style=\"font-weight:bold;color:rgb(175,0,255)\">in</span> layers:\n<span class=\"ansi-green-fg ansi-bold\">   1109</span>   <span style=\"font-weight:bold;color:rgb(0,135,0)\">if</span> <span style=\"font-weight:bold;color:rgb(175,0,255)\">not</span> <span style=\"color:rgb(0,135,0)\">isinstance</span>(obj, base<span style=\"color:rgb(98,98,98)\">.</span>Layer):\n<span class=\"ansi-green-fg\">-&gt; 1110</span>     <span style=\"font-weight:bold;color:rgb(0,135,0)\">raise</span> <span style=\"font-weight:bold;color:rgb(215,95,95)\">ValueError</span>(\n<span class=\"ansi-green-fg ansi-bold\">   1111</span>         <span style=\"color:rgb(175,0,0)\">f</span><span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">Found nonlayer object (</span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span>obj<span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"color:rgb(175,0,0)\">) in layers: </span><span style=\"font-weight:bold;color:rgb(175,95,135)\">{</span>layers<span style=\"font-weight:bold;color:rgb(175,95,135)\">}</span><span style=\"color:rgb(175,0,0)\">'</span>)\n<span class=\"ansi-green-fg ansi-bold\">   1112</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">return</span> layers\n\n<span class=\"ansi-red-fg\">ValueError</span>: Found nonlayer object (None) in layers: [None, None, None]</pre>\n```\n:::\n\n:::\n:::\n\n\n#### **Expected Output:**\n```CPP\n[Serial_in2_out2[\n  Branch_in2_out3[\n    None\n    Serial_in2_out2[\n      LayerNorm\n      Serial_in2_out2[\n        Dup_out2\n        Dup_out2\n        Serial_in4_out2[\n          Parallel_in3_out3[\n            Dense_512\n            Dense_512\n            Dense_512\n          ]\n          PureAttention_in4_out2\n          Dense_512\n        ]\n      ]\n      Dropout\n    ]\n  ]\n  Add_in2\n], Serial[\n  Branch_out2[\n    None\n    Serial[\n      LayerNorm\n      Dense_2048\n      Relu\n      Dropout\n      Dense_512\n      Dropout\n    ]\n  ]\n  Add_in2\n]]\n```\n\n### 2.1.3 The Transformer Encoder {#2.1.3}\n\nNow that you have implemented the `EncoderBlock`, it is time to build the full encoder. BERT, or Bidirectional Encoder Representations from Transformers is one such encoder. \n\nYou will implement its core code in the function below by using the functions you have coded so far. \n\nThe model takes in many hyperparameters, such as the `vocab_size`, the number of classes, the dimension of your model, etc. You want to build a generic function that will take in many parameters, so you can use it later. At the end of the day, anyone can just load in an API and call transformer, but we think it is important to make sure you understand how it is built. Let's get started. \n\n**Instructions:** For this encoder you will need a `positional_encoder` first (which is already provided) followed by `n_layers` encoder blocks, which are the same encoder blocks you previously built. Once you store the `n_layers` `EncoderBlock` in a list, you are going to encode a `Serial` layer with the following sublayers: \n\n- [`tl.Branch`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Branch): helps with the branching and has the following sublayers:\n    - `positional_encoder`.\n    - [`tl.PaddingMask()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.PaddingMask): layer that maps integer sequences to padding masks.\n- Your list of `EncoderBlock`s\n- [`tl.Select([0], n_in=2)`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Select):  Copies, reorders, or deletes stack elements according to indices.\n- [`tl.LayerNorm()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm).\n- [`tl.Mean()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Mean): Mean along the first axis.\n- `tl.Dense()` with n_units set to n_classes. \n- `tl.LogSoftmax()`   \n\nPlease refer to the [trax documentation](https://trax-ml.readthedocs.io/en/latest/) for further information. \n\n\n\n### Exercise 04 {#ex04}\n\n::: {#2e0473ea .cell execution_count=24}\n``` {.python .cell-code}\n# UNQ_C4\n# GRADED FUNCTION: TransformerEncoder\ndef TransformerEncoder(vocab_size=vocab_size,\n                       n_classes=10,\n                       d_model=512,\n                       d_ff=2048,\n                       n_layers=6,\n                       n_heads=8,\n                       dropout=0.1,\n                       dropout_shared_axes=None,\n                       max_len=2048,\n                       mode='train',\n                       ff_activation=tl.Relu,\n                      EncoderBlock=EncoderBlock):\n    \n    \"\"\"\n    Returns a Transformer encoder model.\n    The input to the model is a tensor of tokens.\n  \n    Args:\n        vocab_size (int): vocab size. Defaults to vocab_size.\n        n_classes (int): how many classes on output. Defaults to 10.\n        d_model (int): depth of embedding. Defaults to 512.\n        d_ff (int): depth of feed-forward layer. Defaults to 2048.\n        n_layers (int): number of encoder/decoder layers. Defaults to 6.\n        n_heads (int): number of attention heads. Defaults to 8.\n        dropout (float): dropout rate (how much to drop out). Defaults to 0.1.\n        dropout_shared_axes (int): axes on which to share dropout mask. Defaults to None.\n        max_len (int): maximum symbol length for positional encoding. Defaults to 2048.\n        mode (str): 'train' or 'eval'. Defaults to 'train'.\n        ff_activation (function): the non-linearity in feed-forward layer. Defaults to tl.Relu.\n        EncoderBlock (function): Returns the encoder block. Defaults to EncoderBlock.\n  \n    Returns:\n        trax.layers.combinators.Serial: A Transformer model as a layer that maps\n        from a tensor of tokens to activations over a set of output classes.\n    \"\"\"\n    \n    positional_encoder = [\n        tl.Embedding(vocab_size, d_model),\n        tl.Dropout(rate=dropout, shared_axes=dropout_shared_axes, mode=mode),\n        tl.PositionalEncoding(max_len=max_len)\n    ]\n    \n    ### START CODE HERE (REPLACE INSTANCES OF 'None' WITH YOUR CODE) ###\n    \n    # Use the function `EncoderBlock` (implemented above) and pass in the parameters over `n_layers`\n    encoder_blocks = [None for _ in range(None)]\n\n    # Assemble and return the model.\n    return tl.Serial(\n        # Encode\n        tl.Branch(\n            # Use `positional_encoder`\n            None,\n            # Use trax padding mask\n            None,\n        ),\n        # Use `encoder_blocks`\n        None,\n        # Use select layer\n        None,\n        # Use trax layer normalization\n        None,\n        # Map to output categories.\n        # Use trax mean. set axis to 1\n        None,\n        # Use trax Dense using `n_classes`\n        None,\n        # Use trax log softmax\n        None,\n    )\n\n    ### END CODE HERE ###\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[23], line 3</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># UNQ_C4</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># GRADED FUNCTION: TransformerEncoder</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span> <span style=\"font-weight:bold;color:rgb(0,135,0)\">def</span><span style=\"color:rgb(188,188,188)\"> </span><span style=\"color:rgb(0,0,255)\">TransformerEncoder</span>(vocab_size<span style=\"color:rgb(98,98,98)\">=</span><span class=\"ansi-yellow-bg\">vocab_size</span>,\n<span class=\"ansi-green-fg ansi-bold\">      4</span>                        n_classes<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">10</span>,\n<span class=\"ansi-green-fg ansi-bold\">      5</span>                        d_model<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">512</span>,\n<span class=\"ansi-green-fg ansi-bold\">      6</span>                        d_ff<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">2048</span>,\n<span class=\"ansi-green-fg ansi-bold\">      7</span>                        n_layers<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">6</span>,\n<span class=\"ansi-green-fg ansi-bold\">      8</span>                        n_heads<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">8</span>,\n<span class=\"ansi-green-fg ansi-bold\">      9</span>                        dropout<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">0.1</span>,\n<span class=\"ansi-green-fg ansi-bold\">     10</span>                        dropout_shared_axes<span style=\"color:rgb(98,98,98)\">=</span><span style=\"font-weight:bold;color:rgb(0,135,0)\">None</span>,\n<span class=\"ansi-green-fg ansi-bold\">     11</span>                        max_len<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">2048</span>,\n<span class=\"ansi-green-fg ansi-bold\">     12</span>                        mode<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(175,0,0)\">'</span><span style=\"color:rgb(175,0,0)\">train</span><span style=\"color:rgb(175,0,0)\">'</span>,\n<span class=\"ansi-green-fg ansi-bold\">     13</span>                        ff_activation<span style=\"color:rgb(98,98,98)\">=</span>tl<span style=\"color:rgb(98,98,98)\">.</span>Relu,\n<span class=\"ansi-green-fg ansi-bold\">     14</span>                       EncoderBlock<span style=\"color:rgb(98,98,98)\">=</span>EncoderBlock):\n<span class=\"ansi-green-fg ansi-bold\">     16</span> <span style=\"color:rgb(188,188,188)\">    </span><span style=\"font-style:italic;color:rgb(175,0,0)\">\"\"\"</span>\n<span class=\"ansi-green-fg ansi-bold\">     17</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">    Returns a Transformer encoder model.</span>\n<span class=\"ansi-green-fg ansi-bold\">     18</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">    The input to the model is a tensor of tokens.</span>\n<span class=\"ansi-green-fg\">   (...)</span>\n<span class=\"ansi-green-fg ansi-bold\">     36</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">        from a tensor of tokens to activations over a set of output classes.</span>\n<span class=\"ansi-green-fg ansi-bold\">     37</span> <span style=\"font-style:italic;color:rgb(175,0,0)\">    \"\"\"</span>\n<span class=\"ansi-green-fg ansi-bold\">     39</span>     positional_encoder <span style=\"color:rgb(98,98,98)\">=</span> [\n<span class=\"ansi-green-fg ansi-bold\">     40</span>         tl<span style=\"color:rgb(98,98,98)\">.</span>Embedding(vocab_size, d_model),\n<span class=\"ansi-green-fg ansi-bold\">     41</span>         tl<span style=\"color:rgb(98,98,98)\">.</span>Dropout(rate<span style=\"color:rgb(98,98,98)\">=</span>dropout, shared_axes<span style=\"color:rgb(98,98,98)\">=</span>dropout_shared_axes, mode<span style=\"color:rgb(98,98,98)\">=</span>mode),\n<span class=\"ansi-green-fg ansi-bold\">     42</span>         tl<span style=\"color:rgb(98,98,98)\">.</span>PositionalEncoding(max_len<span style=\"color:rgb(98,98,98)\">=</span>max_len)\n<span class=\"ansi-green-fg ansi-bold\">     43</span>     ]\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'vocab_size' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n::: {#7d1883d2 .cell execution_count=25}\n``` {.python .cell-code}\n# Run this cell to see the structure of your model\n# Only 1 layer is used to keep the output readable\nTransformerEncoder(n_layers=1)\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\nCell <span class=\"ansi-green-fg\">In[24], line 3</span>\n<span class=\"ansi-green-fg ansi-bold\">      1</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Run this cell to see the structure of your model</span>\n<span class=\"ansi-green-fg ansi-bold\">      2</span> <span style=\"font-style:italic;color:rgb(95,135,135)\"># Only 1 layer is used to keep the output readable</span>\n<span class=\"ansi-green-fg\">----&gt; 3</span> <span class=\"ansi-yellow-bg\">TransformerEncoder</span>(n_layers<span style=\"color:rgb(98,98,98)\">=</span><span style=\"color:rgb(98,98,98)\">1</span>)\n\n<span class=\"ansi-red-fg\">NameError</span>: name 'TransformerEncoder' is not defined</pre>\n```\n:::\n\n:::\n:::\n\n\n#### **Expected Output:**\n\n```CPP\nSerial[\n  Branch_out2[\n    [Embedding_32000_512, Dropout, PositionalEncoding]\n    PaddingMask(0)\n  ]\n  Serial_in2_out2[\n    Branch_in2_out3[\n      None\n      Serial_in2_out2[\n        LayerNorm\n        Serial_in2_out2[\n          Dup_out2\n          Dup_out2\n          Serial_in4_out2[\n            Parallel_in3_out3[\n              Dense_512\n              Dense_512\n              Dense_512\n            ]\n            PureAttention_in4_out2\n            Dense_512\n          ]\n        ]\n        Dropout\n      ]\n    ]\n    Add_in2\n  ]\n  Serial[\n    Branch_out2[\n      None\n      Serial[\n        LayerNorm\n        Dense_2048\n        Relu\n        Dropout\n        Dense_512\n        Dropout\n      ]\n    ]\n    Add_in2\n  ]\n  Select[0]_in2\n  LayerNorm\n  Mean\n  Dense_10\n  LogSoftmax\n]\n```\n\n**NOTE Congratulations! You have completed all of the graded functions of this assignment.** Since the rest of the assignment takes a lot of time and memory to run we are providing some extra ungraded labs for you to see this model in action.\n\n**Keep it up!**\n\nTo see this model in action continue to the next 2 ungraded labs. **We strongly recommend you to try the colab versions of them as they will yield a much smoother experience.** The links to the colabs can be found within the ungraded labs or if you already know how to open files within colab here are some shortcuts (if not, head to the ungraded labs which contain some extra instructions):\n\n[BERT Loss Model Colab](https://drive.google.com/file/d/1EHAbMnW6u-GqYWh5r3Z8uLbz4KNpKOAv/view?usp=sharing)\n\n[T5 SQuAD Model Colab](https://drive.google.com/file/d/1c-8KJkTySRGqCx_JjwjvXuRBTNTqEE0N/view?usp=sharing)\n\n",
    "supporting": [
      "assignment_files"
    ],
    "filters": [],
    "includes": {}
  }
}