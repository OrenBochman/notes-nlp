<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">

<title>Speech – NLP Course Notes &amp; Research</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1372234da3246ce8e868649689ba5ed0.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-d99a2a2a191b5c7f2a9a83135e7f0803.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V0T6EFS8LY"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-V0T6EFS8LY', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>

      .quarto-title-block .quarto-title-banner {
        background: images/banner_deep.jpg;
      }
</style>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Speech – NLP Course Notes &amp; Research">
<meta property="og:description" content="CMU CS11-737: Syntax and Parsing">
<meta property="og:image" content="https://orenbochman.github.io/notes-nlp/images/nlp-brain-wordcloud.jpg">
<meta property="og:site_name" content="NLP Course Notes &amp; Research">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">NLP Course Notes &amp; Research</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Speech</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Speech</h1>
            <p class="subtitle lead">CMU CS11-737: Syntax and Parsing</p>
                                <div class="quarto-categories">
                <div class="quarto-category">Attention</div>
                <div class="quarto-category">Multilingual NLP</div>
                <div class="quarto-category">NLP</div>
                <div class="quarto-category">Notes</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-body">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Tuesday, March 29, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Classification &amp; Vector Spaces</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Logistic Regression</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Frequencies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Visualizing tweets</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Probability &amp; Bayes Rule</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Visualizing Naive Bayes</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Vector Space Models &amp; PCA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Linear algebra with NumPy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Manipulating word embeddings</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">MT &amp; Document Search via KNN</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vector manipulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Hash functions and multiplanes</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilistic Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Autocorrect &amp; Dynamic Programming</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Building the vocabulary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Candidates from String Edits</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">POS tagging &amp; HMMS</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vocabulary with unknowns</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Working with tags and Numpy</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Autocomplete &amp; Language Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - N-grams Corpus preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Building the language model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Out of vocabulary words</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Word embeddings with neural networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Data preparation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Intro to CBOW</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Training the CBOW</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequence Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Neural Networks for Sentiment Analysis</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Introduction to Trax</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Classes and Subclasses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Data Generators</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">RNN for Language Modeling</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Hidden State Activation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Calculating Perplexity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Vanilla RNNs, GRUs and the scan function</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L4 - Creating a GRU model using Trax</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false">
 <span class="menu-text">LSTMs and Named Entity Recognition</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vanishing Gradients</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false">
 <span class="menu-text">Siamese Networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Creating a Siamese Model using Trax</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Modified Triplet Loss</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Evaluate a Siamese Model</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true">
 <span class="menu-text">NLP with Attention Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false">
 <span class="menu-text">Neural Machine Translation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-17" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Stack Semantics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - BLEU Score</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false">
 <span class="menu-text">Text Summarization</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-18" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Attention</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - The Transformer Decoder</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false">
 <span class="menu-text">Question Answering</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-19" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - SentencePiece and BPE</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - BERT Loss</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - T5</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false">
 <span class="menu-text">Chat Bots</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-20" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Reformer LSH</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Revnet</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-21" role="navigation" aria-expanded="true">
 <span class="menu-text">Papers</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-21" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-21" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2014-NMT-by-jointly-learning-to-align-and-translate/" class="sidebar-item-text sidebar-link">
 <span class="menu-text">NMT by Jointly Learning to Align and Translate</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2015-LSH/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Practical &amp; Optimal LSH for Angular Distance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2015-effective-approaches-to-attention-based-NMT/" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Effective Approaches to Attention-based NMT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2016-coverage-embedding-models-for-NMT/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coverage Embedding Models for NMT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2016-neural-morphological-segmentation/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Morphological Analysis Encoding-Decoding Canonical Segments</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2017-attention-is-all-you-need/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Attention is all you need</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2017-data-augmentation-low-resource-NMT/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data augmentation for low-resource NMT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2018-ELMo/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ELMO</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2018-BERT/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BERT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2018-PTWM-NMT/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PTWM NMT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2019-morphological-embeddings/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Morphological embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2022-nakdimon/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">nakdimon</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2023-exposing-glitches/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">exposing glitches</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2023-MBR-all-the-way-down/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MBR all the way down</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2024-MBR-decoding/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MBR decoding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../reviews/paper/2025-xLSTM/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">xLSTM</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#outline" id="toc-outline" class="nav-link active" data-scroll-target="#outline">Outline</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection">Reflection</a></li>
  <li><a href="#navajo-in-10" id="toc-navajo-in-10" class="nav-link" data-scroll-target="#navajo-in-10">Navajo in 10</a></li>
  <li><a href="#papers" id="toc-papers" class="nav-link" data-scroll-target="#papers">Papers</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/notes/cs11-737-w19-syntax-and-parsing/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full column-body" id="quarto-document-content">






<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/tiling.png" class="nolightbox img-fluid figure-img" width="200"></p>
<figcaption>course banner</figcaption>
</figure>
</div><div id="vid-01" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-vid figure">
<div aria-describedby="vid-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/f-3N0stPtbw" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-vid" id="vid-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Video&nbsp;1: Lesson Video
</figcaption>
</figure>
</div><div id="sup-slide-deck1" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides" style="@page {size: 16in 9in;  margin: 0;}">
<figure class="quarto-float quarto-float-sup figure">
<div aria-describedby="sup-slide-deck1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="slides" title="This week’s slides"><embed src="slides.pdf" style="@page {size: 16in 9in;  margin: 0;}" width="420" height="340"></a></p>
<figcaption>This week’s slides</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-sup quarto-uncaptioned" id="sup-slide-deck1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Supplementary Figure&nbsp;1
</figcaption>
</figure>
</div><div id="sup-slide-deck2" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides" style="@page {size: 16in 9in;  margin: 0;}">
<figure class="quarto-float quarto-float-sup figure">
<div aria-describedby="sup-slide-deck2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides2.pdf" class="lightbox" data-gallery="slides" title="This week’s slides"><embed src="slides2.pdf" style="@page {size: 16in 9in;  margin: 0;}" width="420" height="340"></a></p>
<figcaption>This week’s slides</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-sup quarto-uncaptioned" id="sup-slide-deck2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Supplementary Figure&nbsp;2
</figcaption>
</figure>
</div></div>


<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Obj·ectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Syntax, Major Word Order</li>
<li>Dependency Parsing and Models</li>
<li>Explanation and demo of AutoLex, a system for linguistic discovery</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<!-- Transcript here is machine generated no punctuation and I eddited it a but but it needs more work and I don't see the benefits unless I can run it through some tool. -->
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>This time we’re going to be talking about syntax in general but dependency parsing in particular and um when we talk about linguistic structure and syntax there’s kind of two types of linguistic structure that we often talk about the first one is dependency structure which focuses on the relations between words and it looks a little bit like this um so for example we have the word saw and the word saw as the root of the sentence and um this is connected to other words uh like i and with uh and girl and then we also have phrase structure um which is focuses on the kind of structure of the sentence as opposed to the relationships between words um both of these are common expressions of syntax or common ways to represent syntax in particular phrase structure was widely used in english uh and uh you know kind of developed by chomsky and other very influential linguists from you know 1950s 1960s until now um and however recently there’s been a big move towards dependency structure uh and the reason why is because they’re relatively straightforward to express and in particularly relatively straightforward to express across a wide variety of languages um and so for example uh we can do things like say saw is the subject of the sentence so or saw is the root of the sentence and then it has a subject it has a direct object and it has a prepositional phrase and um these kinds of things are relatively you know constant across languages maybe not prepositional praise but you know a phrase like this and um it’s particularly good for multilinguality because in some free word order languages it’s also possible to have basically words intervene into a phrase which makes it very difficult to say this is like a particular phrase um and uh what i mean by this is um if you have a dependency tree and words cross um it’s very hard to come up with an example of this in english i don’t know if anybody knows one of the top of your head like ellen okay it’s like um i went um i saw a movie yesterday that was good so this is a relatively natural english sentence um but actually yesterday um yesterday is a child of saw and movie uh that is a child of movie so you can see the dependency is crossing here um basically the only place where we get this in um in english is uh is with adverbs adverbs can be like are basically the only thing with really free word order in english um but they break this kind of phrase structure uh representation because you can’t say that any there’s a consistent phrase here so basically um uh that’s an issue and there are other languages where these are like extremely common where the word order is free for all different kinds of phrases so um because of this a lot of syntactic analysis is kind of moving in the direction of using dependencies instead of phrase structure</p>
</section>
<section id="universal-dependencies" class="level2">
<h2 class="anchored" data-anchor-id="universal-dependencies">Universal Dependencies</h2>
<p>There is an amazing effort called the universal dependencies treebank that gives you a standard format for parse trees in many languages this started out of stanford dependencies and also universal part of speech tags and universal dependencies created by google and the basic motivation for this was they wanted to be able to build like one parser and use it for all of the languages instead of have having uh 400 parsers for 400 languages so if you come up with something in a unified format that you can that you can parse in process then that makes deploying to many different languages much easier the disadvantage of doing this is that in order to make something universal you have to give up on some language specific details so there are details that don’t easily fit within this universal dependencies format um but in most cases they cover you know a lot of the major things that you see in different languages</p>
</section>
<section id="syntax-vs-semantic" class="level2">
<h2 class="anchored" data-anchor-id="syntax-vs-semantic">Syntax vs Semantic</h2>
<p>An other thing that you should know about if you’re considering dependencies or kind of like dependency structure is that there’s actually different types of dependencies – Syntactic and Semantic. And they look very different. <strong>Syntactic dependencies</strong> basically are trying to as closely as possible reflect the phrase structure of the sentence and how sentences are put together So for example in a <em>prepositional phrase</em> the head of the <em>prepositional phrase</em> will be a <em>preposition</em>. Whereas for <strong>semantic dependencies</strong> the head of a prepositional phrase will be like the main <em>noun</em> or <em>verb</em> in that <em>prepositional phrase</em>.</p>
<p>The idea being that syntactic dependencies are good for understanding the structure of the language whereas semantic dependencies might be good, for example, for Question Answering because if you ask a question if you have a sentence like the one i had here “I saw a movie yesterday that was good” or “I saw a movie yesterday at the movie theater” and you want to say where did the person watch the movie and the <em>syntactic dependency</em> <em>movie</em> would be connected to <em>at</em> so you would have to like jump down the tree several nodes wherein <em>semantic dependencies</em> <em>movie</em> would be connected to <em>movie theater</em>. It would have an appropriate label so you could just like look up the edge and connect the two together to answer that question in a single hop instead of multiple hops. This is really important! Aditi might talk about things related to this later and you need to choose which one you want based on which application you’re interested in</p>
</section>
<section id="semantics" class="level2">
<h2 class="anchored" data-anchor-id="semantics">Semantics</h2>
<p>One of the very interesting things about uh yeah sorry god the last play the the semantics uh how do we club all the nouns together like we need some external knowledge to understand the semantic of the norm um do you mean like a noun phrase or no no just to know just a name of something so like it’s a concept right like so that’s a good question so how how do we understand the semantics of a noun or something so even semantic dependencies this is only talking about the relationship between words in the sentence it’s now telling you about the underlying semantics of the nouns so if you wanted to know about like underlying semantics of a noun you would have to have something else like a semantic um like knowledge base or something like this the typical version of this is something like wordnet which basically says well let’s say we have chevrolet chevrolet is a type of car which is a type of vehicle which is a type of uh you know man-made object which is a type of object or something like this and um i think some people might have used wordnet it’s now like lesson style than it was before but um it’s it’s basically telling you this information and there’s actually since we’re in a multilingual class i can tell you about something like babelnet um which is a multilingual uh like a multilingual version of wordnet so if i um put in um [Music] oh i’m sorry i was searching in english no wonder so if i search for this in japanese it can tell you that um this word is a concept for like automobile and it’s it has is a has part part of uh relations and all of these are linked across languages so for example it’s in um i can’t find the language link but here yeah here yeah so you can see that it links to car automobile other things like this so it’s all linked together so if you want to specifically talk about semantics of words on their own then you can either use things like this or you can use word embeddings uh also which give a concept so can’t you get a semantic graph so um what word net tells you is it tells you about the semantics of words it doesn’t tell you about the semantics of like words relating to each other so it doesn’t tell you for example that challenge is the object of love it doesn’t tell you that a challenge is being loved which is what this uh this semantic dependency tells you and then if you go even a little bit farther there’s something called predicate argument analysis or frame semantic parsing or something that gives you an even more abstract version but semantic dependencies are kind of like something related to that so regular um regular universal dependencies are semantic uh sud is syntactic so you should know the difference between them so there’s a lot of cross-lingual differences in structure so we’ve talked about this a lot before like word ordering um so we have svo um we have hindi which is a verb final and arabic which is verb initial and i got this actually from the pud tree bank which is the parallel universal dependencies treebank it has a whole bunch of translated sentences in different languages uh along with their dependency trees and the interesting thing is these sentences all i guess mean the same thing uh hindi speakers can confirm that’s actually the case yes um nobody’s saying no so i’ll assume i’ll assume yes but you can see the structure is very different so we have like is and then in english we have um we have uh is uh is in the middle of the sentence with the noun uh first and the verb second and then what i can what i can see is uh we in handy we have an auxiliary verb but then we have a verb here and then we have the object and i guess an oblique uh indirect object and stuff like this but these all come on the left side of the verb so we can tell that hindi is verb final and then for arabic we can tell that arabic is verb initial and we have a noun here at position um sorry a subject and then an oblique here so you can tell the difference in the structure even though i i can’t even read the script in arabic and hindi i can still tell that just by looking at the dependency</p>
</section>
<section id="dependencies" class="level2">
<h2 class="anchored" data-anchor-id="dependencies">Dependencies</h2>
<p>so what can we do with dependencies so i actually previously they were used for feature engineering and systems um and they’re still useful in some cases but now our default is just to you know pull up m mbert or xlmr and fine tune it and get reasonable accuracy on a lot of tasks that we care about and in fact um you know dependencies are probably captured somewhat to some extent implicitly in these models um so why care about syntax um i would argue that these are more useful now in human-facing applications and a while ago june 3rd i think last year i actually asked a question on twitter what are convicts are i guess two years ago um i asked a question on twitter uh what are convincing use cases in 2020 uh for dependencies and i got 39 answers um and just to give some examples they still can be useful for incorporating inductive bias into neural models so biasing self-attention to follow syntax or other things like this i think in it still is useful to encourage models to be right for kind of like the right reasons instead of the wrong reasons um because this improves model robustness especially out of domain and other things like this and syntactic conductive biases can provide you a way to do this another thing is understanding language structure and this is an example from the aditi’s work which he’s going to present in much more detail in a few minutes so um uh i’ll let her talk to that another very interesting example is um searching over parsed corpora so like i talked about before um like let’s say we want to find examples with that are talking about x was the founder of y so we want to find it lots of examples of founders of something or other um you could try to do this with a regular expression but it’d be pretty tough to come up with a regular expression that gives you this you know with high precision high recall um but if instead you uh find where founder is the verb uh the subject and it has a subject and uh um an object here uh then you can just uh search all examples of this and it actually highlights uh the appropriate ones here so this is um from the spike system created by ai2 and another thing is analysis of other linguistic phenomena or like you know if you want to identify for example when um uh this is coincidentally i actually um one one of these is from <a href="https://strubell.github.io/">Emma Strubell</a> you know assistant professor here another one is from <a href="https://maartensap.com/">Martin Sap</a> who will be an assistant professor here I actually made the slides before I knew he was going to be a professor here but um but anyway this is examining whether film scripts demonstrate that uh people have power or agency and analyzing it along the gender of the participants in the film so whether male or female characters are you know uh like demonstrating more power agency and film scripts and this is used to answer like social and uh sociologically interesting questions for example and this is made a lot easier by analyzing the syntax because then you can do things uh like say who did what to whom more easily</p>
</section>
<section id="parsing" class="level2">
<h2 class="anchored" data-anchor-id="parsing">Parsing</h2>
<p>This is kind of a motivation for like what our dependency parses why would you want to be using uh dependency parts or syntax in general um so to talk a little bit more about dependency parsing how would you get these especially in a multilingual fashion um parsing is predicting linguistic structure from an input sentence and there’s a couple methods that we use to do this the first one is transition based models and basically the way they work is they step through some steps one by one until we we can turn those steps into a tree another one is graph based models and basically they calculate the probability for each edge uh in a dependency parse and perform some sort of dynamic programming over them and if you’re familiar with like part of speech tagging from the first assignment transition based models are kind of like um a history based model for part of speech tagging and what this would look like is if you um if you had like an encoder decoder model where the next tag was always conditioned on the previous tag for graph based models we didn’t really cover crfs here but if you’re familiar with <a href="https://en.wikipedia.org/wiki/Conditional_random_field">CRF</a>s the graph based models are a little bit like these they calculate some scores and then they have a dynamic program to get the best output so just to give a very brief flavor of what these look like</p>
</section>
<section id="shift-reduce" class="level2">
<h2 class="anchored" data-anchor-id="shift-reduce">Shift Reduce</h2>
<p>Shift reduce parsing basically it processes words one by one left to right and it maintains two data structures one is a queue of unprocessed words another is a stack of partially processed words and at each point we choose to either shift moving one word from the queue to the stack um reduce left where the top word on the stack becomes the head of the second word or reduce right where the second word on the stack is becomes ahead of the top word and we learn how to choose each of these actions with a classifier so just to give an example um we want to uh parse the sentence i saw a girl so what we do is we first shift and move something sorry this says buffer it’s the same thing as q uh there’s multiple ways to say this but just think buffer equals q um we move uh one thing from the uh the queue to the stack we move another word from the queue to the stack and then uh sorry that’s another typo this should be reduced left um and so we reduce left and we get a left uh arc here then we shift again and then we um shift again then we reduce left we reduce right and then we reduce right and then um we have a uh final basically parse tree here so basically what you can see is at each point we choose an action and based on the action we add we either uh move something from the queue to the stack or we add an arc between the top two things on the stack so you probably won’t need to implement this yourself um there are plenty of good dependency parsers out there but just to get an idea of what the algorithm looks like in case you’re interested in doing that</p>
</section>
<section id="classification" class="level2">
<h2 class="anchored" data-anchor-id="classification">Classification</h2>
<p>um so the way we do classification for any variety of shift-reduced parsing is basically we take in the stack and the buffer and uh we need to choose between one of the actions uh shift left and right so this is a regular classification problem three-way classification problem and um we can encode uh the stack configuration uh with any variety of recurrent neural network or auto-regressive neural network so one example of this is where we encode basically the stack the previous history of actions and the buffer and feed them into the uh into the model an even simpler way of doing this is you just encode the words in the input sentence and um then have a decoder that generates the actions for you so you could even just throw that into like a regular transformer model and train it as well it would just be you know input is the entire words in the the source sentence and then the output is the sequence of actions so that’s a basic like very quick overview of shift-reduce pricing are there any questions or yeah so you said that we use the dependency passing as an auxiliary fast increase of westminster’s products and inputs yeah so now we have some methods about like adding adapters into xlr to make them more robust for a given language so with adapters do we still need these to increase robustness or if you have a car first and find an adapter and yeah so that’s a really good question um if we have something like adapters uh like multilingual adapters do we still need something like an auxiliary test like dependency parsing and i i would say it’s quite likely that those two things are kind of orthogonal in that um adapters are allowing you to more effectively adapt to individual tasks whereas the supervision that you would get from a dependency parsing objective would um essentially enforce the model to more strictly follow the syntax of the sentence as linguists kind of describe it so i think that both probably would stack together but i i don’t have empirical results or i i don’t know immediately off the top of my head about a paper that demonstrates maddox yeah so i know medics but i don’t remember if they used like dependency parsing it’s an auxiliary task but they show performance improvement on very low resource languages that xlr is failing and then they used access to improve the performance but i’m not sure whether it was one of the things and so basically the the comment to repeat it for other people who couldn’t hear um the so there’s a paper called man x that basically does adapters we talked a little bit about adapters in class i think um but basically um uh they demonstrated that it improves on very low resource languages but i it’s not perfect still after using medx right and i think this and that could be combined together probably to improve a bit but as i said i think that’s not the main good use case of dependencies right now i think the better use cases of the dependencies are they give very like intuitive human facing interfaces if you want to do like analysis of corpora or extract detected phenomena on a more holistic level or other things like that so it was actually inspired by one of your tweets you had put a tweet i think a year back that when a person releases the model for 100 languages doesn’t mean it works languages so yeah that changed my perspective that okay it’s not perfect then i kind of searched for these people yeah so i um uh to repeat in case people in the back couldn’t hear i i said something uh on twitter about a year ago where it’s like when somebody releases a model for 100 languages that doesn’t necessarily mean it works on 100 languages it means it does something on 100 languages probably and it’s probably better than nothing but it’s not perfect for sure so and i’m sure you guys all noticed this as you were implementing your various assignments as well cool.</p>
</section>
<section id="graph-based" class="level2">
<h2 class="anchored" data-anchor-id="graph-based">Graph based</h2>
<p>The other alternative is a graph based parsing and graph based parsing basically what it looks like is we express the sentence as a fully connected directed graph which means that we have all pairs of words as potential candidates for a dependency edge existing between them another way you can think of it is a matrix of scores for each uh for each edge where the rows are the head and the um the columns are the children and the diagonal obviously something can’t be ahead of itself so it would it’s irrelevant but you predict all of the other uh things there and then after you do that um you score each edge independently so you basically calculate the values of that that score matrix and then you have some algorithm that allows you to find the maximal spanning tree which is basically the highest scoring set of edges that form a tree in the uh form a tree with a root in it</p>
</section>
<section id="graphbased-vs-transitionbased" class="level2">
<h2 class="anchored" data-anchor-id="graphbased-vs-transitionbased">Graphbased vs Transitionbased</h2>
<p>and i have a comparison of graph based versus transition based um one ex one advantage of transition based parsing is that it allows you to condition on infinite context basically so it allows you to condition on all of your previous actions so theoretically it has as much expressiveness as you want just like a regular encoder decoder model can do you know can condition on all your previous sections um however for transition based parsing greedy search algorithms can cause short-term uh mistakes to propagate into damaging your long-term performance so you know if you accidentally connect an edge too early there’s no way to recover from it on the other hand um graph based parsing you can find the exact best global solution via dynamic programming um however you have to make some local independence assumptions so you can’t like necessarily easily condition you know the choice of one edge on whether you chose one edge or at another time so um for the dynamic programming</p>
</section>
<section id="dynamic-programming" class="level2">
<h2 class="anchored" data-anchor-id="dynamic-programming">Dynamic Programming</h2>
<p>algorithm i’m not going to go into a lot of detail here because as i said like people are probably not going to be implementing uh this on your own you’re probably going to be using a parser um but uh basically we have a graph and want to find it spanning trees so what we do is we greedily select the best incoming edge to each node and we subtract its score from all other incoming edges because we want a tree and not anything with any cycles in it what we do is we contract the cycles together into a single node and resolve the cycles within that node um and basically we recursively call the algorithm on the graph with the contracted node and then we can expand the contracted node deleting at an edge from the root node uh there so um if you’re more interested in exactly how this works you can uh look at uh jaravsky and martin’s textbook on dependency parsing or something like this but basically that’s the general idea um for these models basically what we do is we extract features over the whole sequence so we feed in all of the um you know all of the words in the input into a feature extractor in this particular um in this particular example it says lstm but in reality now it’s xlmr or bert or you know whatever</p>
</section>
<section id="feature-extractor" class="level2">
<h2 class="anchored" data-anchor-id="feature-extractor">Feature Extractor</h2>
<p>Your favorite feature extractor is the classifier that you use to basically uh apply scores to each of the nodes of the input is a by affine classifier this looks a little bit scary if you look at the equations but it’s actually super simple um what you do is you learn uh specific representations through an mllp for each head word in each dependent word so basically you feed the representations that you get from burke or whatever else into an mlp where you have a separate mlp when you’re considering the word as a head and when you’re considering the word as a child or a dependent and then you calculate the score of each arc um where sorry i thought i had an animation here but basically um the first part of this here is calculating how likely a child word is to connect to a head word so it’s calculating basically the congruence between a child word and a head word and of course you know this is optimized end to end but it will be considering things like how close together are the words how likely is a child to be a child of a head like so nouns tend to be children of verbs uh et cetera et cetera determines children of nouns um and then in addition it also calculates the score saying how likely is this word to be a head word in the first place so for example determiners are almost never head words in um in semantic dependencies and so they’ll get a very low score according to this thing down here whereas verbs are very often head words so we’ll get a high score</p>
</section>
<section id="difficulty" class="level2">
<h2 class="anchored" data-anchor-id="difficulty">Difficulty</h2>
<p>For multi-lingual dependency parsing,the difficulty in multilingual dependency parsing is, that actually <strong>syntactic analysis</strong> is a particularly hard multilingual task. I think it’s harder than named entity recognition; it’s probably harder than part of speech tagging and it might even be on the same level of difficulty as translation. Yeah maybe not maybe not on the same level of difficulty as translation but it’s hard it’s a hard task and the reason why is because it’s on a global level not just a word by word level so you need to consider long distance dependencies within the sentence and syntax varies widely across different languages so like English is very very different from Hindi and both are very very different from Arabic so you can’t like just say you know well like named entities look pretty similar in all languages they all have like low frequency words and um is a key that always works for named entities but you can’t do something like that when deciding syntax is easily</p>
</section>
<section id="order-insensitive-encoder" class="level2">
<h2 class="anchored" data-anchor-id="order-insensitive-encoder">Order insensitive encoder</h2>
<p>um so there’s a bunch of improvements that people have proposed i had some examples of these and the papers that i suggested for reading for the discussion one example is uh that people have shown that when you’re transferring to very very different languages um you can remove the bias on ordering in encoders so for example if you’re using a transformer based model you can remove the positional encodings so you basically get an order insensitive encoder and that transfers much better to very very different languages so um in this case they always use english as the source language and transferred to another language but can you think of any other examples where this might be useful um can you think of it can you think of an example of a language where it would be very hard to get another language with similar syntax that’s included in your dependency treatment yeah i mean if you’re studying a low resource language that’s part of a language family that only has other low resource languages yeah exactly so if you’re studying a low resource language with a language family that only has other low research languages i could give an example uh what about navajo that’s probably the highest resource language in its language family but it’s extremely low resource and i think that’s um i think it’s also useful because one of the or one of it’s also important because dependency parsing is particularly useful for things like linguistic inquiry or human facing interfaces when you can’t just train an end to end model easily so um you know that’s a particularly salient use case another paper that i</p>
</section>
<section id="dependency-parsing" class="level2">
<h2 class="anchored" data-anchor-id="dependency-parsing">Dependency parsing</h2>
<p>this is one of my papers i like it a lot i i wish more people liked it a lot um but uh but basically the um i think it’s a really really cool paper um uh so i i’m trying to sell it to everybody but basically uh we came up with a generative model for dependency parsing and the idea of the generative model for dependency parsing is that you have a model that jointly generates the dependency tree and the sentence and one of the nice things about generative models is that you can train them unsupervised as well so you can take the unsupervised model uh and learn the structure that’s used in the unsupervised model together with like generating the sentences on unlabeled data and the reason why i think this is cool is because you can take a model that was trained on english and then train it unsupervised on the language that you’re interested in parsing and it improves the performance by a lot especially if the languages are very unrelated um so i think this is another cool tool if you have a language that is from like a different language family for example the input is the dependency tree and your model just generates a random sentence in the target so the input is it’s a generative it’s you can think of it like a language model but it calculates instead of just calculating the probability of the output sentence it calculates the joint probability of um the dependency tree and the output sentence so if you’ve given a sentence like it reconstructs the sentence right and it can do other things like it can get the uh the highest probability dependency tree given a sentence that’s called like latent variable inference and other things like that um basically in this case it’s initialization um it can be initialization with regularization towards the original parameters as well um does that imply supervised data for the chemistry it does not it only it only requires um text and basically the way it works is it um it you have a dynamic program that finds the dependency tree that iterates over the dependency trees and it optimizes the parameters of like the dependency parser and the output at the same time but the probability of the output will go up basically if you have a more coherent dependency tree for a completely different family yes yeah the different family could have a completely different type of synthetic structure yes exactly yes you read read the paper i’m not lying so that’s a good um that’s a good question and that will link it to what aditi is going to talk about in a second too um we didn’t we didn’t evaluate it that you know like that extensively so i think that would be a natural interesting next question for any of these improvements um that i’m talking about here does do these improvements lead to a more coherent you know grammatical sketch for the language or something like that if we extract the grammatical sketch cool um uh yeah so i’m i’m</p>
</section>
<section id="linguistic-informed-constraints" class="level2">
<h2 class="anchored" data-anchor-id="linguistic-informed-constraints">Linguistic informed constraints</h2>
<p>as i said i i’m excited about that so come talk to me if you if you want to hear more um a final thing is linguistically informed constraints so there are big atlases of data about linguistic structures like the world atlas of language structures which i believe uh ellen or somebody talked about earlier um and they they tell you things like is an adjective before a noun um and so using this uh what this paper that i’m introducing here does is they use something called posterior regularization which basically says we’re going to parse our whole corpus we’re going to look at the proportion of the time that an adjective appears before a noun or after a noun and then if our big atlas of language structure says that um adjectives should happen before nouns but our dependency parser is putting adjectives after nouns much more often then we are going to decrease the probability of it putting an adjective after the noun and increase the probability of it putting an adjective before the noun so this is a way to introduce basically prior knowledge into the predictor in order to make it uh work better so these are just three examples of cross-lingual dependency parsing but they demonstrate some you know ways to incorporate intuitions and stuff um cool and any other uh things um if not i’ll turn it over to aditi to talk um in a bit of detail um we might or might not have time for discussion uh formal discussion but we could have maybe uh all um uh like class discussion and and it’s the keynote slides uh yes these are the keywords so can i open the demo on the google chrome this one yes thank you and then yeah that works cool and that’s the mind sure okay hi everyone uh i’m aditi i’m a phd student working with graham and today i’m going to show you a part of my research where i’ve used these dependency analysis okay so we just saw some because it’s kind of annoying okay so dependency analysis basically told us on a high level how words are related to each other uh so it’s information is useful but we also need to understand a more complex linguistic phenomena if you truly want to understand the language as a whole so some of these complex linguistic phenomena are like morphological agreement word order case marking suffix usage to name a few and these are important not just for like a language communication or understanding but also has some concrete applications so there are some human-centric or human-facing applications for instance like if you want to like learn the language then you need to know how to arrange these words when does the ordering of the word changes uh what kind of suffix to use when what happens gender is like for each gender you might have a different word ending and so on uh another important application which for navajo we also saw was language documentation because languages are getting extinct quite frequently and quite quickly also so language documentation is a way where linguists document the salient grammar points of a language not just for preservation but also as a way to like also create pedagogical resources maybe even create language technologies from that so another kind of application is from machine centric applications some examples that we saw where dependency analysis were used to give inductive bias into models another application is like we sort of used these um rules that we extract automatically to evaluate a machine output so often across languages as we saw syntax is quite different so we want to have a way to automatically evaluate how grammatically correct let’s say a machine translation output is so basically to achieve both human centric application and machine centric applications we need to extract rules which explain this phenomena in a format which is both human readable and machine readable and i’m going to quickly explain like how we do this using a process of</p>
</section>
<section id="definition-of-required-agreement" class="level2">
<h2 class="anchored" data-anchor-id="definition-of-required-agreement">Definition of required agreement</h2>
<p>morphological agreement so agreement is a quite complex process wherein basically words in a sentence often change their forms or morphology based on some other words in the same sentence based on some category like gender number and person so i’ll give a quickly an example from number agreement in spanish so here you can see that girl is in singular and the word for verb has also been singular so now if i change the word for girl to be in a plural form then the words form also changes to the plural form so basically any change in the subjects number has to bring about a change in the verbs number so we call this as subject verb required agreement now if you look at the object and the word they are also both in the singular form in the first sentence and the second sentence when the form of the object dog has become plural the form of the word still remains in a singular form so essentially any change in the object’s number is not bringing a change in the verbs number so this is it’s not required agreement so any sort of agreement that we may observe between object and work is purely by chance so we call this as object work chance agreement so to basically understand what are the rules which govern subject agreement and orders or how to require agreement you basically formulate it into a classification task</p>
</section>
<section id="prediction-task" class="level2">
<h2 class="anchored" data-anchor-id="prediction-task">Prediction task</h2>
<p>so the task is here of predicting required agreement versus chance agreement and how do we extract these rules automatically just from the raw text so here i have an example of greek this is a greek sentence and we first automatically perform some syntactic analysis which basically gives us what is the part of speech of each word what is this morphological features what are the dependency links between them now from this syntactic analysis we basically create our training data for this prediction task so here’s an example so on this box here you basically have a dependency link between the determiner and the proper noun now the gender of the determinant and the proper noun are both matching they’re both in feminine gender so basically we can create a training data point saying that proper noun and determiner when they are in a relation then the gender is matching so the agreement value becomes yes now another dependency link here is between the noun and the proper noun now here the gender values are not matching so our data point here becomes that any relation between noun and proper noun in this example the agreement value is known so essentially we are basically creating a binary classification task from this example and we create this data set for all the sentences we then basically learn a model on top of this training data from which we extract rules where the rules are telling us which of these rules are actually leading to a required agreement and which are leading to a chance agreement so essentially this is um an example of the model so again going back to the previous slide where i mentioned about human centric applications so we want to understand and extract these rules which are understandable to humans so we want to use a model which is more interpretable so here i have used the model of decision trees the decision trees can exactly tell you what are the features which led to one decision so once we have applied a decision tree style model on our training data it gives us a leaf node the leaf here is inducing a distribution of agreement over these examples the leaf 3 here is showing us that there are 58 000 examples where the gender values were matching and 778 but they were not matching but how do we know whether this distribution is leading to a required agreement or a chance agreement and to automatically extract this label we basically apply a statistical threshold i won’t go into the much details of it but essentially we apply a significance test which tells us whether the observed agreement distribution is significant or not and this can tell us whether the leaf is truly capturing a required agreement or not and this is like an example of the label decision tree where for spanish gender agreement this is the leaf or this is the tree after the leaf labeling stage and the leaf three here has been marked as required agreement so basically from this leaf three we can extract some discrete rules which says okay if determinant and noun are in the following relation then they need to agree on gender so basically from the raw text we started training data over which we train an interpretable model from which we then extracted some discrete and very simple rules and this is just a very basic pipeline and now we are trying to extract this</p>
</section>
<section id="linguistic-questions" class="level2">
<h2 class="anchored" data-anchor-id="linguistic-questions">Linguistic questions</h2>
<p>sort of or apply this pipeline for potentially any linguistic question so we saw this for agreement where our linguistic question was when do syntactic heads show agreement with their dependence on gender number and so on another interesting question was for case marking in case marking we’re interested to know when does a particular class of words like nouns take nominative case over the other so for example in this sentence anna has food anna is in the nominated case but if it becomes anna’s food then ani is a generative base so we want to basically if you are learning this language you need to know that when to add an apostrophe is when you are basically showing a possession another kind of interesting linguistic phenomena is of word order like you need to know how to arrange the words appropriately and even in english typically when we say about word order people just say it’s one word that english follows svo but it’s even within english there are multiple word orders so for instance if if i’m saying english is sorry anna is eating an apple then your word order is simply subject verb and object but if i’m asking a question what is anna eating then these order changes it now becomes object subject and work so if i’m learning english i need to know that when i’m asking a question what is the typical order but if i am just using or saying a decorative sentence what is the what order so essentially for any linguistic question we want to formulate it as a prediction task and learn and extract its rules and this is the final general framework which we have been working on from the raw text you basically extract some</p>
</section>
<section id="general-framework" class="level2">
<h2 class="anchored" data-anchor-id="general-framework">General framework</h2>
<p>features but in our case the features were part of speech tags dependency analysis from which we then extract rules for each of this phenomena and i’ll show you what the rules look like in a minute okay so now what are the kind of syntactic analysis which we can use so graham just showed you the universal dependencies project within that is also the sud tree banks so basically if for a language we have this kind of data available which more or less is uh annotated by language experts we can directly use these sud treatment as a starting point but for many more languages we even don’t have annotations so in that case your multilingual parsers come into the picture where you can take some raw text first parse it using these models and then apply the same approach okay so this is the toolkit</p>
</section>
<section id="toolkit" class="level2">
<h2 class="anchored" data-anchor-id="toolkit">Toolkit</h2>
<p>which we have developed and okay this basically this is an autolex framework where we have extracted such kind of rules for different linguistic behaviors for a bunch of languages uh sure so for each language we extract a bunch of features and i’ll just go through some of them here so let’s say we want to explore the spanish agreement features and let’s go into gender so okay so this is exactly the so if you look at the first uh thing here basically say that okay mostly in spanish gender usually agrees between the determiner and its head but there are some significant number of cases when this does not hold true and some of these cases we have highlighted here that if let’s say a determiner is governed by an adjective in some cases the gender did not agree so we basically extracts rules in a human readable format and further for each of these rules because rules alone can often get quite overwhelming we also show some illustrative examples so here basically if you look here so here the determiner gender is masculine and the adjective gender is feminine so here is one example where although the determiner is governed by an adjective the gender is not matching but then there are some other examples where the determiner’s gender is masculine and the adjectives gender is also masculine here the general values are matching so these are some sort of exceptions to the language general oriented and knowing these exceptions are also important because they do occur quite frequently in the language uh again we have some rules for word order also so let’s say we want to um can go adjective noun so for instance so typically in spanish unlike english most adjectives come after the noun that’s the typical ordering of objectives but there are very specific cases or or very specific adjectives which come before the nouns and the model has correctly identified some of them for instance this rule is telling us that if the adjective has the lima primero then the adjectives come before the noun and again for each of the rules we also ex like show some this illustrative examples where indeed these adjective which has the lima primero is coming before the noun but again language is not that simple there are even exceptions to exceptions so there are again examples which show that even when the lima is primarily there are certain times when this rule is not followed so we are trying to show a more softer view of the rule also that this rule is not 100 applicable every time there are conditions where this rule is not followed so essentially here we have used dependencies as our feature base to explain the rules in a human readable format and i guess one another important aspect here is the quality of the rules also depend a lot on the quality of the underlying analysis so as we improve the multilingual dependency parsing the quality of the rules should also improve so we also applied this system for an endangered language variety called hmong so hmong is spoken in north america also china thailand vietnam and laos and one of its variety is close to endangered and we were trying to we simply had access to a bunch of monk sentences and we wanted to analyze some of his interests and linguistic properties and we had david in lti who also speaks more and knows a lot about it so we basically presented such kind of rules for mong to david and there were a couple of interesting observations first the quality of rules was not as good as what we were seeing for spanish but despite that the model had still been able to identify some cluster of examples which showed rules which david was not aware about so such kind of data-driven approaches is also able to capture or identify some rules which the linguist was not initially aware of so i think dependency analysis is a very useful tool which has a lot of applications especially for exploring a language because there’s so much data out there the dependency analysis helps us find the key components to it so i can go into more detail but these are the main features sure so right now we basically uh i showed you grammar rules and how it was</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>useful um from let’s say a linguist or language documentation point of view uh we’re also now using these tools to actually teach languages to a more less linguistically aware audience because often learners or teachers they don’t go into the linguistic jargon that much but they’re still interested in knowing the grammar rules and especially we are focusing on two languages marathi and kanada these are both indian languages and there are schools in north america where they are teaching these languages to english speakers so a lot of the times there are immigrants who are settled here and they want their children to learn these languages so that so there are english native speakers here and the schools here are interested in teaching them these languages from english so here we basically extract a lot of interesting features so for example for example here we have basically extracted uh some of the most common words observed in kannada what is the transliteration in english and what are the different kind of forms they are um like what are the different forms these lemma have been observed across different genders so this lemma do here i don’t know i’m pronouncing it correctly but you can see here how this lima is used for a masculine gender or how this lima is used in the feminine gender and such kind of tables are pretty common when you are teaching how a word should be used in a language so we are automatically again performing syntactic analysis on these languages extracting such kind of useful insights and then presenting them to actual teachers so that they can check if this material is useful for their teaching process so we are trying to ease the teachers job so that they can focus on the creative aspect of teaching and yeah i guess those are the main points great thank you thank you aditi um yeah so i’m sorry we’re right up against the uh the time so i don’t think we’re gonna have time for discussion this time i really apologize i try not to do this uh but i packed too much stuff in but i also invited the dt and didn’t want to ever prepare for nothing um because of this um if you took time to like prepare for the discussion today and read the things if you want to send um like a short summary of the things that you prepared we can give like extra credit it won’t be required but um uh we i’ll give like one discussion worth of extra credit for that um are there any questions uh for about the stuff that you was talking about here yeah obviously mentioned like uh different regions and different species like america are there any like grammatical differences region-wise or are they like that’s a good question so there are these different varieties so we worked uh so the question was about because hmong is spread across so many different regions are there any difference in the grammatical properties so there are because there are different hmong varieties and we worked on one of the variety which is predominantly spoken in north america so we didn’t have the chance to investigate uh how the grammar rules changes across these different varieties but the interesting thing so we did another sort of a separate set of experiments where the universal dependencies project they have a lot of free bang for the same language for different domains so there are data from grammar books they have data from news articles and even within the same language across these domains the grammar structure varies quite a lot so in this tool we are basically also offering linguists to like check okay these are the do’s extracted from one domain how do they change in another domain is their model able to account for instances of agreement where there’s not exact matching values for instance if the subject is marked as duo so that would be considered as that if the agreement is not happening because the value is not matching i’m not sure if the universal dependency tree bank actually has that level of detail it might um i maybe you have experience with that but um i think the universal dependency annotations are actually quite i don’t know coarse so that my level of detail might not show up in the first place but it might yeah that is like uh an important point that this analysis has been done on one schema the schema used here is the ud schema or the sud schema which is the the we purposefully chose sud or ud because first of all it’s available for a lot more languages and it has a consistent annotation format so the kind of rules we extract now they’re also consistent across languages but that being said it might not consider the language the system is that well that is like a drawback for that but potentially you can apply this pipeline or this model to any um other annotation statement it will give you rules according to that schema okay great thanks a lot everyone we can answer other other questions</p>
</section>
</div>
</div>
</div>
<section id="outline" class="level2">
<h2 class="anchored" data-anchor-id="outline">Outline</h2>
<ul>
<li><p><strong>Part 1: Data Augmentation for Machine Translation</strong></p>
<ul>
<li><strong>Introduction to Low-Resource Machine Translation</strong></li>
</ul>
<p>n * Challenges in translating low-resource languages due to small parallel corpora. * Multilingual training approaches as a solution. * Limitations of multilingual training: suboptimal lexical/syntactic sharing and inability to leverage monolingual data.</p>
<ul>
<li><p><strong>Data Augmentation Strategies</strong></p>
<ul>
<li>Using available resources (parallel data, related high-resource languages, monolingual data) to create augmented data.</li>
<li>Naturally occurring low-resource language and target language data.</li>
<li>Pseudo-parallel data generation.</li>
</ul></li>
<li><p><strong>Back Translation</strong></p>
<ul>
<li>Training a target language to source language system using small parallel data.</li>
<li>Back-translating target language monolingual data into the source language.</li>
<li>Training a low-resource language to target language translation model using the generated pseudo-parallel data.</li>
<li>Permissible error in source data as long as target data is clean.</li>
</ul></li>
<li><p><strong>Translation Generation Methods</strong></p>
<ul>
<li>Beam search: highest quality but lower diversity and potential data bias.</li>
<li>Sampling: higher diversity and effectiveness.</li>
</ul></li>
<li><p><strong>Iterative Back Translation</strong></p>
<ul>
<li>Training a system in the desired translation direction.</li>
<li>Forward translating the low-resource language to the target language.</li>
<li>Training a target to low-resource language back translation system.</li>
<li>Back-translating from the target to the low-resource language to augment data in the backwards direction.</li>
</ul></li>
<li><p><strong>Combining Multilingual Training with Data Augmentation</strong></p>
<ul>
<li>English to high-resource language augmentation to improve low-quality back translation.</li>
<li>Back-translating into a high-resource language for more sentence pairs.</li>
<li>Vocabulary sharing if the high-resource and low-resource languages are related.</li>
<li>Syntactic similarity for bootstrapping.</li>
</ul></li>
<li><p><strong>Monolingual Data Copying</strong></p>
<ul>
<li>Using monolingual data as is on both the source and target side to prevent word dropping and improve translation of identical terms.</li>
<li>Combining with a poor back translation system to improve accuracy.</li>
</ul></li>
<li><p><strong>Heuristic Augmentation Strategies</strong></p>
<ul>
<li>Dictionary-based augmentation: using a language model to predict words and a translation dictionary to replace words in source and target sentences.</li>
<li>Word alignment to learn translation dictionaries.</li>
<li>Word-by-word data augmentation: translating each word one by one using a dictionary.</li>
<li>Word-by-word augmentation with reordering based on grammatical rules.</li>
</ul></li>
</ul></li>
<li><p><strong>Part 2: Dependency Parsing</strong></p>
<ul>
<li><p><strong>Introduction to Dependency Parsing</strong></p>
<ul>
<li>Focus on the relationships between words.</li>
<li>Suitability for multilinguality, especially in languages with free word order.</li>
</ul></li>
<li><p><strong>Universal Dependencies Treebank</strong></p>
<ul>
<li>Standard format for parse trees in many languages.</li>
</ul></li>
<li><p><strong>Semantic vs.&nbsp;Syntactic Dependencies</strong></p>
<ul>
<li>Semantic (UD): Flatter, semantically related words closer, more content word heads.</li>
<li>Syntactic (SUD): Deeper, reflect phrase structure, more function word heads.</li>
</ul></li>
<li><p><strong>Cross-Lingual Differences in Structure</strong></p>
<ul>
<li>Examples: English (SVO), Hindi (Verb Final), Arabic (Verb Initial).</li>
</ul></li>
<li><p><strong>Use Cases of Dependencies</strong></p>
<ul>
<li>Feature engineering.</li>
<li>Human-facing applications.</li>
</ul></li>
<li><p><strong>Dependency Parsing Methods</strong></p>
<ul>
<li>Transition-based models: step through actions one-by-one.</li>
<li>Graph-based models: calculate probability of each edge and use dynamic programming.</li>
</ul></li>
<li><p><strong>Shift-Reduce Parsing</strong></p>
<ul>
<li>Processing words left-to-right using a queue and a stack.</li>
<li>Actions: shift, reduce left, reduce right.</li>
</ul></li>
<li><p><strong>Graph-Based Dependency Parsing</strong></p>
<ul>
<li>Expressing a sentence as a fully connected directed graph.</li>
<li>Scoring each edge independently and finding the maximal spanning tree.</li>
</ul></li>
<li><p><strong>Chu-Liu-Edmonds Algorithm</strong></p>
<ul>
<li>Greedily selecting the best incoming edge to each node.</li>
<li>Contracting cycles into single nodes and recursively calling the algorithm.</li>
</ul></li>
<li><p><strong>Multilingual Dependency Parsing Challenges</strong></p>
<ul>
<li>Syntactic analysis is a hard multilingual task.</li>
<li>Syntax varies widely across different languages.</li>
</ul></li>
<li><p><strong>Improvements in Multilingual Dependency Parsing</strong></p>
<ul>
<li>Order-insensitive encoders to avoid overfitting to the source language.</li>
<li>Generative model fine-tuning.</li>
<li>Linguistically informed constraints.</li>
</ul></li>
</ul></li>
<li><p><strong>Part 3: Integrating Data Augmentation with Dependency Parsing for Linguistic Insight</strong></p>
<ul>
<li><p><strong>Predicting Linguistic Insights</strong></p>
<ul>
<li>Understanding complex linguistic phenomena (morphological agreement, word order, case marking, suffix usage).</li>
</ul></li>
<li><p><strong>Morphological Agreement</strong></p>
<ul>
<li>Agreement as a process where a word/morpheme changes form based on another word/morpheme’s grammatical categories.</li>
<li>Task of predicting required-agreement vs.&nbsp;chance-agreement.</li>
</ul></li>
<li><p><strong>General Framework for Extracting Linguistic Descriptions</strong></p>
<ul>
<li>Extracting features (POS tagging, dependency parse, lexico-semantics).</li>
<li>Extracting rules for agreement, case marking, and word order.</li>
</ul></li>
<li><p><strong>Applications</strong></p>
<ul>
<li>Automatic grammar rule extraction.</li>
<li>Grammar error correction.</li>
<li>Natural language generation evaluation.</li>
<li>Language learning and documentation.</li>
</ul></li>
</ul></li>
<li><p><strong>Conclusion</strong>: Review of data augmentation techniques, dependency parsing, and their applications in multilingual NLP for extracting linguistic insights.</p></li>
</ul>
</section>
<section id="reflection" class="level2">
<h2 class="anchored" data-anchor-id="reflection">Reflection</h2>
<p>Morphological agreements discussion by Aditi is of particular interest.</p>
<p>It seems that understanding agreement is central to ‘second order’ model that need to beat the <strong>baseline</strong>. To get this to happen in an interpretable form we may want to train an attention head that is looking at thing that are in agreement and responding to the feature of agreement and disagreement as both are signals of some value.</p>
<p>I belief that we can learn a probabilistic model of agreement between different cases but that they may be affected by all sorts of constraints like clause and phrase boundaries and the degree of morphological markings. So this is why attention seems so appropriate as it can learn what to focus on. And what we want is to make it interpretable so we can also extract the rules that it has learned!</p>
<p>Aditi talks about <strong>require agreement</strong> v.s. <strong>chance agreement</strong> for verb-subject and verb-object. I think that we may want to have a theory that looks at agreement in winder context and create a model that can predict agreement in a wider context so that we can consider the entropy of a sentence once agreement has been accounted for. In fact my thinking is that we may want to go further and determine the functional load of the agreement and have a more redined metric that can be used to evaluate the entropy of a sentence accounting to agreement in a functional context. (Error correction ambiguity, Reducing cognitive load, Reducing ambiguity, Parsing)</p>
</section>
<section id="navajo-in-10" class="level2">
<h2 class="anchored" data-anchor-id="navajo-in-10">Navajo in 10</h2>
<ul>
<li><p><strong>Language Name and Classification</strong>:</p>
<ul>
<li><strong>Navajo</strong> (also known as <strong>Navaho</strong>).</li>
<li>Navajo: <em>Diné bizaad</em> [tìnépìz̥ɑ̀ːt] or <em>Naabeehó bizaad</em> [nɑ̀ːpèːhópìz̥ɑ̀ːt].</li>
<li>It is a <strong>Southern Athabaskan language</strong> of the <strong>Na-Dené family</strong>.</li>
</ul></li>
<li><p><strong>Speakers and Location</strong>:</p>
<ul>
<li>Spoken primarily in the <strong>Southwestern United States</strong>, especially in the <strong>Navajo Nation</strong>.</li>
<li>One of the most widely spoken <strong>Native American languages</strong>.</li>
<li>The most widely spoken Native American language north of the <strong>Mexico–United States border</strong>.</li>
<li>Almost <strong>170,000 Americans</strong> speaking Navajo at home as of 2011.</li>
</ul></li>
<li><p><strong>Nomenclature</strong>:</p>
<ul>
<li>The word <em>Navajo</em> is an <strong>exonym</strong> from the Tewa word <em>Navahu</em>, meaning ‘large field’.</li>
<li>The Navajo refer to themselves as the <em>Diné</em> (‘People’), with their language known as <em>Diné bizaad</em> (‘People’s language’) or <em>Naabeehó bizaad</em>.</li>
</ul></li>
<li><p><strong>Official Status</strong>:</p>
<ul>
<li>Official language in <strong>Navajo Nation</strong>.</li>
</ul></li>
<li><p><strong>History and Development</strong>:</p>
<ul>
<li>The Apachean languages, of which Navajo is one, are thought to have arrived in the American Southwest from the north by 1500.</li>
<li>Speakers of the Navajo language were employed as <strong>Navajo code talkers</strong> during World Wars I and II.</li>
<li>Orthography developed in the late 1930s and is based on the <strong>Latin script</strong>.</li>
</ul></li>
<li><p><strong>Writing System</strong>:</p>
<ul>
<li>Based on the <strong>Latin script</strong>.</li>
<li>Developed between 1935 and 1940.</li>
<li>Uses an apostrophe to mark <strong>ejective consonants</strong> and mid-word or final <strong>glottal stops</strong>.</li>
<li>Represents nasalized vowels with an <strong>ogonek</strong> and the voiceless alveolar lateral fricative with a <strong>barred L</strong>.</li>
</ul></li>
<li><p><strong>Phonology</strong>:</p>
<ul>
<li>Has a fairly large <strong>consonant inventory</strong>.</li>
<li><strong>Stop consonants</strong> exist in three laryngeal forms: aspirated, unaspirated, and ejective.</li>
<li>Has a simple <strong>glottal stop</strong> used after vowels.</li>
<li>Four <strong>vowel qualities</strong>: /a/, /e/, /i/, and /o/.</li>
<li>Each vowel exists in both <strong>oral and nasalized</strong> forms and can be either <strong>short or long</strong>.</li>
<li>Distinguishes for <strong>tone</strong> between high and low.</li>
</ul>
<p><img src="navajo-consonants.png" class="img-fluid" width="400" alt="Navajo Consonants"> <img src="navajo-vowels.png" class="img-fluid" width="400" alt="Navajo Vowels"></p></li>
<li><p><strong>Grammar</strong>:</p>
<ul>
<li>Relies heavily on <strong>affixes</strong>, mainly prefixes.</li>
<li>Affixes are joined in unpredictable, overlapping ways that make them difficult to segment.</li>
<li>Basic word order is <strong>subject–object–verb</strong>.</li>
<li>Verbs are conjugated for <strong>aspect and mood</strong>.</li>
</ul></li>
<li><p><strong>Vocabulary</strong>:</p>
<ul>
<li>Most Navajo vocabulary is of <strong>Athabaskan origin</strong>.</li>
<li>Has been conservative with <strong>loanwords</strong> due to its highly complex noun morphology.</li>
<li>Expanded its vocabulary to include Western technological and cultural terms through <strong>calques and Navajo descriptive terms</strong>.</li>
</ul></li>
<li><p><strong>Revitalization and Current Status</strong>:</p>
<ul>
<li><strong>Bilingual Education Act</strong> in 1968 provided funds for educating young students who are not native English speakers.</li>
<li>Navajo Nation Council decreed in 1984 that the Navajo language would be available and comprehensive for students of all grade levels in schools of the Navajo Nation.</li>
<li><strong>Navajo-immersion programs</strong> have cropped up across the Navajo Nation.</li>
<li>Diné College offers an associate degree in the subject of Navajo.</li>
<li>In December 2024, Navajo Nation President made Navajo language the official language of Navajo Nation.</li>
</ul></li>
</ul>
</section>
<section id="papers" class="level2">
<h2 class="anchored" data-anchor-id="papers">Papers</h2>
<ul>
<li><ol class="example" type="1">
<li><a href="https://aclanthology.org/2020.emnlp-main.422/">Automatic Extraction of Rules Governing Morphological Agreement</a> EMNLP 2020. <a href="https://slideslive.com/38939038/automatic-extraction-of-rules-governing-morphological-agreement">video</a></li>
</ol>
<ul>
<li>This paper is related to extracting morphological agreement rules using dependency relations.</li>
</ul></li>
<li><ol start="2" class="example" type="1">
<li><a href="https://arxiv.org/abs/1811.00570">On difficulties of cross-lingual transfer with order differences: A case study on dependency parsing</a></li>
</ol>
<ul>
<li>This paper discusses challenges in cross-lingual transfer due to word order differences.</li>
</ul></li>
<li><ol start="3" class="example" type="1">
<li><a href="https://arxiv.org/abs/1906.02656">Cross-lingual syntactic transfer through unsupervised adaptation of invertible projections</a></li>
</ol>
<ul>
<li>This paper is about cross-lingual syntactic transfer using unsupervised adaptation of invertible projections.</li>
</ul></li>
<li><ol start="4" class="example" type="1">
<li><a href="https://arxiv.org/abs/1909.01482">Target language-aware constrained inference for cross-lingual dependency parsing</a>.”</li>
</ol>
<ul>
<li>This paper focuses on target language-aware constrained inference for cross-lingual dependency parsing.</li>
</ul></li>
<li><ol start="5" class="example" type="1">
<li><a href="https://github.com/jungyeul/chu-liu-1965/tree/main?tab=readme-ov-file">On the Shortest Arborescence of a Directed Graph</a></li>
</ol></li>
<li><ol start="6" class="example" type="1">
<li><a href="https://nvlpubs.nist.gov/nistpubs/jres/71B/jresv71Bn4p233_A1b.pdf">Optimum Branchings*</a></li>
</ol>
<ul>
<li>These papers are related to the <a href="https://en.wikipedia.org/wiki/Edmonds%27_algorithm">Chu-Liu-Edmonds algorithm</a>.</li>
</ul></li>
<li><span class="citation" data-cites="kiperwasser2016simpleaccuratedependencyparsing">Kiperwasser and Goldberg (<a href="#ref-kiperwasser2016simpleaccuratedependencyparsing" role="doc-biblioref">2016</a>)</span> <a href="https://arxiv.org/abs/1603.04351">Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations</a>
<ul>
<li>This paper concerns Sequence Model Feature Extractors.</li>
</ul></li>
<li><ol start="7" class="example" type="1">
<li><a href="https://arxiv.org/abs/1611.01734">Deep Biaffine Attention for Neural Dependency Parsing</a>**</li>
</ol>
<ul>
<li>This paper discusses the BiAffine Classifier.</li>
</ul></li>
<li><span class="citation" data-cites="yamada-matsumoto-2003-statistical">Yamada and Matsumoto (<a href="#ref-yamada-matsumoto-2003-statistical" role="doc-biblioref">2003</a>)</span> <a href="https://aclanthology.org/W03-3023/">Statistical Dependency Analysis with Support Vector Machines</a>
<ul>
<li>These paper describes Arc Standard Shift-Reduce Parsing.</li>
</ul></li>
<li><ol start="8" class="example" type="1">
<li><a href="https://aclanthology.org/W03-3017/">An Efficient Algorithm for Projective Dependency Parsing</a>
<ul>
<li>These paper describes Arc Standard Shift-Reduce Parsing.</li>
</ul></li>
</ol></li>
<li><ol start="9" class="example" type="1">
<li><a href="https://arxiv.org/abs/2203.13901">AutoLEX: An Automatic Framework for Linguistic Exploration</a> <a href="https://aditi138.github.io/auto-lex-learn/index.html">project</a></li>
</ol></li>
<li><ol start="10" class="example" type="1">
<li><a href="https://aclanthology.org/2021.emnlp-main.570/">Evaluating the Morphosyntactic Well-formedness of Generated Texts</a> <a href="https://aclanthology.org/2021.emnlp-main.570.mp4">video</a></li>
</ol></li>
<li><ol start="11" class="example" type="1">
<li><a href="https://aclanthology.org/P17-2090/">Data augmentation for low resource neural machine translation</a></li>
</ol></li>
<li><ol start="12" class="example" type="1">
<li><a href="https://aclanthology.org/D19-1143/">Handling syntactic divergence and low resource translation</a></li>
</ol></li>
</ul>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-kiperwasser2016simpleaccuratedependencyparsing" class="csl-entry" role="listitem">
Kiperwasser, Eliyahu, and Yoav Goldberg. 2016. <span>“Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations.”</span> <a href="https://arxiv.org/abs/1603.04351">https://arxiv.org/abs/1603.04351</a>.
</div>
<div id="ref-yamada-matsumoto-2003-statistical" class="csl-entry" role="listitem">
Yamada, Hiroyasu, and Yuji Matsumoto. 2003. <span>“Statistical Dependency Analysis with Support Vector Machines.”</span> In <em>Proceedings of the Eighth International Conference on Parsing Technologies</em>, 195–206. Nancy, France. <a href="https://aclanthology.org/W03-3023/">https://aclanthology.org/W03-3023/</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2022,
  author = {Bochman, Oren},
  title = {Speech},
  date = {2022-03-29},
  url = {https://orenbochman.github.io/notes-nlp/notes/cs11-737-w19-syntax-and-parsing/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2022" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2022. <span>“Speech.”</span> March 29, 2022. <a href="https://orenbochman.github.io/notes-nlp/notes/cs11-737-w19-syntax-and-parsing/">https://orenbochman.github.io/notes-nlp/notes/cs11-737-w19-syntax-and-parsing/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2023-2025, Oren Bochman</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/notes/cs11-737-w19-syntax-and-parsing/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 💛 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"right","loop":true,"openEffect":"fade","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>