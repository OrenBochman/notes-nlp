<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="keywords" content="Cosine similarity, Data generators, Hard negative mining, Modified Triplet Loss, Margin of safety, Cost function for Siamese networks">
<meta name="description" content="we cover Neural networks for deep learning, then build a tweet classifier that places tweets into positive or negative sentiment categories, using a DNN.">

<title>Siamese Networks – NLP Specialization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1372234da3246ce8e868649689ba5ed0.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-d99a2a2a191b5c7f2a9a83135e7f0803.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">NLP Specialization</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Sequence Models</li><li class="breadcrumb-item"><a href="../../notes/c3w4/index.html">Siamese Networks</a></li><li class="breadcrumb-item"><a href="../../notes/c3w4/index.html">Notes</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Sequence Models</li><li class="breadcrumb-item"><a href="../../notes/c3w4/index.html">Siamese Networks</a></li><li class="breadcrumb-item"><a href="../../notes/c3w4/index.html">Notes</a></li></ol></nav>
      <h1 class="title">Siamese Networks</h1>
            <p class="subtitle lead">Sequence Models</p>
                  <div>
        <div class="description">
          we cover Neural networks for deep learning, then build a tweet classifier that places tweets into positive or negative sentiment categories, using a DNN.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">NLP</div>
                <div class="quarto-category">Coursera</div>
                <div class="quarto-category">notes</div>
                <div class="quarto-category">Sequence Models</div>
                <div class="quarto-category">LSTM</div>
                <div class="quarto-category">Siamese networks</div>
                <div class="quarto-category">One shot learning</div>
                <div class="quarto-category">Triplet loss</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-body">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Wednesday, November 18, 2020</p>
      </div>
    </div>
    
      
    </div>
    

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>Cosine similarity, Data generators, Hard negative mining, Modified Triplet Loss, Margin of safety, Cost function for Siamese networks</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Classification &amp; Vector Spaces</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Logistic Regression</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Frequencies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Visualizing tweets</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Probability &amp; Bayes Rule</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Visualizing Naive Bayes</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Vector Space Models &amp; PCA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Linear algebra with NumPy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Manipulating word embeddings</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">MT &amp; Document Search via KNN</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vector manipulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Hash functions and multiplanes</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilistic Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Autocorrect &amp; Dynamic Programming</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Building the vocabulary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Candidates from String Edits</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">POS tagging &amp; HMMS</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vocabulary with unknowns</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Working with tags and Numpy</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Autocomplete &amp; Language Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - N-grams Corpus preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Building the language model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Out of vocabulary words</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Word embeddings with neural networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Data preparation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Intro to CBOW</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Training the CBOW</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequence Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Neural Networks for Sentiment Analysis</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Introduction to Trax</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Classes and Subclasses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Data Generators</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">RNN for Language Modeling</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Hidden State Activation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Calculating Perplexity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Vanilla RNNs, GRUs and the scan function</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L4 - Creating a GRU model using Trax</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false">
 <span class="menu-text">LSTMs and Named Entity Recognition</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vanishing Gradients</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">Siamese Networks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Creating a Siamese Model using Trax</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Modified Triplet Loss</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Evaluate a Siamese Model</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true">
 <span class="menu-text">NLP with Attention Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false">
 <span class="menu-text">Neural Machine Translation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-17" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Stack Semantics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - BLEU Score</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false">
 <span class="menu-text">Text Summarization</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-18" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Attention</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - The Transformer Decoder</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false">
 <span class="menu-text">Question Answering</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-19" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - SentencePiece and BPE</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - BERT Loss</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - T5</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false">
 <span class="menu-text">Chat Bots</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-20" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Reformer LSH</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Revnet</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-siamese-network" id="toc-sec-siamese-network" class="nav-link active" data-scroll-target="#sec-siamese-network">Siamese Network</a></li>
  <li><a href="#sec-architecture" id="toc-sec-architecture" class="nav-link" data-scroll-target="#sec-architecture">Architecture</a></li>
  <li><a href="#sec-lab-siamese" id="toc-sec-lab-siamese" class="nav-link" data-scroll-target="#sec-lab-siamese">Lab: Creating a Siamese Model using Trax</a></li>
  <li><a href="#sec-cost-function" id="toc-sec-cost-function" class="nav-link" data-scroll-target="#sec-cost-function">Cost Function</a></li>
  <li><a href="#sec-triplets" id="toc-sec-triplets" class="nav-link" data-scroll-target="#sec-triplets">Triplets</a></li>
  <li><a href="#sec-computing-cost-1" id="toc-sec-computing-cost-1" class="nav-link" data-scroll-target="#sec-computing-cost-1">Computing the Cost I</a></li>
  <li><a href="#sec-computing-cost-2" id="toc-sec-computing-cost-2" class="nav-link" data-scroll-target="#sec-computing-cost-2">Computing the Cost II</a></li>
  <li><a href="#sec-lab-modified" id="toc-sec-lab-modified" class="nav-link" data-scroll-target="#sec-lab-modified">Lab: Lecture Notebook: Modified Triplet Loss</a></li>
  <li><a href="#sec-one-shot" id="toc-sec-one-shot" class="nav-link" data-scroll-target="#sec-one-shot">One Shot Learning</a></li>
  <li><a href="#sec-training-testing" id="toc-sec-training-testing" class="nav-link" data-scroll-target="#sec-training-testing">Training and Testing</a></li>
  <li><a href="#sec-lab-evaluate" id="toc-sec-lab-evaluate" class="nav-link" data-scroll-target="#sec-lab-evaluate">Lab: Evaluate a Siamese Model</a></li>
  <li><a href="#sec-reflections" id="toc-sec-reflections" class="nav-link" data-scroll-target="#sec-reflections">Reflections</a></li>
  <li><a href="#sec-acknowledgments" id="toc-sec-acknowledgments" class="nav-link" data-scroll-target="#sec-acknowledgments">Acknowledgments</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/notes/c3w4/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full column-body" id="quarto-document-content">





<!-- TODO: link to Hinton course notes lesson with Siamese networks -->
<!-- TODO: find the papers on Siamese networks and Triplet loss -->

<div class="no-row-height column-margin column-container"><div class="nolightbox">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../../images/Course-Logo-3-3.webp" class="lightbox" data-gallery="slides" title="course banner"><img src="../../images/Course-Logo-3-3.webp" class="img-fluid figure-img" alt="course banner"></a></p>
<figcaption>course banner</figcaption>
</figure>
</div>
</div><div id="sup-slide-deck" class="quarto-float quarto-figure quarto-figure-center anchored" style="@page {size: 16in 9in;  margin: 0;}">
<figure class="quarto-float quarto-float-sup figure">
<div aria-describedby="sup-slide-deck-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="This week’s slides"><embed src="slides.pdf" style="@page {size: 16in 9in;  margin: 0;}" width="420" height="340"></a></p>
<figcaption>This week’s slides</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-sup quarto-uncaptioned" id="sup-slide-deck-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Supplementary Figure&nbsp;1
</figcaption>
</figure>
</div></div>
<p>My notes for Week 4 of the <a href="https://www.coursera.org/learn/sequence-models-in-nlp/home/welcome">Natural Language Processing with Sequence Models</a> Course in the Natural Language Processing Specialization Offered by <a href="DeepLearning.AI">DeepLearning.AI</a> on <a href="https://www.coursera.org/">Coursera</a></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked=""><a href="#sec-one-shot">One shot learning</a></label></li>
<li><label><input type="checkbox" checked=""><a href="#sec-triplets">Triplet loss</a></label></li>
<li><label><input type="checkbox" checked=""><a href="#sec-cosine-similarity">Cosine similarity</a></label></li>
<li><label><input type="checkbox" checked=""><a href="#sec-siamese-network">Siamese networks</a></label></li>
<li><label><input type="checkbox" checked=""><a href="#sec-data-generators">Data generators</a></label></li>
</ul>
</div>
</div>
<section id="sec-siamese-network" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-siamese-network">Siamese Network</h2>
<p>It is best to describe what a Siamese network is through an example.</p>

<div class="no-row-height column-margin column-container"><div id="fig-01" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide01.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;1: Comparisons questions pairs"><img src="img/slide01.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Comparisons questions pairs
</figcaption>
</figure>
</div></div><p>Note that in the first example above, the two sentences mean the same thing but have completely different words. While in the second case, the two sentences mean completely different things but they have very similar words.</p>
<ul>
<li><strong>Classification</strong>: learns what makes an input what it is.</li>
<li><strong>Siamese Networks</strong>: learns what makes two inputs the same</li>
</ul>
<p>Here are a few applications of siamese networks:</p>

<div class="no-row-height column-margin column-container"><div id="fig-02" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide02.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;2: NLP applications of Siamese Networks include, comparing two signatures, comparing questions or search engine queries,"><img src="img/slide02.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: NLP applications of Siamese Networks include, comparing two signatures, comparing questions or search engine queries,
</figcaption>
</figure>
</div></div><div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>In this video you’re going to learn about a special type of neural network known as the Siamese network. It is a neural network made up of two identical neural networks which are merged at the end. This type of architecture has many applications and NLP. And in this video, you’ll see the different examples where you can use it.</p>
</blockquote>
<blockquote class="blockquote">
<p>Consider the following question. How old are you? And what is your age? You can see that these questions don’t have any words in common. However, they both mean the same thing. On the other hand, if you were to look at the following questions, where are you from? And where are you going? You can see that the first three words are the same. However, the last word completely changes the meaning of each question. This example shows that comparing meaning is not as simple as just comparing words. Coming up, you’re going to see how you can use Siamese networks to compare the meaning of word sequences, and identify question duplicates, which is a very important NLP application at the core of platforms like Stack Overflow or Quora.</p>
</blockquote>
<blockquote class="blockquote">
<p>Before these platforms allow you to post a new question, they want to be sure that your question hasn’t already been posted by somebody else. Now take this sentence, I’m happy because I’m learning, and consider it in the context of sentiment analysis and binary classification. Now in training a classification algorithm, you discover what features give the statement a positive or negative sentiment.</p>
</blockquote>
<blockquote class="blockquote">
<p>With Siamese networks you’ll be aiming to identify what’s makes two input similar, and what makes them different. Take a look at these two questions. What is your age? And how old are you? When you build a Siamese model, you’re trying to identify the difference or the similarity between these two questions. You do this by computing a single similarity score, representing the relationship between the two questions. And based on that score when compared against a threshold, you can predict whether these two are the same or different.</p>
</blockquote>
<blockquote class="blockquote">
<p>Siamese networks have many applications in NLP, you can use them to authenticate handwritten checks by determining whether two signatures are the same or not. You can use them to identify question duplicates on platforms like Quora or Stack Overflow.</p>
</blockquote>
<blockquote class="blockquote">
<p>And you can use them in search engine queries to predict whether a new query is similar to the one that was already executed. These are just a few examples, but there are many more applications of Siamese networks in NLP.</p>
</blockquote>
<p>You can use Siamese networks in many types of NLP applications. In the next video, I’ll walk you through the architecture that is used in this type of model. And I’ll show you how you can use it in a text. I’ll see you in the next video.</p>
</div>
</div>
</div>
</section>
<section id="sec-architecture" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-architecture">Architecture</h2>
<p>The model architecture of a typical siamese network could look as follows:</p>

<div class="no-row-height column-margin column-container"><div id="fig-03" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide03.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;3: The architecture of a typical siamese network has two sub-networks consisting of embedding LSTMs and a cosine similarity function that evaluates their outputs."><img src="img/slide03.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: The architecture of a typical siamese network has two sub-networks consisting of embedding LSTMs and a cosine similarity function that evaluates their outputs.
</figcaption>
</figure>
</div></div><p>These two sub-networks are sister-networks which come together to produce a similarity score. Not all Siamese networks will be designed to contain LSTMs. One thing to remember is that sub-networks share identical parameters. This means that we only need to train one set of weights and not two.</p>
<p>The output of each sub-network is a vector. We can then run the output through a cosine similarity function to get the similarity score. In the next video, we will talk about the cost function for such a network.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Siamese networks have a special type of architecture. <mark>They have <strong>two identical sub-networks</strong> which are merged together through a <strong>dense layer</strong> to produce a final output or its <strong>similarity score</strong>.</mark> I like to think of these two sub-networks as sister-networks which come together to produce a similarity score.</p>
<p>In <a href="#fig-03" class="quarto-xref">Figure&nbsp;3</a> we can see the model architecture for a Siamese network. Note that the architecture presented here is just an example. Not all Siamese networks will be designed to contain LSTMs.</p>
<p>On the left, you have two inputs which represents Question 1 and Question 2. You will take each question, transform it into an embedding and then you’ll run the embedding through an LSTM layer to model the questions meaning. Each LSTM outputs a vector.</p>
<p>In this architecture, you have two identical sub-networks.<br>
One for Question 1 and the second for Question 2. <mark>An important note here is that the sub-networks share identical parameters. That is the learned parameters of each sub-network are exactly the same. So you actually only need to train one sets of weights, not two.</mark></p>
<p>Then given the two outputs vectors, one corresponding to each question, find their cosine similarity.</p>
<section id="what-is-cosine-similarity" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-is-cosine-similarity">What is cosine similarity?</h4>
<p>Recall that the cosine similarity is a measure of similarity between two vectors. When two vectors point generally in the same direction, the cosine of the angle between them is near one. For vectors that point in opposite directions, the cosine of the angle between them is minus one. If that sounds unfamiliar don’t worry.</p>
<p>Right now you just need to know that the cosine similarity tells you how similar two vectors are. In this case, it tells you how similar the two questions are.</p>
<p>The cosine similarity gives the Siamese networks prediction, denoted here by the variable y-hat, which will be a value between minus one and positive one.</p>
</section>
<section id="how-do-we-interpret-y-hat-and-tau" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="how-do-we-interpret-y-hat-and-tau">How do we interpret y-hat and tau?</h4>
<p>If y-hat is less than or equal to some threshold, tau, then you will say that the input questions are different. If y-hat is greater than tau, then you will say that they are the same.</p>
<p><mark>The threshold tau is a parameter that you will choose based on how often you want to interpret cosine similarity to indicate that two questions are similar or not.</mark> A higher threshold means that only very similar sentences will be considered similar.</p>
</section>
<section id="how-would-we-walking-through-the-architecture" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="how-would-we-walking-through-the-architecture">How would we walking through the architecture</h4>
<p>If you think of this process as a series of steps you take to get from your inputs to your outputs, it would go something like this; you start with a model architecture for a Siamese network made up of two identical sub-networks. In this case, your inputs are questions that you feed into each sub-network and each question gets transformed into an embedding and pass through an LSTM layer. Then you take the outputs of each of the sub-networks and compare them using cosine similarity to get your y-hat.</p>
<p>After seeing the model architecture, I’ll start talking about different cost functions you can use for this type of architecture.</p>
</section>
</div>
</div>
</div>
</section>
<section id="sec-lab-siamese" class="level2">
<h2 class="anchored" data-anchor-id="sec-lab-siamese">Lab: Creating a Siamese Model using Trax</h2>
<p><a href="../../notes/c3w4/lab01.html">Creating a Siamese Model using Trax</a></p>
</section>
<section id="sec-cost-function" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-cost-function">Cost Function</h2>
<p>Let us take a close look at the following slide:</p>

<div class="no-row-height column-margin column-container"><div id="fig-04" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide04.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure&nbsp;4: Understanding the triplet loss cost function"><img src="img/slide04.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Understanding the triplet loss cost function
</figcaption>
</figure>
</div></div><p>Note that when trying to compute the cost for a siamese network we use the triplet loss. The triplet loss usually consists of an Anchor and a Positive example. Note that the anchor and the positive example have a cosine similarity score that is very close to one. On the other hand, the anchor and the negative example have a cosine similarity score close to -1. Now we are ideally trying to optimize the following equation: <span class="math inline">−cos(A,P)+cos(A,N)≤0</span></p>
<p>Note that if <span class="math inline">cos(A,P)=1</span> is 1 and <span class="math inline">cos(A,N)=−1</span>, then the equation is definitely less than 0. However, as <span class="math inline">cos(A,P)</span> deviates from 1 and <span class="math inline">cos(A,N)</span> deviates from -1, then we can end up getting a cost that is <span class="math inline">&gt; 0</span>. Here is a visualization that would help we understand what is going on. Feel free to play with different numbers.</p>

<div class="no-row-height column-margin column-container"><div id="fig-05" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide05.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure&nbsp;5: A worked example of triplet loss"><img src="img/slide05.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-05-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: A worked example of triplet loss
</figcaption>
</figure>
</div><div id="fig-loss-function" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-loss-function-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide05.1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure&nbsp;6: Chart for the loss function"><img src="img/slide05.1.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-loss-function-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Chart for the loss function
</figcaption>
</figure>
</div></div>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>I’ll now show you a simple loss function you can use in your Siamese network.</p>
<p>Just as a recap, this is the overall structure of the Siamese network, which enables you to predict whether two questions are similar or different, or the outputs of the network, you are able to calculate y-hat, which is the similarity between the two questions.</p>
<p>Now, I’ll show you a loss function for a Siamese network.</p>
</blockquote>
<section id="what-are-positive-and-negative-questions" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-are-positive-and-negative-questions">What are positive and negative questions?</h4>
<blockquote class="blockquote">
<p>I’ll starts by looking at this first question, which is, “How old are you?” I’ll call this first question the anchor, which I’m going to use to compare against two other questions relative to the anchor.</p>
</blockquote>
<blockquote class="blockquote">
<p>Other questions that have the same meaning as the anchor are called <strong>positive questions</strong>. Whereas questions that do not have the same meaning as the anchor are called <strong>negative questions</strong>.</p>
</blockquote>
<blockquote class="blockquote">
<p>Note that the meaning of positive and negative in the context of finding question duplicates is referring to whether a question is similar to the anchor or not, and <mark>not whether it has a positive or negative sentiment</mark>.</p>
</blockquote>
</section>
<section id="what-is-a-positive-question" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-is-a-positive-question">What is a positive question?</h4>
<blockquote class="blockquote">
<p>The question, “What is your age?” is considered a positive question relative to the anchor, because “How old are you?” and “What is your age?” mean the same thing.</p>
</blockquote>
</section>
<section id="what-is-a-negative-question" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-is-a-negative-question">What is a negative question?</h4>
<blockquote class="blockquote">
<p>This other question, “Where are you from?” is considered a negative question because it does not have the same meaning as the anchor question.</p>
</blockquote>
</section>
<section id="what-is-cosine-similarity-1" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-is-cosine-similarity-1">What is cosine similarity?</h4>
<blockquote class="blockquote">
<p>Here’s a definition of cosine similarity between two vectors. <a href="#fig-04" class="quarto-xref">Figure&nbsp;4</a> That will be the similarity of function s. To train your model, you’ll be comparing the vectors that are outputs by each sub-network using similarity.</p>
<p>So for this example, you’re going to take the similarity between A and P, where A refers to the anchor question, and P refers to the positive question.</p>
<p><mark>Similarity is bounded between negative one and one.</mark> So for vectors that are completely different, the similarity is near negative one, and for vectors that are nearly identical, there similarity is close to positive one.</p>
<p>For a well-trained model, you would like to see a similarity close to one when comparing the anchor and the positive example. Similarly, when comparing the anchor to the negative example, a successful model should yield a similarity close to negative one.</p>
</blockquote>
</section>
<section id="how-do-you-compute-the-loss" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="how-do-you-compute-the-loss">How do you compute the loss?</h4>
<blockquote class="blockquote">
<p>To begin building a loss function, you start with the similarity of A and N and subtract the similarity of A and P to calculate the difference.</p>
<p>What you have here <a href="#fig-loss-function" class="quarto-xref">Figure&nbsp;6</a> is a loss function that allows you to determine whether your model is roughly doing what you hope it will do.</p>
<p>Namely, finding that the anchor and the positive example are similar, and that the anchor and the negative example are different.</p>
<p>As the difference gets bigger or smaller along the x-axis, the loss gets bigger or smaller along the y-axis.</p>
<p>When minimizing the loss in training, you are in effect minimizing this difference. You’ve started seeing a difference approach which will allow you to build a different cost function.</p>
</blockquote>
</section>
</div>
</div>
</div>
</section>
<section id="sec-triplets" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-triplets">Triplets</h2>
<p>We will now build on top of our previous cost function. To get the full cost function we will add a margin.</p>

<div class="no-row-height column-margin column-container"><div id="fig-06" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide06.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure&nbsp;7: Adding a margin to the triplet loss"><img src="img/slide06.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-06-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Adding a margin to the triplet loss
</figcaption>
</figure>
</div></div><p>Note that we added an <span class="math inline">α</span> in the equation above. This allows we to have a margin of “safety”.<br>
When computing the full cost, we take the <code>max</code> of that the outcome of <span class="math inline">−cos(A,P)+cos(A,N)+α</span> and 0. Note, we do not want to take a negative number as a cost.</p>
<p>Here is a quick summary:</p>
<ul>
<li><p><span class="math inline">𝜶</span>: controls how far <span class="math inline">cos(A,P)</span> is from <span class="math inline">cos(A,N)</span></p></li>
<li><p>Easy negative triplet: <span class="math inline">cos(A,N) &lt; cos(A,P)</span></p></li>
<li><p>Semi-hard negative triplet: $cos(A,N) &lt; cos(A,P) &lt; cos(A,N) + 𝜶 $</p></li>
<li><p>Hard negative triplet: <span class="math inline">cos(A,P) &lt; cos(A,N)</span></p></li>
</ul>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>You will now explore triplets. You’ll see how you can build pairs of inputs. Rather than just classifying what’s an input is, you’re going to build something that will allow you to identify the difference between two inputs. Let’s see how this works.</p>
<p>Here are three questions where the first one, <code>how old are you</code>, is the <strong>anchor</strong>. The second one is <strong>a positive example</strong>, <code>what is your age?</code> The third one, <code>where are you from?</code> is <strong>a negative example</strong>.</p>
<p>Having the three components here is what gives rise to the name triplets, which is to say, an anchor being used in conjunction with a positive and negative pairing. Accordingly, triplet loss is the name for a loss function that uses three components. <mark>The intuition behind this simple function is to minimize the difference between the similarity of A and N, and the similarity of A and P.</mark> You already know that, as the difference gets bigger or smaller along the x axis, the loss gets bigger or smaller along the y axis.</p>
</blockquote>
<section id="do-we-want-the-loss-to-be-less-than-zero" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="do-we-want-the-loss-to-be-less-than-zero">Do we want the loss to be less than zero?</h4>
<blockquote class="blockquote">
<p>But notice, when the difference is less than zero, do you also want the loss to be less than zero? Let’s think about this for a moment.</p>
<p>If you gave the model a positive loss value, the model uses this to update its weight to improve.</p>
<p>If you gave the model a negative loss value, this is like telling the model, “Good job. Please update your weight to the worst next time.”</p>
<p>So you don’t actually want to give the model a loss value that’s less than zero. In other words, when the model is doing a good job, you don’t want it to undo a its update. To make sure that the model doesn’t update itself to do worse, you can modify the loss so that whenever the diff is less than zero, the loss should just be zero. When the loss is zero, we’re effectively not asking the model to update it’s weights, because it is performing as expected for that training example. The loss-function now cannot take on negative values. If the difference is less than or equal to 0, the loss is 0. If the difference is greater than 0, then the loss is equal to the difference.</p>
<p>Notice the non-linearity happens at the origin of this line chart.</p>
<p>But you might also wonder what’s happens when the model is correct but only by a tiny bits? The model is still correct if the difference is a tiny number, that is less than zero.</p>
<p>What if you want the model to still learn from this example, and ask it to predict a wider difference for this training example?</p>
<p>You can think of shifting this loss function a little to the left, by a margin that we’ll refer to as Alpha. Let’s say we chose Alpha to be 0.2, if the difference between similarities is very small, like negative 0.1, then if you add it to the Alpha of 0.2, the result is still greater than 0. The sum of the diff plus Alpha can be considered a positive loss that tells the model to learn from this example.</p>
<p>You can see this visually in the line chart. <!-- figure --> The loss function is shifted to the left by the amount Alpha. The diff is along the horizontal axis. When the difference is less than zero but small in magnitude, the loss is greater than zero. So if the difference is smaller in magnitude than Alpha, then there is still a loss. <mark>This loss tells the model that it can still improve and learn from this training example.</mark> Triplet loss, as the difference with a margin Alpha, is what you will implement in the assignments which you will code like this, which is the triplet loss function for A, P and N. A small detail worth noting.</p>
<p>In these explanations, I’ve been using similarity because that’s what will be used in the programming assignments, so similarity of <span class="math inline">v_1</span>, <span class="math inline">v_2</span>.</p>
<p>But if you were to read the literature, you might find d of <span class="math inline">v_1</span>, <span class="math inline">v_2</span> used also, where this <span class="math inline">d</span> could be any function that calculates the distance between two vectors. A distance metric is the mirror image of a similarity metric, and a similarity metric can be derived from a distance metric.</p>
<p>One example of a distance metric is <strong>Euclidean distance</strong>.</p>
</blockquote>
</section>
<section id="how-do-we-pick-good-triplets" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="how-do-we-pick-good-triplets">How do we pick good triplets?</h4>
<blockquote class="blockquote">
<p>Selecting triplets A, P, and N for training involves two steps; first, select a pair of questions that are known to be duplicates to serve as the anchor and positive, and you’ll do this from the training set; second, select a question that is known to be difference in meaning from the anchor, to form the anchor and the negative pair.</p>
</blockquote>
</section>
<section id="why-not-use-random-triplets" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="why-not-use-random-triplets">Why not use random triplets?</h4>
<blockquote class="blockquote">
<p>If you were to select triplets at random, you’d be likely to select non-duplicative pairs A and N, where the loss is 0.<br>
The loss is zero whenever the model correctly predicts that A and P are more similar relative to A and N.</p>
<p>When the loss is 0, the network has nothing more to learn from the triplets example. So we can train more efficiently if we choose triplets that show the model when it’s incorrect, so that’s just going to adjust it’s weight and improve.</p>
</blockquote>
</section>
<section id="what-are-hard-triplets" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-are-hard-triplets">What are hard triplets?</h4>
<blockquote class="blockquote">
<p>Instead of selecting random triplets, you’ll specifically select so-called <strong>hard triplets</strong>. That is, triplets that are more difficult to train on. <mark>Hard triplets are those where the similarity between anchor and negative is very close to, but still smaller than the similarity between anchor and positive.</mark> When the model encounters a hard triplet, the learning algorithm needs to adjust its weight, so that’s it’s going to yield similarities that line up with the real-world labels. So by selecting hard triplets, focusing the training on doing better, on the difficult cases, that it’s predicting incorrectly.</p>
</blockquote>
<blockquote class="blockquote">
<p>I spoke about easy and hard triplets. I also spoke about a margin. In the next video, you’ll see how all these concepts come together to help us create a cost function.</p>
</blockquote>
</section>
</div>
</div>
</div>
</section>
<section id="sec-computing-cost-1" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-computing-cost-1">Computing the Cost I</h2>
<p>To compute the cost, we will prepare the batches as follows:</p>

<div class="no-row-height column-margin column-container"><div id="fig-07" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide07.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Figure&nbsp;8: An example batch of question pairs"><img src="img/slide07.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-07-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: An example batch of question pairs
</figcaption>
</figure>
</div></div><p>Note that each example, has a similar example to its right, but no other example means the same thing. We will now introduce <strong>hard negative mining</strong>.</p>

<div class="no-row-height column-margin column-container"><div id="fig-08" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-08-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide08.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure&nbsp;9: Hard negative mining"><img src="img/slide08.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-08-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Hard negative mining
</figcaption>
</figure>
</div></div><p>Each horizontal vector corresponds to the encoding of the corresponding question. Now when we multiply the two matrices and compute the cosine, we get the following:</p>

<div class="no-row-height column-margin column-container"><div id="fig-09" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-09-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide09.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure&nbsp;10: Understanding Cost matrix for a batch of question pairs"><img src="img/slide09.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-09-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Understanding Cost matrix for a batch of question pairs
</figcaption>
</figure>
</div></div><p>The diagonal line corresponds to scores of similar sentences, (normally they should be positive). The off-diagonals correspond to cosine scores between the anchor and the negative examples.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Welcome back. As promised, you’ll see how everything fits together now. You will start by building a cost function, and then you will use gradient descent to optimize this cost function. Let’s take a look at how this works. To compute the cost, begin by preparing the data in batches. Here you have the questions, what is your age and how old are you? You can see these are duplicates, because they mean the same thing. Can you see me and are you seeing me? Are also duplicates. Where are thou and where are you? Are duplicates too. As are, when is the game and what time is the game? So with four pairs, you have batch size of four. Here we will use the letter b to stand for batch size. Something that’s very important to note is that each question has its corresponding duplicate to the left or right of it. That is, in each row all of the sentences in the columns are duplicates. But you will notice that each question has no duplicates above or below it. That is, for any column, none of the rows in those column contain a sentence that is a duplicate of another sentence in those column. So this is how you prepare the batches. Now, let me show you how you will want to organize the data in this way. Given the first batch, you’re going to run it through this model to get a vector v_1 with dimensions one row by five columns. The number of columns shown in this matrix is equal to the dimension of your embedding layer, which in this case is five. I’ll refer to this dimension of the embedding layer as d model for each question in the batch. I haven’t talked about the dimension of the embedding layer yet, but don’t worry, it will become more clear once you’re working with the code. The important takeaway is that the dimension of the embedding, the model, is a parameter that determines the dimensions of the weights through each layer in the model, and thus determines the size of the outputs vector. The model is running a batch size that is greater than one. So the v_1 outputs is actually a matrix of stacked vectors like this. In this visual example, there are four rows in this matrix to indicate that there are four observations in this batch. The batch size is four. Our subscript to observations in the batch as v_1_1, v_1_2, and so on corresponding to the vector outputs for each question in the batch. You’ll do the same thing for the batch of v_2 vectors. Each question in the batch 1 is a duplicate of its corresponding question in batch 2. But none of the questions in batch 1 are duplicates of each other. The same applies to batch 2. Here, for example, v_1_1 is a duplicate of v_2_1, as are the rest of the respective row pairs. But v_1_1 is not a duplicates of any other rows in v_1. The last step is to combine the two branches of the Siamese network by calculating the similarity between all vector pair combinations of v_1 with v_2. For this example with a batch size of four, you might get a matrix of similarities that looks like this. The diagonal is a key feature here. These values are the similarities for all your positive examples, the question duplicates. Notice that all the values are generally greater than the numbers in the off diagonals. So the model is performing as you would expect for duplicates questions, because you would expect that the question duplicates to have higher similarity compared to the non-duplicates. In the upper right and lower left, you have the similarities for all the negative examples. These are the results for the non-duplicates pairs. Notice that most of these numbers are lower than the similarities that’s are along the diagonal. Also notice that you can have negative example question pairs that still have a similarity greater than zero. The range of similarity ranges from negative 1 to positive 1, but there isn’t any special requirements that a similarity greater than zero indicates duplicates or that’s a similarity less than zero indicates non-duplicates. What’s matters for a properly functioning model is that it generally finds that duplicates have a higher similarity relative to non-duplicates. Creating non-duplicates pairs like this removes the need for additional non-duplicate examples and the input data, which turns out to be a big deal. Instead of needing to sets up specific batches with negative examples, your model can learn from them in the existing question duplicates batches. Now, you can just stop here and use these similarities with the triplet loss function you already know shown here. Then the overall costs for your Siamese network will be the sum of these individual losses over the training sets. Here you can see that superscripts i refers to a specific training example and there are m observations, but there are more techniques available that’s can vastly improve upon model performance. I’ll show you those next.</p>
</div>
</div>
</div>
</section>
<section id="sec-computing-cost-2" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-computing-cost-2">Computing the Cost II</h2>
<p>Now that we have the matrix with cosine similarity scores, which is the product of two matrices, we go ahead and compute the cost.</p>

<div class="no-row-height column-margin column-container"><div id="fig-10" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Figure&nbsp;11: "><img src="img/slide10.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11
</figcaption>
</figure>
</div></div><p>We now introduce two concepts, the <strong>mean_neg</strong>, which is the mean negative of all the other off diagonals in the row, and the <strong>closest_neg</strong>, which corresponds to the highest number in the off diagonals.</p>
<p><span class="math display">
Cost = \max(−\cos(A,P)+\cos(A,N)+α,0)
</span></p>
<p>So we will have two costs now:</p>
<p><span class="math display">
Cost_1 = \max(−\cos(A,P)+ mean_n eg + α,0)
</span></p>
<p><span class="math display">
Cost_2 = \max(−\cos(A,P)+ closest_n eg + α,0)
</span> ⁡</p>
<p>The full cost is defined as: Cost1 + Cost2.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>Previously, you set up the training data into two specific batches, each batch containing no duplicate questions within it. You ran those batches through one sub network each. And that’s produced a vector of supports per question. Which has dimension 1 by d_model, where d_model is the embedding dimension. And is equal to the number of columns in the matrix, which is five, at least in this example. The <span class="math inline">v_1</span> vectors for a single batch are stuck together. And in this case, the batch size is the number of rows shown in this matrix, which is four. You can see a similar batch of <span class="math inline">v_2</span> vectors as well. The last step was to combine the two branches of the Siamese network. By calculating the similarity between all vector pair combinations of the <span class="math inline">v_1</span> vectors and <span class="math inline">v_2</span> vectors. For this example with a batch size of four, that last step would produce a matrix of similarities that looks something like this.</p>
</blockquote>
<section id="what-are-the-attributes-of-this-matrix" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-are-the-attributes-of-this-matrix">What are the attributes of this matrix?</h4>
<blockquote class="blockquote">
<p>This matrix has some important attributes. The similarities along the green diagonal contain similarities for the duplicate questions. For a well trained model, these values should be greater than similarities for the off-diagonals. Reflecting the fact that the network produces similar vector outputs for duplicate questions. The orange values in the upper right and lower left are similarities for the non duplicate questions.</p>
<p>Now this is where things get really interesting. You can use this off diagonal information to make some modifications to the loss function and really improve your models performance. To do so, I’m going to make use of two concepts.</p>
</blockquote>
</section>
<section id="what-is-the-mean-negative" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-is-the-mean-negative">What is the mean negative?</h4>
<blockquote class="blockquote">
<p>The first concept is the mean negative, which is just the mean or average of all the off-diagonal values in each row. Notice that off-diagonal elements can still be positive numbers. So when I say mean negative, I’m referring to the mean of the similarity for negative examples, not the mean of negative numbers in a row.</p>
<p>For example, the mean negative of the first row is just the mean of all the off-diagonal values in that row.</p>
<p>In this case, -0.8, 0.3 and -0.5, excluding the value 0.9, which is on the diagonal. You can use the mean negative to help speed up training by modifying the loss function, which I’ll show you soon.</p>
</blockquote>
</section>
<section id="what-is-the-closest-negative" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-is-the-closest-negative">What is the closest negative?</h4>
<blockquote class="blockquote">
<p>The next concept is what’s called the closest negative. As mentioned earlier, because of the way you define the triplet loss function, you’ll need to choose so called hard triplets to train on. What this means is that for training, you want to choose triplets where the cosine similarity of the negative example is close to the similarity of the positive example.</p>
<p>This forces your model to learn what differentiates these examples and ultimately drive those similarity values further apart through training. To do this, you’ll search each row in your output matrix for the closest negative. Which is to say the off diagonal value which is closest to, but still less than the value on the on diagonal for that row. So in this first row, the value on the diagonal is 0.9. So the closest off-diagonal elements in this case is 0.3. What this means is that this negative example with a similarity of 0.3 has the most to offer your model in terms of learning opportunity.</p>
</blockquote>
</section>
<section id="how-do-we-use-these-new-concepts" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="how-do-we-use-these-new-concepts">How do we use these new concepts ?</h4>
<blockquote class="blockquote">
<p>To make use of these new concepts, recall that the triplet loss was defined as the max of the similarity of A and N minus the similarity of A and B plus the margin alpha and 0. Also recall that we refer to the difference between the two similarities with the variable named diff.</p>
<p>Here, we’re just writing out the definition of diff. So in order to minimize the loss you want this diff plus the margin alpha to be less than or equal to 0. I’ll introduce loss 1 to be the max of the mean negative minus the similarity of A and P plus alpha and 0. The change between the formulas for triplet loss and loss 1 is the replacement of similarity of A and N. With the mean negative, this helps the model converge faster during training by reducing noise. It reduces noise by training on just the average of several observations, rather than training the model on each of these off-diagonal examples.</p>
<p>So why does taking the average of several observations usually reduce noise? Well, we define noise to be a small value that comes from a distribution that is centered around 0. So in other words, the average of several noise values is usually 0. So if we took the average of several examples, this has the effect of cancelling out the individual noise from those observations. Then loss 2 will be the max of the closest negative minus the similarity of A and B plus alpha and 0.</p>
<p>The difference between the formulas this time is the replacement of the cosine of A and N. With the closest negative, this helps create a slightly larger penalty by diminishing the effects of the otherwise more negative similarity of A and N that it replaces.</p>
<p>You can think of the closest negative as finding the negative example that results in the smallest difference between the two cosine similarities. If you had that small difference to alpha, then you’re able to generate the largest loss among all of the other examples in that row.</p>
<p>By focusing the training on the examples that produce higher loss values, you make the model update its weights more.</p>
<p>To learn from these more difficult examples, then you can define the full loss as loss 1 + loss 2. And you will use this new full loss as an improved triplet loss in the assignments. The overall costs for your Siamese network will be the sum of these individual losses over the training sets.</p>
</blockquote>
<blockquote class="blockquote">
<p>In the next video, you will use this cost function in one shot learning. One shot learning is a very effective technique that can save you a lot of time when comparing the authenticity of checks or of any other type of inputs</p>
</blockquote>
</section>
</div>
</div>
</div>
</section>
<section id="sec-lab-modified" class="level2">
<h2 class="anchored" data-anchor-id="sec-lab-modified">Lab: Lecture Notebook: Modified Triplet Loss</h2>
<p><a href="../../notes/c3w4/lab02.html">Modified Triplet Loss</a></p>
</section>
<section id="sec-one-shot" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-one-shot">One Shot Learning</h2>
<p>Imagine we are working in a bank and we need to verify the signature of a check. We can either build a classifier with K possible signatures as an output or we can build a classifier that tells we whether two signatures are the same.</p>

<div class="no-row-height column-margin column-container"><div id="fig-11" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Figure&nbsp;12: Classification vs one shot learning"><img src="img/slide11.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-11-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: Classification vs one shot learning
</figcaption>
</figure>
</div></div><p>Hence, we resort to one shot learning. Instead of retraining your model for every signature, we can just learn a similarity score as follows:</p>

<div class="no-row-height column-margin column-container"><div id="fig-12" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="Figure&nbsp;13: "><img src="img/slide12.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13
</figcaption>
</figure>
</div></div><div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>Let’s say that you’re trying to identify whether the author for a certain poem is Lucas or not. You can either take all of Lucas’ poems and put them into datasets, and instead of predicting K classes, you will now predict K plus 1 classes. All the previous poems of other authors plus Lucas’, so that’s why it’s k plus 1. Or you can compare one of Lucas’ poems to another poem, and that is where one-shot learning comes in. In this video, I’ll show you how you can do that. To understand the difference between classification and one-shot learning, first consider identifying or classifying signatures based on one through K possible classes. You might use some classification model trained on the K classes, probably with a softmax function at the end to find the maximum probability. Then at recognition time, classify the input signature to one of those corresponding classes. That’s great if you have a signature list that’s rarely changes. But what if you get a new signature to classify? It would be expensive to retrain the model every time this happens, and besides, unless you have a great many examples of that new signature, model training won’t work very well. In one-shot learning, you need to be able to recognize a signature repeatedly from just one example. You can do this with a learned similarity function. Then you can test a similarity score against some threshold to see if two signatures are the same. So the problem changes to determining which class to instead measuring similarity between two classes. This is very useful, especially in banks, for example. Every time there’s a new signature, you can’t retrain your entire system to classify the signatures into K possible outputs. So instead, you just learn a similarity function that can be used to calculate a similarity score. That can in turn be used to identify whether two signatures are the same. You already did this using cosine similarity as the similarity function. If the result was greater than some threshold Tau, you determine the inputs to be the same. In the case of comparing signatures, if the similarity is less than or equal to Tau, then the signatures are different. In this video, I spoke about one-shot learning and I told you why it is a very effective technique. One-shot learning makes use of Siamese networks. In the next video, I’ll show you how you can train and test your Siamese network.</p>
</blockquote>
</div>
</div>
</div>
</section>
<section id="sec-training-testing" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-training-testing">Training and Testing</h2>
<p>After preparing the batches of vectors, we can proceed to multiplying the two matrices.</p>
<p>Here is a quick recap of the first step:</p>

<div class="no-row-height column-margin column-container"><div id="fig-13" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16" title="Figure&nbsp;14: Preparing batches of questions"><img src="img/slide13.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-13-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: Preparing batches of questions
</figcaption>
</figure>
</div></div><p>The next step is to implement the siamese model as follows:</p>

<div class="no-row-height column-margin column-container"><div id="fig-14" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-14-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="img/slide14.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17" title="Figure&nbsp;15: Reviewing the architecture of the siamese networks"><img src="img/slide14.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-14-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15: Reviewing the architecture of the siamese networks
</figcaption>
</figure>
</div></div><p>Finally when testing:</p>
<ol type="1">
<li>Convert two inputs into an array of numbers</li>
<li>Feed it into your model</li>
<li>Compare <span class="math inline">𝒗_1,𝒗_2</span> using <em>cosine similarity</em></li>
<li>Test against a threshold <span class="math inline">\tau</span></li>
</ol>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>In this video, you’re goingto see what the dataset would look like for a Siamese network. I’ll show you how you can train your model and then you can use that model to test your Siamese network. Let’s take a look at how you can do this. You’ll be using the Quora question duplicates datasets for this week’s programming assignment. It looks like this. It consists of a collection of question pairs within its duplicates Boolean for each question. For example, for Question 1 and Question 2, “What is your age?” and “How old are you?” Its duplicate equals “true” because these two questions are duplicates. “Where are you from?” and “Where are you going?” are not duplicates, so it’s false and so on. This dataset gives your model plenty of examples to learn from. First, you will process the dataset so that it looks like this. You will pre-process the data into batches of size b. The corresponding questions from each batch are duplicates. For example, the first question in Batch 1, “What is your age?” is a duplicate of the first question in Batch 2, “How old are you?” The second question in Batch 1 is a duplicate of the second question in Batch 2 and so on.</p>
<p>Note however, that there are no duplicates within an individual batch. If I call this <span class="math inline">q1_a</span>, this <span class="math inline">q2_a</span>, then <span class="math inline">q1_a</span> and <span class="math inline">q2_a</span> are duplicates. If this was <span class="math inline">q1_b</span> and this was <span class="math inline">q2_b</span>, then <span class="math inline">q1_b</span> and <span class="math inline">q2_b</span> are duplicates. However, <span class="math inline">q1_a</span> and <span class="math inline">q1_b</span> are not duplicates. Similarly, <span class="math inline">q2_a</span> and <span class="math inline">q2_b</span> are not duplicates. I’ll show you how to prepare the batches in such a way that no question within the same batch is duplicated. Finally, you’ll use these inputs to get outputs vectors for each batch. Then, you can calculate the cosine similarity between each pair of output vectors. This is the Siamese model that you’ll be implementing in the assignment. You’ll create a subnetwork, which is then duplicated and drawn in parallel. In each subnetwork, you got the embedding, run it through the LSTM, take your vector output, and then use them to find the cosine similarity.</p>
</blockquote>
<blockquote class="blockquote">
<p>An important note here, is that the learned parameters of the subnetworks are exactly the same between the two subnetworks. So you are actually only training one sets of weights, not two. When testing the model, you will perform one-shot learning. The goal is to find a similarity score between two inputs questions. First, convert each input into an array of numbers. Feed these into your model. Compare the subnetwork outputs <span class="math inline">v_1</span> and <span class="math inline">v_2</span> using cosine similarity for a similarity score. Then, test the score against some threshold Tau, and if the cosine similarity is greater than Tau, then the questions are classified as duplicates.</p>
</blockquote>
<blockquote class="blockquote">
<p>Note that both $tau$ and the margin <span class="math inline">\alpha</span> from the last function are <strong>tunable hyperparameters</strong>.</p>
</blockquote>
<blockquote class="blockquote">
<p>Congratulations, you now know how to train your Siamese network and you know how to test it. In this week’s programming exercise, you’ll be using a Siamese network to identify whether a question is a duplicate or not. Specifically, you’ll be using the Quora question duplicate data sets, and using that, you’ll be able to get a very good accuracy.</p>
</blockquote>
</div>
</div>
</div>
</section>
<section id="sec-lab-evaluate" class="level2">
<h2 class="anchored" data-anchor-id="sec-lab-evaluate">Lab: Evaluate a Siamese Model</h2>
<p><a href="../../notes/c3w4/lab03.html">Evaluate a Siamese Model</a></p>
</section>
<section id="sec-reflections" class="level2">
<h2 class="anchored" data-anchor-id="sec-reflections">Reflections</h2>
<ul>
<li><p>Could we improve the model by Can we give each LSTM it own loss function?</p></li>
<li><p>What are some typical use cases for using Siamese networks?</p>
<ul>
<li><strong>Face recognition</strong>. The faces are very different from each other but we don’t want to retrain the model for every new face - we typically want to check if a face is the same as one of the faces on file.</li>
<li><strong>Signature verification</strong> is a good example of a use case for Siamese networks. We want to check if a signatures we get is sufficiently similar to the few samples we have on file.</li>
<li><strong>One shot learning</strong> is another area where Siamese networks could be useful.</li>
</ul></li>
<li><p>In which NLP tasks are Siamese networks utilized?</p>
<ul>
<li><strong>Search engine queries</strong> are often challenging since they are very brief compared to the documents they are searching for, and so they tend to miss the best variation for some query. Also the distribution has many similar queries and a long tail of unique queries.</li>
<li><strong>Question-Answering</strong> sites like Stack overflow or Quora is another place where Siamese networks could be useful. The crowd sourcing works better if the questions are not repeated so that all the answers are in one place.</li>
<li><strong>Paraphrase detection</strong> is another area where Siamese networks could be useful. The paraphrase could be a completely different sentence but the meaning remains the same.</li>
<li><strong>Spam detection</strong> is another area where Siamese networks could be useful. The spammer could change the words in the spam message but the meaning remains the same.</li>
</ul></li>
<li><p>How can we improve the model by using a different similarity function?</p></li>
<li><p>Are there any benefits to use Location sensitive hashing with the cosine similarity function ?</p></li>
</ul>
</section>
<section id="sec-acknowledgments" class="level2">
<h2 class="anchored" data-anchor-id="sec-acknowledgments">Acknowledgments</h2>
<ul>
<li><span class="citation" data-cites="Chadha2020DistilledNotesCourseraDLSpec">(<a href="#ref-Chadha2020DistilledNotesCourseraDLSpec" role="doc-biblioref">Chadha 2020</a>)</span> <a href="https://aman.ai/coursera-nlp/logistic-regression/">Aman Chadha’s Notes</a></li>
<li><a href="https://github.com/ibrahimjelliti/Deeplearning.ai-Natural-Language-Processing-Specialization/tree/master/1%20-%20Natural%20Language%20Processing%20with%20Classification%20and%20Vector%20Spaces#testing-logistic-regression">Ibrahim Jelliti’s Notes</a></li>
</ul>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Chadha2020DistilledNotesCourseraDLSpec" class="csl-entry" role="listitem">
Chadha, Aman. 2020. <span>“Distilled Notes for the Natural Language Processing Specialization on Coursera (Offered by Deeplearning.ai).”</span> <a href="https://www.aman.ai" class="uri">https://www.aman.ai</a>. <a href="https://www.aman.ai">www.aman.ai</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2020,
  author = {Bochman, Oren},
  title = {Siamese {Networks}},
  date = {2020-11-18},
  url = {https://orenbochman.github.io/notes-nlp/notes/c3w4/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2020" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2020. <span>“Siamese Networks.”</span> November 18, 2020.
<a href="https://orenbochman.github.io/notes-nlp/notes/c3w4/">https://orenbochman.github.io/notes-nlp/notes/c3w4/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2023-2025, Oren Bochman</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/notes/c3w4/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 💛 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"right","loop":true,"openEffect":"fade","selector":".lightbox","skin":"my-css-class"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>