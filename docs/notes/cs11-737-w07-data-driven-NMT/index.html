<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="keywords" content="Evaluation, Data augmentation">
<meta name="description" content="This week we will cover text classification and sequence labeling. We will start with the basics of text classification, and then move on to more advanced topics like sequence labeling.">

<title>Data-driven Strategies for NMT – NLP Course Notes &amp; Research</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1372234da3246ce8e868649689ba5ed0.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-d99a2a2a191b5c7f2a9a83135e7f0803.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/videojs/video.min.js"></script>
<link href="../../site_libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>

      .quarto-title-block .quarto-title-banner {
        background: images/banner_deep.jpg;
      }
</style>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Data-driven Strategies for NMT – NLP Course Notes &amp; Research">
<meta property="og:description" content="This week we will cover text classification and sequence labeling. We will start with the basics of text classification, and then move on to more advanced topics like sequence labeling.">
<meta property="og:image" content="https://orenbochman.github.io/notes-nlp/images/nlp-brain-wordcloud.jpg">
<meta property="og:site_name" content="NLP Course Notes &amp; Research">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">NLP Course Notes &amp; Research</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Data-driven Strategies for NMT</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Data-driven Strategies for NMT</h1>
            <p class="subtitle lead">CMU CS11-737: Multilingual NLP</p>
                  <div>
        <div class="description">
          This week we will cover text classification and sequence labeling. We will start with the basics of text classification, and then move on to more advanced topics like sequence labeling.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Attention</div>
                <div class="quarto-category">Multilingual NLP</div>
                <div class="quarto-category">NLP</div>
                <div class="quarto-category">Notes</div>
                <div class="quarto-category">NMT</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-body">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Thursday, February 3, 2022</p>
      </div>
    </div>
    
      
    </div>
    

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>Evaluation, Data augmentation</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Classification &amp; Vector Spaces</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Logistic Regression</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Frequencies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Visualizing tweets</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Probability &amp; Bayes Rule</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Visualizing Naive Bayes</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Vector Space Models &amp; PCA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Linear algebra with NumPy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Manipulating word embeddings</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">MT &amp; Document Search via KNN</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vector manipulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Hash functions and multiplanes</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilistic Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Autocorrect &amp; Dynamic Programming</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Building the vocabulary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Candidates from String Edits</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">POS tagging &amp; HMMS</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vocabulary with unknowns</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Working with tags and Numpy</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Autocomplete &amp; Language Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - N-grams Corpus preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Building the language model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Out of vocabulary words</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Word embeddings with neural networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Data preparation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Intro to CBOW</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Training the CBOW</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequence Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Neural Networks for Sentiment Analysis</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Introduction to Trax</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Classes and Subclasses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Data Generators</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">RNN for Language Modeling</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Hidden State Activation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Calculating Perplexity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Vanilla RNNs, GRUs and the scan function</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L4 - Creating a GRU model using Trax</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false">
 <span class="menu-text">LSTMs and Named Entity Recognition</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vanishing Gradients</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false">
 <span class="menu-text">Siamese Networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Creating a Siamese Model using Trax</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Modified Triplet Loss</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Evaluate a Siamese Model</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true">
 <span class="menu-text">NLP with Attention Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false">
 <span class="menu-text">Neural Machine Translation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-17" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Stack Semantics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - BLEU Score</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false">
 <span class="menu-text">Text Summarization</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-18" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Attention</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - The Transformer Decoder</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false">
 <span class="menu-text">Question Answering</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-19" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - SentencePiece and BPE</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - BERT Loss</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - T5</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false">
 <span class="menu-text">Chat Bots</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-20" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Reformer LSH</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Revnet</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#papers" id="toc-papers" class="nav-link active" data-scroll-target="#papers">Papers:</a></li>
  <li><a href="#in-class-assignment" id="toc-in-class-assignment" class="nav-link" data-scroll-target="#in-class-assignment">In-class Assignment</a></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources">Resources</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/notes/cs11-737-w07-data-driven-NMT/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full column-body" id="quarto-document-content">






<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/tiling.png" class="nolightbox img-fluid figure-img" width="200"></p>
<figcaption>course banner</figcaption>
</figure>
</div><div id="vid-01" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-vid figure">
<div aria-describedby="vid-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/XeDCP0newd8?list=PL8PYTP1V4I8BhCpzfdKKdd1OnTfLcyZr7&amp;index=17&amp;ab_channel=GrahamNeubig" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-vid" id="vid-01-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Video&nbsp;1: Lesson Video
</figcaption>
</figure>
</div><div id="vid-02" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-vid figure">
<div aria-describedby="vid-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video"><video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="https://aclanthology.org/P19-1579.mp4"></video></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-vid" id="vid-02-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Video&nbsp;2: Generalized Data Augmentation for Low-Resource Translation (<span class="citation" data-cites="xia-etal-2019-generalized">Xia et al. (<a href="#ref-xia-etal-2019-generalized" role="doc-biblioref">2019</a>)</span>)
</figcaption>
</figure>
</div><div id="vid-03" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-vid figure">
<div aria-describedby="vid-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video"><video id="video_shortcode_videojs_video2" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="https://aclanthology.org/Q17-1024.mp4"></video></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-vid" id="vid-03-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Video&nbsp;3: Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation (<span class="citation" data-cites="johnson-etal-2017-googles">Johnson et al. (<a href="#ref-johnson-etal-2017-googles" role="doc-biblioref">2017</a>)</span>)
</figcaption>
</figure>
</div><div id="vid-04" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-vid figure">
<div aria-describedby="vid-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-video"><video id="video_shortcode_videojs_video3" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="https://aclanthology.org/D18-1103.mp4"></video></div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-vid" id="vid-04-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Video&nbsp;4: Rapid Adaptation of Neural Machine Translation to New Languages (<span class="citation" data-cites="neubig-hu-2018-rapid">Neubig and Hu (<a href="#ref-neubig-hu-2018-rapid" role="doc-biblioref">2018</a>)</span>)
</figcaption>
</figure>
</div><div id="sup-slide-deck" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides" style="@page {size: 16in 9in;  margin: 0;}">
<figure class="quarto-float quarto-float-sup figure">
<div aria-describedby="sup-slide-deck-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="slides" title="This week’s slides"><embed src="slides.pdf" style="@page {size: 16in 9in;  margin: 0;}" width="420" height="340"></a></p>
<figcaption>This week’s slides</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-sup quarto-uncaptioned" id="sup-slide-deck-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Supplementary Figure&nbsp;1
</figcaption>
</figure>
</div></div>




<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Transcript
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<blockquote class="blockquote">
<p>This time I’ll be talking about Machine Translation one more time</p>
<p>I didn’t get a chance to talk about <strong>evaluation of translation</strong> two times ago. I’d like to start out with that because that’s pretty important and then we can talk about <strong>the data augmentation strategies</strong>.</p>
</blockquote>
</section>
<section id="machine-translation-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="machine-translation-evaluation">Machine Translation Evaluation</h2>
<blockquote class="blockquote">
<p>MT evaluation is a very important and difficult topic in doing machine translation research. <mark>I think we’ve gotten to the point where almost evaluating how well we’re doing is maybe as difficult as like actually doing the translation itself</mark> The reason for this is: if we output a translation there are many different correct translations. We could have paraphrases where the output is “this is a dog”, “I see a dog”, “there is a dog” here other things like this and all of those would be appropriate for an equivalent sentence in another language.</p>
</blockquote>
</section>
<section id="manual-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="manual-evaluation">Manual Evaluation</h2>
<blockquote class="blockquote">
<p>The basic evaluation paradigm in MT. There’s two different types. There’s human evaluation or manual evaluation and automatic evaluation. This is the basic evaluation paradigm for automatic evaluation. Where basically what we do is we have a parallel test set where we have an input and an output in the language pair that we’re interested in. We use a system to generate translations and we compare the target translations with references. Before I talk a little bit more detail about that I’d like to talk about kind of manual evaluation. This is the gold standard of doing evaluation of translation systems. Where basically we ask human evaluators to check whether the answer is correct or not. To give an example we’ve taken a source side sentence we generate some outputs and you can either evaluate by having a human evaluator look at the source in the output or look at a reference and in the output and the reference would be like the so-called correct translation looking at the source and the output only works if you’re bilingual in both languages and it’s somewhat difficult to get bilingual speakers or at least more expensive however given the quality of machine translation systems nowadays very often you don’t know if the output of a human translator like your reference is better than the machine translation system so like very often if you hire a person to do evaluation you know they might not try super hard and like I mentioned before so kind of the gold standard is to get somebody who knows the source and the target to do the evaluation there’s a number of different axes along which you can do evaluation I just listed a couple of them here one is adequacy and adequacy is basically whether the meaning of the translation is conveyed properly and the in this case this is the correct answer here you would know this if you knew japanese which you know most people don’t but if you knew japanese you would know the first one is correct so this is perfectly adequate it conveys the target message the middle one is conveys the target message but is this fluent so it would score high on an adequacy scale but on a fluency scale it would score low the one over here is fluent but not adequate so basically it switched the subject to that object for order so it would be wrong and one notable thing about fluency is you don’t need to know the source language to evaluate fluency all you need to know is the target language because it only has to do with whether the output is fluent or not you can also do pairwise evaluation which just says which one of these is better one of the good things about pairwise evaluation is it’s very simple because you just ask question which do you like better which do you think is a better translation the problem with it is it doesn’t give you an absolute idea of how well you’re doing so if you have two really bad systems and say which is better one might be better but they’re both really bad if you have two really good systems and say which is better one might be better but they’re both really good so kind of absolute scales have that advantage another thing is just like you might get bad translators you might get lazy evaluators you know if you hire people on mechanical turks and they’re not very motivated for example so you need to be careful about quality control as well</p>
</blockquote>
</section>
<section id="human-evaluation-shared-tasks" class="level2">
<h2 class="anchored" data-anchor-id="human-evaluation-shared-tasks">Human Evaluation Shared Tasks</h2>
<blockquote class="blockquote">
<p>There’s a <strong>human evaluation shared tasks</strong> so the most famous one is <em>the conference on machine translation shared tasks</em>. I can show you a little bit what this looks like. They basically have a whole bunch of tasks that you can participate in most of these are tasks for actual translation, but they also have evaluation tasks on metrics and quality estimation so basically what you try to do here is you try to create a metric that has the highest correlation with with human evaluation and for quality estimation what this is is this is essentially evaluation without a gold standard reference so you’re just given the input and the output and you want to guess how good the system output is and this is harder obviously because you don’t have an example of what a good translation looks like but it’s also very useful in practical situations where like let’s say you’re a machine translation company and you want to decide whether you need to get a human translator to go in and check the output and correct it or something like that so if that’s the case if you can estimate very accurately whether the input and output are correct or not then that would save you money save you time give you confidence in the results</p>
</blockquote>
</section>
<section id="bleu-scores-bilingual-evaluation-understudy" class="level2">
<h2 class="anchored" data-anchor-id="bleu-scores-bilingual-evaluation-understudy">BLEU Scores (BiLingual Evaluation Understudy)</h2>
<blockquote class="blockquote">
<p>There’s also other leaderboards and stuff for other seq2seq models but that’s a little bit less important for this multilingual class. There are other metrics like BLEU scores so BLEU score is very famous. You know if you’ve done any research on machine translation or even heard of it you probably encountered BLEU. The exact details of how BLEU is calculated are: What you do is you take the precision of N-grams output by the system. So for example if you look at the unigram precision that’s out of all the unigrams that the system output how many of them exist in a reference or one of the references that you’re provided. If in the case that you’re using multiple references and this gives you a position of like three out of five and then you take the geometric mean of N-grams, usually one to four and then you also have a penalty for outputting two short sentences. Because one way to improve your precision is to not output very many things &gt; This is basically to prevent you from gaming system. But the important thing is now the details of how BLEU is calculated probably the important thing is that this is a <strong>lexical metric</strong> which means that you’re just doing exact match with the references and this has a few issues. One of the issues is essentially that you So there’s there’s two major issues that cause BLEU to either underestimate how good a translation is or overestimate how good a translation is.</p>
</blockquote>
<blockquote class="blockquote">
<p>BLEU tends to underestimate how good translations are when the translations are paraphrases of the true reference. So for example had I have like “I went I went to the store and bought a book yesterday” and you compare that with “yesterday I bought a book at the store” Those are almost identical in meaning But they would get a low BLEU square because I’ve just rearranged the phrases a little bit. So that’s when BLEU tends to underestimate scores.</p>
</blockquote>
<blockquote class="blockquote">
<p>BLEU tends to overestimate scores when you get very critical words in the sentence wrong but get everything else right</p>
</blockquote>
<p>for example</p>
<p>“could you please send this big package to philadelphia”</p>
<p>turns into:</p>
<p>“could you please send this big package to japan”</p>
<blockquote class="blockquote">
<p>That would get a very good BLEU score because most of the words are the same but your package would go to Japan and that’s probably not what you intended by that, otherwise right.</p>
</blockquote>
<blockquote class="blockquote">
<p>That’s the the downside of BLEU. It’s basically not smart enough with respect to these.</p>
</blockquote>
</section>
<section id="shortness-penalty" class="level2">
<h2 class="anchored" data-anchor-id="shortness-penalty">Shortness Penalty</h2>
<blockquote class="blockquote">
<p>Yhe brevity the brevity penalty basically gives you a penalty if your output is shorter than the intended output. If the reference is like 20 words then you’re and your sentence is 15 words you would get a penalty of about 0.75 It’s not exactly like just the ratio it actually drops off faster and stuff like that but that’s a basic idea. That’s a really good question so you pay a penalty in your precision your precision goes down by a lot because there’s no way to get good precision if you output too many things. One thing you should know about BLEU if you’re using it in your research which you might is that it’s very very sensitive to the length. So if your length is a little bit too short or a little bit too long it hurts your BLEU really badly. That’s another problem with BLEU essentially is that it’s not sensitive to paraphrases that are too long or too short as well.</p>
</blockquote>
</section>
<section id="bert-score" class="level2">
<h2 class="anchored" data-anchor-id="bert-score">Bert Score</h2>
<blockquote class="blockquote">
<p>Recently in the past three years or so, there’s been a huge improvement in embedding based metrics which are basically metrics that you know take advantage of recent NLP techniques and one of the first ones was bert score and these can be separated into unsupervised metrics and supervised metrics unsupervised metrics require no annotated data of whether a translation is a good translation or a bad translation supervised metrics are trained to basically regress to an estimation of how good a transplantation is or not so a Bert score is an unsupervised metric that’s based essentially on the similarity between burton betting so it has this matching algorithm where you basically for each word in the output you try to find you know how good it matches with one of the words in the input and this is good because it can do things like handle paraphrases as long as the paraphrases have similar bert embeddings another famous one is BLEUrt</p>
</blockquote>
</section>
<section id="bluert" class="level2">
<h2 class="anchored" data-anchor-id="bluert">BlueRT</h2>
<p>What they did essentially was they trained bert to predict human evaluation scores so they essentially solve a regression problem from the sentences like the reference in this system output to an evaluation score so they’re just going in directly predicting evaluation and they have a bunch of other tricks like unsupervised training where they try to predict BLEU or rouge or other lexical metrics beforehand and that makes it more robust the favorite one that we use in our Comet research on mt now is a comet and comet is also similarly it trains the model to predict human evaluation but in addition to using the just the system output in reference it also uses a source sentence which means that essentially I talked about human evaluation right where you can either ask a human evaluator to look only at the the reference or also look at the source and for a similar reason to why we would like a speaker human speaker to do that it’s also useful to have the model do that because the model can look at the source and see if the information is reflected in the target</p>
</section>
<section id="bart-score" class="level2">
<h2 class="anchored" data-anchor-id="bart-score">Bart Score</h2>
<p>and the final one prism’s another one based on paraphrasing a final one is a bart score environment score is one that I’m a co-author on this is a unsupervised metric that is based on basically a generative model that tries to generate the the system output using the reference or the reference using the system output or the source using the system output et cetera et cetera and bart score I think is good because it’s unsupervised like birth score but it’s essentially more accurate and more controllable so you can do things like calculate recall calculate a precision and other things like that so if that sounds interesting you can take a look at the paper as well but basically if you’re doing empty I would suggest using comment now because it’s well supported it has a nice package it’s pretty widely tested and follow-up reports have suggested that it has very good correlation with human evaluation so that’s my suggestion you can</p>
</section>
<section id="meta-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="meta-evaluation">Meta Evaluation</h2>
<p>Meta evaluation runs human evaluation and automatic evaluation on the same outputs and calculates the correlation this is what they do in the wmt shared tasks like the wmt metrics task for mt other things for summarization etc and one interesting thing is that evaluation as I mentioned at the beginning is pretty hard especially with good systems so most metrics actually had no correlation with human eval over a subset of the best systems at some of the wmt 2019 tasks which means that basically all of the evaluation metrics we had were kind of broken on like evaluating really good mt systems so fortunately now we have comment we have other things like this that actually seemed to be a lot more robust but it was a major problem so you basically calculate the correlation you calculate pearson’s correlation there’s experiments correlation and the way you do that is you human you do human eval of a whole bunch of sentences or humans develop a whole bunch of systems and you try to find the metric that has the highest correlation between the evaluation scores of the systems and the evaluations given by the humans yep all right they often don’t support that many languages well so that’s a good that’s a really good question I many of them do use something like embert or xlmr which support a lot of languages xlmr actually envert’s a little bit more biased xlmr has pretty good coverage of the most common languages in the world but of course as you go down to less well resource languages that’s going to continue to be a problem there you might be stuck with BLEU for now but honestly if you have really bad systems really bad empty systems I still think BLEU is probably good enough in many cases oh another option is carefu chrf and that’s a character-based evaluation metric for mt that’s particularly good for languages with like rich morphology or something like that so I think when you’re working with low resource languages your mnt systems are also going to be really bad so any metric you have is still going to be like reasonably good at measuring progress so</p>
</section>
<section id="database-strategies" class="level2">
<h2 class="anchored" data-anchor-id="database-strategies">Database Strategies</h2>
<p>The next thing I’d like to talk about is the database strategies to low resource mt there’s not a whole lot of content here so I’ll try to go through it rather quickly to leave time for the discussion but basically we have data challenges in the resource mt so mt of high resource languages with large parallel corpora gives us you know very good translations but low resource languages with small parallel corporate you just train there you can end up with nonsense so this is an example of a system trained on 5 000 languages and the most frequent failure state is basically that a neural nt system will just spit out something that has nothing to do with the original inputs there’s a famous example of this so that says why is google translate spitting out sinister religious prophecies and basically if you put in a dog dog dog dog dog in maori it outputs doomsday clock is three minutes at 12 we are experiencing characters in a dramatic development in which jesus returns [Music] can you guess why this happened exactly they use bible data in training their system and when you use bible data and training your system and your system doesn’t know what to do because it has so few resources or it sees something it doesn’t know it just reverts to using the language model and basically outputs whatever the language model thinks and thinks it looks likely and so you know if your system is trained on bible data that looks like the bible if your system’s trained on something else it looks like something else High and Low Resource Languages so you know that’s basically what happened here as well so some ways to fix this we can transfer from high resource languages to low resource languages so basically what you do is you train on a high resource language or multiple high resource languages and then you adapt to the low resource language one the simplest way to do that is just to continue fine tuning on the low resource language you can also do joint training with the low resource language in the high resource language so just concatenate all the data together and in training so this is okay but there are some problems with this as well one problem is a sub-optimal lexical or syntactic sharing and another problem is it’s not possible to leverage monolingual data because you still require a parallel data here and I’m going to be talking more about like lexical overlap and loanwords and stuff in in the next class so I’ll cover that more there but basically suffice to say the high resource language and the lower resource language are different so training on different data is sub-optimal for information sure</p>
</section>
<section id="data-augmentation" class="level2">
<h2 class="anchored" data-anchor-id="data-augmentation">Data Augmentation</h2>
<p>so if we think about data augmentation data augmentation is basically generating other data that looks like the data that you want to have the very convenient thing about this is generating more training data and feeding it into your existing system is easy but effective in in improving mt performance so it’s actually a pretty widely used technique now so if we look at the available resources we might have a low resource language parallel data a high resource language parallel data and also for example target data which is monolingual hence the m here and what we do is we would like to create augmented data where we have target data and like pseudo low resource language data and train our model on this with the idea being that if we can create this this will be closer to our final evaluation scenario where we where we want to generate the target given a low resource language</p>
</section>
<section id="back-translation" class="level2">
<h2 class="anchored" data-anchor-id="back-translation">Back Translation</h2>
<p>so the first example is a back translation and the way back translation works is basically we train a target two low resource language system and we take our monolingual target data and we generate fake low resource language data by translating the target data into the low resource language data so this is how it works we take our target to low resource language system we back translate using the system and then we train a low resource language to target language system using the concatenation of this augmented data in the original data and the key point here is that when we are when we’re training like a sequence sequence model or a machine translation model we’re we’re training it to do two things we’re training it to do language modeling on the target side only and we’re trying to do mapping between the source side and the target side and in order to do language modeling we only really need good target site data so even if there’s some degree of error in this like low resource language here we’ll still be able to learn target site data and we’ll be able to learn a the language model from target side data and we’ll be able to learn a mapping you know even if it’s imperfect from the low resource language to the target language</p>
</section>
<section id="training-schedule" class="level2">
<h2 class="anchored" data-anchor-id="training-schedule">Training Schedule</h2>
<p>so there’s a couple ways to generate translations when doing back translation the first one is using beam search oh sorry yeah yeah that’s a really that’s a really good question so the question was is there any sort of training schedule that you use when you do this so the the kind of quote-unquote obvious training schedule that you might do is you might train jointly on both of them at first and then fine-tune on this data over here and that would make sense because you know this is good data this is like actually translated data however there’s another issue which actually is not super obvious at first but it’s maybe obvious in hindsight which is that if this data is all from the bible and then you want to translate news then actually fine tuning on bible data will be really out of domain and cause issues for you so in fact in the original black translation paper they threw away this data and only trained on this because it was more in domain and that ended up giving better results but that was predicated on the fact that they have a good you know batch translation system in the first place so it’s not necessarily clear what the ideal schedule is but you would almost certainly benefit from some sort of schedule or balancing or something but that’s a complicated hyper parameter so because it’s a complicated hyper parameter it’s also very common to just concatenate the two and these are good details to know for assignment too by the way because they might make a difference in your final scores</p>
</section>
<section id="generating-translations" class="level2">
<h2 class="anchored" data-anchor-id="generating-translations">Generating Translations</h2>
<blockquote class="blockquote">
<p>How to generate translations?</p>
<p>Beam search is one way and basically what this is doing is selecting the highest scoring output. This was done in the original paper. This has the advantage of having higher quality but also lower diversity in the outputs and the potential for bias. You might like for example one result is beam search tends to mostly output pronouns from the majority gender because they’re over-represented. You might get only get male inflections if you do beam search. That’s the type of data bias that could result from here. The other option is sampling. What you do is you randomly sample from the back translation model which gives a lower overall quality but higher diversity. Most reports say this works better at the moment. We had a recent paper which I’m going to introduce in a second but this has kind of a theoretical explanation for why we think sampling should be better which is that it’s a better model of the underlying data distribution that we’re trying to model. I think I’m pretty firmly a believer that sampling is the way to go there’s also a method of iterative back translation.</p>
</blockquote>
</section>
<section id="iterative-back-translation." class="level2">
<h2 class="anchored" data-anchor-id="iterative-back-translation.">Iterative back translation.</h2>
<blockquote class="blockquote">
<p>Iterative back translation is particularly useful when you have a large monolingual data in both languages. Again the idea is simple you train a low resource language to target system first. This is going in the direction you originally want to translate. You generate pseudo data with the target language. You use that to train your target to low resource language system. You back translate and then you use this to train your final system so this is now you have three systems your forward translation data augmentation system your back translation data augmentation system and your forward translation final system you can do this as many times as you want obviously you could also do it on the fly in the process of training the system so this can become arbitrarily complicated if you want</p>
</blockquote>
</section>
<section id="metaback-translation" class="level2">
<h2 class="anchored" data-anchor-id="metaback-translation">Metaback translation</h2>
<p>just one example of this this is a paper that I just talked about but we have a paper called meta back translation which I think is kind of a an interesting idea so normally when we’re training this system to train the the low resource language to the target language system we’re back propping the gradient from the slow resource language data but we can also do a back propagation step where we basically train oh sorry that arrow is thrown I apologize so the arrow actually should be going from here around this to here so the basic idea I’ll fix this later in the slides but the basic idea is we use the signal that we get from from training the final system that we want to train to update the parameters of the back translation system so we’re essentially training the ideal back translation system to train a good forward translation system so this is a I like the idea behind here which is basically the final goal of the back translation system is to improve the forward translation system so we can directly optimize it to do this</p>
</section>
<section id="metaback-translation-issues" class="level2">
<h2 class="anchored" data-anchor-id="metaback-translation-issues">Metaback translation issues</h2>
<p>so there are a couple issues here the first issue is that back translation often fails in low resource languages or domains and as a solution one thing that we can do is we can use other high resource languages or we can combine them with monolingual data maybe with denoising objectives which we’re covering in a following class and we can perform other varieties of rule-based augmentation so I’m gonna go through these in a little bit in maybe in a few minutes so also actually we’ll have discussion about about these two so maybe I’ll just briefly explain the idea and we can discuss more in the discussion for people who read those papers so using high resource languages High resource languages augmentation and augmentation the problem is target to low resource language back translation might be very low quality so the idea is we can also use a high resource language that’s similar to the low resource language and basically for example if we have something like azerbaijani in turkish azerbaijani and turkish are very highly related so maybe we could use information from azerbaijani to english translation back translate into az into turkish which is certainly going to give us higher quality data and use that to augment our data for azerbaijani english system and then we can just throw away this azerbaijani data that we know is not going to be very useful so that would High resource languages pivoting give us additional high resource language to target language data and another thing we can do is we can augment via pivoting and so basically what that does is that gives us data where we take the high resource language data and we translate that into the low resource language and presumably translation from the high resource language to low resource language is easier because these languages are more related so basically what this does is that gives us a better like low resource language pseudo data here and we can also do a similar thing where we generate more high resource language data and this basically gives us three different ways to create this pseudo-parallel data between the low resource language and target language another simple trick this is kind of</p>
</section>
<section id="monolingual-data-copying" class="level2">
<h2 class="anchored" data-anchor-id="monolingual-data-copying">Monolingual data copying</h2>
<p>like frustratingly effective at improving your models is monolingual data copying and the issue is that back translation may help with structure but one of the issues with the resource language systems is that they tend to fail really badly on unusual vocabulary so like for example proper names or something like this so you might get a back translation system that’s very good at getting the structure right but get it gets you know all of your proper names and entities incorrect so basically one thing that you can do here is you just copy the target data into the source data and then you’re done and this kind of guarantees to maintain the entities so or the the rare words so that will help mitigate these issues of like vocabulary being dropped yeah something to point out with copying is that even in languages with different scripts it seems to work really well. &gt; Maybe because of auto and clutter objective stuff yeah even in languages with different scripts</p>
</section>
<section id="transfer-learning" class="level2">
<h2 class="anchored" data-anchor-id="transfer-learning">Transfer learning</h2>
<blockquote class="blockquote">
<p>There’s actually a nice paper by the same authors who wrote this paper where they examine this. Basically they are trying to figure out <strong>transfer learning</strong>. Why does transfer learning have this positive effect? One of the things that they <mark>show is that even making sure the length is the same or approximately the same or making sure that the words are output in approximately the same order as the input is is effective for improving translation accuracy.</mark> If you have a low resource language the translation system might drop half the content or it might like totally mess up the order or something like this This paper is demonstrating that kind of just like a monotonic bias and a bias towards outputting approximately the same number of words gets you a long way in improving the results which of course monolingual data copying would also do</p>
</blockquote>
</section>
<section id="dictionary-based-augmentation" class="level2">
<h2 class="anchored" data-anchor-id="dictionary-based-augmentation">Dictionary based augmentation</h2>
<blockquote class="blockquote">
<p>So for the final things which we’re also reading so we can talk more about them in the discussion. We had dictionary based augmentation and dictionary based augmentation basically finds rare words in the source sentences it could also be in the target sentence and tries to replace the words with other words that are kind of in the same semantic class. It replaces car with motorbike and then using a lexicon. It replaces the words in the targeted sentence as well. It’s basically creating more sentences to augment augmented data with like words that are less frequent in the original</p>
</blockquote>
</section>
<section id="word-alignment" class="level2">
<h2 class="anchored" data-anchor-id="word-alignment">Word alignment</h2>
<blockquote class="blockquote">
<p>In order to do this they need to use a tool called word alignment What Word alignment does is, it essentially takes in two parallel corpora. The parallel corpora you want to find which words align to each other in the source and target sentences. This is useful for a number of reasons it’s useful for analysis it’s useful for cross-lingual transfer learning I talked about supervised alignment as a training method last time I believe and there’s a couple methods to do so there’s again traditional symbolic methods which like BLEU are based on exact lexical match or you know some variety of clustering</p>
</blockquote>
<p>giza ++ has some clustering involved in it but recently neural methods have been largely outperforming these and I can recommend a highly our aligner called awesome lion I i didn’t name it I’m far too humble to name my alignment or awesome line but but it’s pretty awesome I have to say and basically it uses multilingual perks and it tries to find things that are similar but it’s also fine-tuned multilingually on supervised data so basically there’s some supervision that goes into it to try to inform the aligner about the outputs and it works on any language that’s included in mvert again like the question before it won’t work on very low resource languages of course so then you might be stuck with keystone plus plus and faster Word by word data augmentation so you can also do things like word by word data augmentation where you simply translate sentences word by word into the target sentence using a dictionary this is another frustratingly you know effective method like monolingual data copying however there are problems like word order and syntactic divergence so if you get like I the new car bought number one the order is strange number two these words don’t actually align with each other so that’s a problem so Reordering other things you can do or you can try to decrease this divergence with reordering or rules so this was also another paper in the potential reading and basically what the idea is that you a priori do some reordering from one language from english into like reordered english and then do data augmentation on top of that and the good thing about this is like english has a lot of analysis tools you could like do syntactic parsing of english get the syntactic structure build reordering rules on top of that and then just apply dictionary-based translation and then the hope would be that you would get something that looks a lot more like japanese than if you just translated english word by word and one interesting thing we showed here was we demonstrated that this was useful for japanese translation but then we applied the exact same reordering rules and also applied it to wigger which is another language that’s completely different different language family but it’s it has a very similar syntax to japanese so because of that the exact same reordering rules for english were still effective in improving the results for weaker english translations so because of that you know it’s not language dependent it’s rather syntax dependent and because there’s syntactic similarities between the language it helps so yeah given that we now have the</p>
</section>
<section id="assignment" class="level2">
<h2 class="anchored" data-anchor-id="assignment">Assignment</h2>
<p>assignment actually this is this slide is missing one of the one of the papers that was a potential paper to read so first before we go to the discussion are there any questions so I kind of breezed through it the last part quickly but hopefully we can also talk about them in the discussion okay if not this time we’re going to try a new experiment we’re going to try to make six groups so the groups are going to be half the size and they’re going to be front middle front right front left back middle back left back middle in that right so we’re gonna ask everybody to talk a little bit more quietly but also you’ll be in a smaller circle so hopefully that’ll be easier and yeah let’s go ahead and actually guys since we’re running a little bit late I think maybe we’ll skip the reporting part this time is that okay and we’ll just you know be within our groups and if there’s anything really interesting we can share on piazza or something okay</p>
</section>
</div>
</div>
</div>
<section id="papers" class="level2">
<h2 class="anchored" data-anchor-id="papers">Papers:</h2>
<ul>
<li><span class="citation" data-cites="xia-etal-2019-generalized">Xia et al. (<a href="#ref-xia-etal-2019-generalized" role="doc-biblioref">2019</a>)</span> <a href="https://aclanthology.org/P19-1579/">Generalized data augmentation for low-resource translation</a>.</li>
<li>Transfer HRL to LRL
<ul>
<li><span class="citation" data-cites="zoph-etal-2016-transfer">Zoph et al. (<a href="#ref-zoph-etal-2016-transfer" role="doc-biblioref">2016</a>)</span> <a href="https://aclanthology.org/D16-1163/">Transfer Learning for Low-Resource Neural Machine Translation</a><br>
</li>
<li><span class="citation" data-cites="nguyen-chiang-2017-transfer">Nguyen and Chiang (<a href="#ref-nguyen-chiang-2017-transfer" role="doc-biblioref">2017</a>)</span> <a href="https://aclanthology.org/I17-2050/">Transfer Learning across Low-Resource, Related Languages for Neural Machine Translation</a></li>
</ul></li>
<li>Joint training with LRL and HRL parallel data
<ul>
<li><span class="citation" data-cites="johnson-etal-2017-googles">Johnson et al. (<a href="#ref-johnson-etal-2017-googles" role="doc-biblioref">2017</a>)</span> <a href="https://aclanthology.org/Q17-1024/">Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation</a></li>
<li><span class="citation" data-cites="neubig-hu-2018-rapid">Neubig and Hu (<a href="#ref-neubig-hu-2018-rapid" role="doc-biblioref">2018</a>)</span> <a href="https://aclanthology.org/D18-1103/">Rapid Adaptation of Neural Machine Translation to New Languages</a></li>
</ul></li>
<li>Back Translation
<ul>
<li><span class="citation" data-cites="sennrich-etal-2016-improving">Sennrich, Haddow, and Birch (<a href="#ref-sennrich-etal-2016-improving" role="doc-biblioref">2016</a>)</span> <a href="https://aclanthology.org/P16-1009.pdf">Improving neural machine translation models with monolingual data</a>.</li>
<li><span class="citation" data-cites="edunov-etal-2018-understanding">Edunov et al. (<a href="#ref-edunov-etal-2018-understanding" role="doc-biblioref">2018</a>)</span> <a href="https://aclanthology.org/D18-1045.pdf">Understanding Back-Translation at Scale</a></li>
<li><span class="citation" data-cites="pham2021metabacktranslation">Pham et al. (<a href="#ref-pham2021metabacktranslation" role="doc-biblioref">2021</a>)</span> <a href="https://arxiv.org/abs/2102.07847">Meta Back-translation</a></li>
</ul></li>
<li><span class="citation" data-cites="currey-etal-2017-copied">Currey, Miceli Barone, and Heafield (<a href="#ref-currey-etal-2017-copied" role="doc-biblioref">2017</a>)</span> <a href="https://aclanthology.org/W17-4715/">Copied Monolingual Data Improves Low-Resource Neural Machine Translation</a></li>
<li><span class="citation" data-cites="fadaee-etal-2017-data">Fadaee, Bisazza, and Monz (<a href="#ref-fadaee-etal-2017-data" role="doc-biblioref">2017</a>)</span> <a href="https://aclanthology.org/P17-2090/">Data Augmentation for Low-Resource Neural Machine Translation</a></li>
<li>Word-by-word Data Augmentation
<ul>
<li><span class="citation" data-cites="lample2018unsupervisedmachinetranslationusing">Lample et al. (<a href="#ref-lample2018unsupervisedmachinetranslationusing" role="doc-biblioref">2018</a>)</span> <a href="https://arxiv.org/abs/1711.00043">Unsupervised Machine Translation Using Monolingual Corpora Only</a></li>
</ul></li>
<li>Word-by-word Augmentation w/ Reordering
<ul>
<li><span class="citation" data-cites="zhou2019handlingsyntacticdivergencelowresource">Zhou et al. (<a href="#ref-zhou2019handlingsyntacticdivergencelowresource" role="doc-biblioref">2019</a>)</span> <a href="https://arxiv.org/abs/1909.00040">Handling Syntactic Divergence in Low-resource Machine Translation</a></li>
</ul></li>
</ul>
</section>
<section id="in-class-assignment" class="level2">
<h2 class="anchored" data-anchor-id="in-class-assignment">In-class Assignment</h2>
<p>Read one of the cited papers on heuristic data augmentation - <span class="citation" data-cites="fadaee-etal-2017-data">Fadaee, Bisazza, and Monz (<a href="#ref-fadaee-etal-2017-data" role="doc-biblioref">2017</a>)</span> or - <span class="citation" data-cites="zhou2019handlingsyntacticdivergencelowresource">Zhou et al. (<a href="#ref-zhou2019handlingsyntacticdivergencelowresource" role="doc-biblioref">2019</a>)</span></p>
<ul>
<li>Try to think of how it would work for one of the languages you’re familiar with</li>
<li>Are there any potential hurdles to applying such a method? Are there any improvements you can think of?</li>
</ul>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<ul>
<li><a href="https://github.com/moses-smt/giza-pp">GizA++</a></li>
<li><a href="https://github.com/moses-smt/mgiza">mgiza</a></li>
<li><a href="https://github.com/clab/fast_align">Fast Align</a></li>
<li><a href="https://github.com/neulab/awesome-align">awesome-align</a> (<span class="citation" data-cites="dou2021wordalignmentfinetuningembeddings">Dou and Neubig (<a href="#ref-dou2021wordalignmentfinetuningembeddings" role="doc-biblioref">2021</a>)</span>)</li>
</ul>
<pre><code>doch jetzt ist der Held gefallen . ||| but now the hero has fallen .
neue Modelle werden erprobt . ||| new models are being tested .
doch fehlen uns neue Ressourcen . ||| but we lack new resources .</code></pre>
<pre><code>0-0 1-1 2-4 3-2 4-3 5-5 6-6
0-0 1-1 2-2 2-3 3-4 4-5
0-0 1-2 2-1 3-3 4-4 5-5</code></pre>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-currey-etal-2017-copied" class="csl-entry" role="listitem">
Currey, Anna, Antonio Valerio Miceli Barone, and Kenneth Heafield. 2017. <span>“Copied Monolingual Data Improves Low-Resource Neural Machine Translation.”</span> In <em>Proceedings of the Second Conference on Machine Translation</em>, edited by Ondřej Bojar, Christian Buck, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes, Philipp Koehn, and Julia Kreutzer, 148–56. Copenhagen, Denmark: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/W17-4715">https://doi.org/10.18653/v1/W17-4715</a>.
</div>
<div id="ref-dou2021wordalignmentfinetuningembeddings" class="csl-entry" role="listitem">
Dou, Zi-Yi, and Graham Neubig. 2021. <span>“Word Alignment by Fine-Tuning Embeddings on Parallel Corpora.”</span> <a href="https://arxiv.org/abs/2101.08231">https://arxiv.org/abs/2101.08231</a>.
</div>
<div id="ref-edunov-etal-2018-understanding" class="csl-entry" role="listitem">
Edunov, Sergey, Myle Ott, Michael Auli, and David Grangier. 2018. <span>“Understanding Back-Translation at Scale.”</span> In <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, edited by Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun’ichi Tsujii, 489–500. Brussels, Belgium: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/D18-1045">https://doi.org/10.18653/v1/D18-1045</a>.
</div>
<div id="ref-fadaee-etal-2017-data" class="csl-entry" role="listitem">
Fadaee, Marzieh, Arianna Bisazza, and Christof Monz. 2017. <span>“Data Augmentation for Low-Resource Neural Machine Translation.”</span> In <em>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, edited by Regina Barzilay and Min-Yen Kan, 567–73. Vancouver, Canada: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P17-2090">https://doi.org/10.18653/v1/P17-2090</a>.
</div>
<div id="ref-johnson-etal-2017-googles" class="csl-entry" role="listitem">
Johnson, Melvin, Mike Schuster, Quoc V. Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, et al. 2017. <span>“<span>G</span>oogle‘s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation.”</span> Edited by Lillian Lee, Mark Johnson, and Kristina Toutanova. <em>Transactions of the Association for Computational Linguistics</em> 5: 339–51. <a href="https://doi.org/10.1162/tacl_a_00065">https://doi.org/10.1162/tacl_a_00065</a>.
</div>
<div id="ref-lample2018unsupervisedmachinetranslationusing" class="csl-entry" role="listitem">
Lample, Guillaume, Alexis Conneau, Ludovic Denoyer, and Marc’Aurelio Ranzato. 2018. <span>“Unsupervised Machine Translation Using Monolingual Corpora Only.”</span> <a href="https://arxiv.org/abs/1711.00043">https://arxiv.org/abs/1711.00043</a>.
</div>
<div id="ref-neubig-hu-2018-rapid" class="csl-entry" role="listitem">
Neubig, Graham, and Junjie Hu. 2018. <span>“Rapid Adaptation of Neural Machine Translation to New Languages.”</span> In <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, edited by Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun’ichi Tsujii, 875–80. Brussels, Belgium: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/D18-1103">https://doi.org/10.18653/v1/D18-1103</a>.
</div>
<div id="ref-nguyen-chiang-2017-transfer" class="csl-entry" role="listitem">
Nguyen, Toan Q., and David Chiang. 2017. <span>“Transfer Learning Across Low-Resource, Related Languages for Neural Machine Translation.”</span> In <em>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</em>, edited by Greg Kondrak and Taro Watanabe, 296–301. Taipei, Taiwan: Asian Federation of Natural Language Processing. <a href="https://aclanthology.org/I17-2050/">https://aclanthology.org/I17-2050/</a>.
</div>
<div id="ref-pham2021metabacktranslation" class="csl-entry" role="listitem">
Pham, Hieu, Xinyi Wang, Yiming Yang, and Graham Neubig. 2021. <span>“Meta Back-Translation.”</span> <a href="https://arxiv.org/abs/2102.07847">https://arxiv.org/abs/2102.07847</a>.
</div>
<div id="ref-sennrich-etal-2016-improving" class="csl-entry" role="listitem">
Sennrich, Rico, Barry Haddow, and Alexandra Birch. 2016. <span>“Improving Neural Machine Translation Models with Monolingual Data.”</span> In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, edited by Katrin Erk and Noah A. Smith, 86–96. Berlin, Germany: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P16-1009">https://doi.org/10.18653/v1/P16-1009</a>.
</div>
<div id="ref-xia-etal-2019-generalized" class="csl-entry" role="listitem">
Xia, Mengzhou, Xiang Kong, Antonios Anastasopoulos, and Graham Neubig. 2019. <span>“Generalized Data Augmentation for Low-Resource Translation.”</span> In <em>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, edited by Anna Korhonen, David Traum, and Lluís Màrquez, 5786–96. Florence, Italy: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P19-1579">https://doi.org/10.18653/v1/P19-1579</a>.
</div>
<div id="ref-zhou2019handlingsyntacticdivergencelowresource" class="csl-entry" role="listitem">
Zhou, Chunting, Xuezhe Ma, Junjie Hu, and Graham Neubig. 2019. <span>“Handling Syntactic Divergence in Low-Resource Machine Translation.”</span> <a href="https://arxiv.org/abs/1909.00040">https://arxiv.org/abs/1909.00040</a>.
</div>
<div id="ref-zoph-etal-2016-transfer" class="csl-entry" role="listitem">
Zoph, Barret, Deniz Yuret, Jonathan May, and Kevin Knight. 2016. <span>“Transfer Learning for Low-Resource Neural Machine Translation.”</span> In <em>Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</em>, edited by Jian Su, Kevin Duh, and Xavier Carreras, 1568–75. Austin, Texas: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/D16-1163">https://doi.org/10.18653/v1/D16-1163</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2022,
  author = {Bochman, Oren},
  title = {Data-Driven {Strategies} for {NMT}},
  date = {2022-02-03},
  url = {https://orenbochman.github.io/notes-nlp/notes/cs11-737-w07-data-driven-NMT/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2022" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2022. <span>“Data-Driven Strategies for NMT.”</span>
February 3, 2022. <a href="https://orenbochman.github.io/notes-nlp/notes/cs11-737-w07-data-driven-NMT/">https://orenbochman.github.io/notes-nlp/notes/cs11-737-w07-data-driven-NMT/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2023-2025, Oren Bochman</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/notes/cs11-737-w07-data-driven-NMT/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 💛 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>videojs(video_shortcode_videojs_video1);</script>
<script>videojs(video_shortcode_videojs_video2);</script>
<script>videojs(video_shortcode_videojs_video3);</script>
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"right","loop":true,"openEffect":"fade","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>