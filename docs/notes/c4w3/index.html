<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oren Bochman">
<meta name="keywords" content="BERT, Causal attention, Dot product attention, Multi-head attention, Self attention, Transformer decoder, T5">
<meta name="description" content="This week we will dive into Neural Question Answering. We will build advanced models like T5 and BERT to accurately answer questions based on given contexts. We will fine-tune these models to optimize their performance. We will gain practical experience in building question-answering systems.">

<title>Question Answering – NLP Specialization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-d166b450ba5a8e9f7a0ab969bf6592c1.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1372234da3246ce8e868649689ba5ed0.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-d99a2a2a191b5c7f2a9a83135e7f0803.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<style>

      .quarto-title-block .quarto-title-banner {
        background: images/banner_deep.jpg;
      }
</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">NLP Specialization</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">NLP with Attention Models</li><li class="breadcrumb-item"><a href="../../notes/c4w3/index.html">Question Answering</a></li><li class="breadcrumb-item"><a href="../../notes/c4w3/index.html">Notes</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">NLP with Attention Models</li><li class="breadcrumb-item"><a href="../../notes/c4w3/index.html">Question Answering</a></li><li class="breadcrumb-item"><a href="../../notes/c4w3/index.html">Notes</a></li></ol></nav>
      <h1 class="title">Question Answering</h1>
            <p class="subtitle lead">NLP with Attention Models</p>
                  <div>
        <div class="description">
          This week we will dive into Neural Question Answering. We will build advanced models like T5 and BERT to accurately answer questions based on given contexts. We will fine-tune these models to optimize their performance. We will gain practical experience in building question-answering systems.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Attention</div>
                <div class="quarto-category">Coursera</div>
                <div class="quarto-category">Deep Learning Algorithms</div>
                <div class="quarto-category">NLP</div>
                <div class="quarto-category">Notes</div>
                <div class="quarto-category">NLP with Attention Models</div>
                <div class="quarto-category">Neural Machine Translation</div>
                <div class="quarto-category">Transformer</div>
                <div class="quarto-category">Teacher forcing</div>
                <div class="quarto-category">Positional encoding</div>
                <div class="quarto-category">Question answering task</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-body">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Oren Bochman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Saturday, April 10, 2021</p>
      </div>
    </div>
    
      
    </div>
    

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>BERT, Causal attention, Dot product attention, Multi-head attention, Self attention, Transformer decoder, T5</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Classification &amp; Vector Spaces</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Logistic Regression</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Frequencies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w1/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Visualizing tweets</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Probability &amp; Bayes Rule</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Visualizing Naive Bayes</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Vector Space Models &amp; PCA</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Linear algebra with NumPy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Manipulating word embeddings</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">MT &amp; Document Search via KNN</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vector manipulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c1w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Hash functions and multiplanes</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Probabilistic Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Autocorrect &amp; Dynamic Programming</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Building the vocabulary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Candidates from String Edits</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">POS tagging &amp; HMMS</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vocabulary with unknowns</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Working with tags and Numpy</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Autocomplete &amp; Language Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - N-grams Corpus preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Building the language model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w3/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Out of vocabulary words</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Word embeddings with neural networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Data preparation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Intro to CBOW</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c2w4/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Training the CBOW</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequence Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Neural Networks for Sentiment Analysis</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Introduction to Trax</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Classes and Subclasses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w1/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Data Generators</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">RNN for Language Modeling</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Hidden State Activation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Calculating Perplexity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Vanilla RNNs, GRUs and the scan function</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w2/lab04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L4 - Creating a GRU model using Trax</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false">
 <span class="menu-text">LSTMs and Named Entity Recognition</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w3/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Vanishing Gradients</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false">
 <span class="menu-text">Siamese Networks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Creating a Siamese Model using Trax</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Modified Triplet Loss</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c3w4/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - Evaluate a Siamese Model</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true">
 <span class="menu-text">NLP with Attention Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false">
 <span class="menu-text">Neural Machine Translation</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-17" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Stack Semantics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w1/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - BLEU Score</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false">
 <span class="menu-text">Text Summarization</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-18" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Attention</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w2/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - The Transformer Decoder</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="true">
 <span class="menu-text">Question Answering</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-19" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - SentencePiece and BPE</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - BERT Loss</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w3/lab03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L3 - T5</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false">
 <span class="menu-text">Chat Bots</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-20" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/lab01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L1 - Reformer LSH</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/c4w4/lab02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L2 - Revnet</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-question-answering" id="toc-sec-question-answering" class="nav-link active" data-scroll-target="#sec-question-answering">Question Answering</a></li>
  <li><a href="#sec-overview" id="toc-sec-overview" class="nav-link" data-scroll-target="#sec-overview">Overview</a></li>
  <li><a href="#sec-video2-transfer-learning-nlp" id="toc-sec-video2-transfer-learning-nlp" class="nav-link" data-scroll-target="#sec-video2-transfer-learning-nlp">Transfer Learning in NLP</a></li>
  <li><a href="#sec-video3-elmo-gpt-bert-t5" id="toc-sec-video3-elmo-gpt-bert-t5" class="nav-link" data-scroll-target="#sec-video3-elmo-gpt-bert-t5">ELMo, GPT, BERT, T5</a></li>
  <li><a href="#cbow" id="toc-cbow" class="nav-link" data-scroll-target="#cbow">CBOW</a></li>
  <li><a href="#sec-video4-bert" id="toc-sec-video4-bert" class="nav-link" data-scroll-target="#sec-video4-bert">BERT Bidirectional Encoder Representations from Transformers</a></li>
  <li><a href="#sec-video5-bert-objective" id="toc-sec-video5-bert-objective" class="nav-link" data-scroll-target="#sec-video5-bert-objective">BERT Objective</a></li>
  <li><a href="#sec-video6-fine-tuning-bert" id="toc-sec-video6-fine-tuning-bert" class="nav-link" data-scroll-target="#sec-video6-fine-tuning-bert">Fine tuning BERT</a></li>
  <li><a href="#transformer-t5" id="toc-transformer-t5" class="nav-link" data-scroll-target="#transformer-t5">Transformer: T5</a></li>
  <li><a href="#sec-video8-multi-task-training-strategy" id="toc-sec-video8-multi-task-training-strategy" class="nav-link" data-scroll-target="#sec-video8-multi-task-training-strategy">Lecture Multi-Task Training Strategy</a>
  <ul class="collapse">
  <li><a href="#sec-training-data-strategies" id="toc-sec-training-data-strategies" class="nav-link" data-scroll-target="#sec-training-data-strategies">Training data strategies</a></li>
  </ul></li>
  <li><a href="#sec-video9-glue-benchmark" id="toc-sec-video9-glue-benchmark" class="nav-link" data-scroll-target="#sec-video9-glue-benchmark">GLUE Benchmark</a></li>
  <li><a href="#sec-video10-question-answering" id="toc-sec-video10-question-answering" class="nav-link" data-scroll-target="#sec-video10-question-answering">Question Answering</a></li>
  <li><a href="#sec-programming-assignment-question-answering" id="toc-sec-programming-assignment-question-answering" class="nav-link" data-scroll-target="#sec-programming-assignment-question-answering">Programming Assignment: Question Answering</a></li>
  <li><a href="#sec-lab-sentencepiece-and-bpe" id="toc-sec-lab-sentencepiece-and-bpe" class="nav-link" data-scroll-target="#sec-lab-sentencepiece-and-bpe">Lab: SentencePiece and BPE</a>
  <ul class="collapse">
  <li><a href="#sec-nfkc-normalization" id="toc-sec-nfkc-normalization" class="nav-link" data-scroll-target="#sec-nfkc-normalization">NFKC Normalization</a></li>
  </ul></li>
  <li><a href="#lossless-tokenization" id="toc-lossless-tokenization" class="nav-link" data-scroll-target="#lossless-tokenization">lossless tokenization</a>
  <ul class="collapse">
  <li><a href="#sec-sentencepiece" id="toc-sec-sentencepiece" class="nav-link" data-scroll-target="#sec-sentencepiece">SentencePiece</a></li>
  <li><a href="#sec-bpe" id="toc-sec-bpe" class="nav-link" data-scroll-target="#sec-bpe">BPE</a></li>
  </ul></li>
  <li><a href="#sec-lab-bert-loss" id="toc-sec-lab-bert-loss" class="nav-link" data-scroll-target="#sec-lab-bert-loss">Lab: BERT Loss</a></li>
  <li><a href="#sec-lab-t5" id="toc-sec-lab-t5" class="nav-link" data-scroll-target="#sec-lab-t5">Lab: T5</a></li>
  <li><a href="#representation.-pdf-bib" id="toc-representation.-pdf-bib" class="nav-link" data-scroll-target="#representation.-pdf-bib">Representation. [pdf] [bib]</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References:</a>
  <ul class="collapse">
  <li><a href="#tokenization" id="toc-tokenization" class="nav-link" data-scroll-target="#tokenization">Tokenization</a></li>
  <li><a href="#transformers" id="toc-transformers" class="nav-link" data-scroll-target="#transformers">Transformers</a>
  <ul class="collapse">
  <li><a href="#question-answering-task" id="toc-question-answering-task" class="nav-link" data-scroll-target="#question-answering-task">Question Answering Task:</a></li>
  </ul></li>
  <li><a href="#links" id="toc-links" class="nav-link" data-scroll-target="#links">Links</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/notes/c4w3/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full column-body" id="quarto-document-content">






<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../images/Course-Logo-4-1.webp" class="nolightbox img-fluid figure-img"></p>
<figcaption>course banner</figcaption>
</figure>
</div></div><section id="sec-question-answering" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-question-answering">Question Answering</h2>

<div class="no-row-height column-margin column-container"><div id="sup-slide-deck" class="quarto-float quarto-figure quarto-figure-center anchored" data-group="slides" style="@page {size: 16in 9in;  margin: 0;}">
<figure class="quarto-float quarto-float-sup figure">
<div aria-describedby="sup-slide-deck-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="slides.pdf" class="lightbox" data-gallery="slides" title="This week’s slides"><embed src="slides.pdf" style="@page {size: 16in 9in;  margin: 0;}" width="420" height="340"></a></p>
<figcaption>This week’s slides</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-sup quarto-uncaptioned" id="sup-slide-deck-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Supplementary Figure&nbsp;1
</figcaption>
</figure>
</div></div><p>My notes for Week 3 of the <a href="https://www.coursera.org/learn/attention-models-in-nlp/home/info">Natural Language Processing with Attention Labels</a> Course in the Natural Language Processing Specialization Offered by <a href="DeepLearning.AI">DeepLearning.AI</a> on <a href="https://www.coursera.org/">Coursera</a></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives:
</div>
</div>
<div class="callout-body-container callout-body">
<ul class="task-list">
<li><label><input type="checkbox" checked=""><span id="sec-video2-transfer-learning-nlp">Gain intuition for how transfer learning works in the context of NLP</span></label></li>
<li><label><input type="checkbox" checked=""><span id="sec-video2-transfer-learning-nlp">Identify two approaches to transfer learning</span></label></li>
<li><label><input type="checkbox" checked=""><span id="sec-video3-elmo-gpt-bert-t5">Discuss the evolution of language models from CBOW to T5 and Bert</span></label></li>
<li><label><input type="checkbox" checked=""><span id="sec-video4-bert">Fine-tune BERT on a dataset</span></label></li>
<li><label><input type="checkbox" checked=""><span id="sec-video7-transformer-t5">Implement context-based question answering with T5</span></label></li>
<li><label><input type="checkbox" checked=""><span id="sec-video9-glue-benchmark">Interpret the GLUE benchmark</span></label></li>
</ul>
</div>
</div>
</section>
<section id="sec-overview" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-overview">Overview</h2>
<div class="page-columns page-full"><p> In this week we are going to learn about <strong>transfer learning</strong>. More specifically we will understand how <strong>T5</strong> and <strong>BERT</strong> actually work.</p><div class="no-row-height column-margin column-container"><img src="img/V1-001-week-3.png" class="img-fluid" data-group="slides" alt="week-3"></div></div>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V1-002-question-answering.png" class="lightbox" data-gallery="slides" title="question-answering"><img src="img/V1-002-question-answering.png" class="img-fluid figure-img" alt="question-answering"></a></p>
<figcaption>question-answering</figcaption>
</figure>
</div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definitions:
</div>
</div>
<div class="callout-body-container callout-body">
<p>Q&amp;A comes in two forms:</p>
<p>context based : given a document and a question the model extracts an answer or generates an answer</p>
<p>closed book : the model picks an answer from several options (classifier)</p>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V1-003-tl.png" class="lightbox" data-gallery="slides" title="tl"><img src="img/V1-003-tl.png" class="img-fluid figure-img" alt="tl"></a></p>
<figcaption>tl</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V1-004-classical-training.png" class="lightbox" data-gallery="slides" title="classical-training"><img src="img/V1-004-classical-training.png" class="img-fluid figure-img" alt="classical-training"></a></p>
<figcaption>classical-training</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V1-005-transfer-learning.png" class="lightbox" data-gallery="slides" title="transfer-learning"><img src="img/V1-005-transfer-learning.png" class="img-fluid figure-img" alt="transfer-learning"></a></p>
<figcaption>transfer-learning</figcaption>
</figure>
</div></div>

<div class="page-columns page-full"><p> We can see how a model initially trained on some type of sentiment classification, could now be used for question answering. One other model that has state of the art makes use of multi tasking. For example, the same model could be used for sentiment analysis, question answering, and many other things.</p><div class="no-row-height column-margin column-container"><img src="img/V1-006-transfer-learning-tasks.png" class="img-fluid" data-group="slides" alt="transfer-learning-tasks"></div></div>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V1-007-goals.png" class="lightbox" data-gallery="slides" title="goals"><img src="img/V1-007-goals.png" class="img-fluid figure-img" alt="goals"></a></p>
<figcaption>goals</figcaption>
</figure>
</div></div><p>These new types of models make use of a lot of data. For example the C4 (colossal cleaned crawled corpus) is about 800 GB when all of the english wikipedia is just 13 GB!</p>
<blockquote class="blockquote">
<p>C4 is a colossal, cleaned version of Common Crawl’s web crawl corpus. It was based on <a href="https://commoncrawl.org">Common Crawl dataset</a>. It was used to train the T5 text-to-text Transformer models. Introduced by <span class="citation" data-cites="raffel2023exploringlimitstransferlearning">Raffel et al. (<a href="#ref-raffel2023exploringlimitstransferlearning" role="doc-biblioref">2023</a>)</span> in a paper titled “Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer” The dataset can be downloaded in a pre-processed form from <a href="https://github.com/allenai/allennlp/discussions/5056">allennlp</a>. <a href="https://paperswithcode.com/dataset/c4">C4 at papers with code</a></p>
</blockquote>
</section>
<section id="sec-video2-transfer-learning-nlp" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-video2-transfer-learning-nlp">Transfer Learning in NLP</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-010-transfer-learning-options.png" class="lightbox" data-gallery="slides" title="transfer-learning-options"><img src="img/V2-010-transfer-learning-options.png" class="img-fluid figure-img" alt="transfer-learning-options"></a></p>
<figcaption>transfer-learning-options</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-011-tl-general-purpose.png" class="lightbox" data-gallery="slides" title="tl-general-purpose"><img src="img/V2-011-tl-general-purpose.png" class="img-fluid figure-img" alt="tl-general-purpose"></a></p>
<figcaption>tl-general-purpose</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-012-tl-features-vs-fine-tuning.png" class="lightbox" data-gallery="slides" title="tl-features-vs-fine-tuning"><img src="img/V2-012-tl-features-vs-fine-tuning.png" class="img-fluid figure-img" alt="tl-features-vs-fine-tuning"></a></p>
<figcaption>tl-features-vs-fine-tuning</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-013-tl-fine-tuning.png" class="lightbox" data-gallery="slides" title="tl-fine-tuning"><img src="img/V2-013-tl-fine-tuning.png" class="img-fluid figure-img" alt="tl-fine-tuning"></a></p>
<figcaption>tl-fine-tuning</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-014-tl-pretain-data-performance.png" class="lightbox" data-gallery="slides" title="tl-pretain-data-performance"><img src="img/V2-014-tl-pretain-data-performance.png" class="img-fluid figure-img" alt="tl-pretain-data-performance"></a></p>
<figcaption>tl-pretain-data-performance</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-015-tl-pretain-data-supervision.png" class="lightbox" data-gallery="slides" title="tl-pretain-data-supervision"><img src="img/V2-015-tl-pretain-data-supervision.png" class="img-fluid figure-img" alt="tl-pretain-data-supervision"></a></p>
<figcaption>tl-pretain-data-supervision</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-016-tl-pretain-unsupervised.png" class="lightbox" data-gallery="slides" title="tl-pretain-unsupervised"><img src="img/V2-016-tl-pretain-unsupervised.png" class="img-fluid figure-img" alt="tl-pretain-unsupervised"></a></p>
<figcaption>tl-pretain-unsupervised</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-017-tl-pretrain-selfsupervised.png" class="lightbox" data-gallery="slides" title="tl-pretrain-selfsupervised"><img src="img/V2-017-tl-pretrain-selfsupervised.png" class="img-fluid figure-img" alt="tl-pretrain-selfsupervised"></a></p>
<figcaption>tl-pretrain-selfsupervised</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-018-tl-pretrain-selfsupervised.png" class="lightbox" data-gallery="slides" title="tl-pretrain-selfsupervised"><img src="img/V2-018-tl-pretrain-selfsupervised.png" class="img-fluid figure-img" alt="tl-pretrain-selfsupervised"></a></p>
<figcaption>tl-pretrain-selfsupervised</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-019-tl-per-task-fine-tuning.png" class="lightbox" data-gallery="slides" title="tl-per-task-fine-tuning"><img src="img/V2-019-tl-per-task-fine-tuning.png" class="img-fluid figure-img" alt="tl-per-task-fine-tuning"></a></p>
<figcaption>tl-per-task-fine-tuning</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V2-020-tl-summary.png" class="lightbox" data-gallery="slides" title="tl-summary"><img src="img/V2-020-tl-summary.png" class="img-fluid figure-img" alt="tl-summary"></a></p>
<figcaption>tl-summary</figcaption>
</figure>
</div></div>









<p>There are three main advantages to transfer learning:</p>
<ul>
<li>Reduce training time</li>
<li>Improve predictions</li>
<li>Allows we to use smaller datasets</li>
</ul>
<p>Two methods that we can use for transfer learning are the following:</p>
<ul>
<li>pre-training</li>
<li>fine tuning</li>
</ul>
<p>In <strong>feature based</strong>, we can train word embeddings by running a different model and then using those features (i.e.&nbsp;word vectors) on a different task. When <strong>fine tuning</strong>, we can use the exact same model and just run it on a different task. Sometimes when fine tuning, we can keep the model weights fixed and just add a new layer that we will train. Other times we can slowly unfreeze the layers one at a time. We can also use unlabelled data when pre-training, by masking words and trying to predict which word was masked.</p>
<p>For example, in the drawing above we try to predict the word “friend”. This allows your model to get a grasp of the overall structure of the data and to help the model learn some relationships within the words of a sentence</p>
</section>
<section id="sec-video3-elmo-gpt-bert-t5" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-video3-elmo-gpt-bert-t5">ELMo, GPT, BERT, T5</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-030-outline.png" class="lightbox" data-gallery="slides" title="outline"><img src="img/V3-030-outline.png" class="img-fluid figure-img" alt="outline"></a></p>
<figcaption>outline</figcaption>
</figure>
</div></div><hr>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-031-cbow-fixed-window.png" class="lightbox" data-gallery="slides" title="CBOW-fixed-window"><img src="img/V3-031-cbow-fixed-window.png" class="img-fluid figure-img" alt="CBOW-fixed-window"></a></p>
<figcaption>CBOW-fixed-window</figcaption>
</figure>
</div></div><p>The models mentioned in the previous video were discovered in the following order.</p>
<ul>
<li>CBOW in Word2Vec - Issue: Fixed window we want all the context
<ul>
<li>2013 Word2Vec Google</li>
<li>CBOW &amp; Skip grams<br>
</li>
<li>2014 Glove Stanfor <a href="">GloVe: Global Vectors for Word ()</a></li>
</ul></li>
<li>ElMo - Bidirectional LSTM
<ul>
<li>Solves: fixed window size using a biderectional RNN</li>
<li>Issue: weak long term dependency</li>
</ul></li>
<li>GPT2 - issue: unidirectional. only looks back</li>
<li>BERT - just encoder - biderctional, multi mask learning</li>
<li>T5 - Encoder Decoder - multi-task learning</li>
</ul>
</section>
<section id="cbow" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="cbow">CBOW</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-032-cbow-issues.png" class="lightbox" data-gallery="slides" title="CBOW-issues"><img src="img/V3-032-cbow-issues.png" class="img-fluid figure-img" alt="CBOW-issues"></a></p>
<figcaption>CBOW-issues</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-033-elmo-solution.png" class="lightbox" data-gallery="slides" title="ELMo-solution"><img src="img/V3-033-elmo-solution.png" class="img-fluid figure-img" alt="ELMo-solution"></a></p>
<figcaption>ELMo-solution</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-034-elmo-rnn.png" class="lightbox" data-gallery="slides" title="ELMo-RNN"><img src="img/V3-034-elmo-rnn.png" class="img-fluid figure-img" alt="ELMo-RNN"></a></p>
<figcaption>ELMo-RNN</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-035-GPT-unidirectional.png" class="lightbox" data-gallery="slides" title="GPT-unidirectional"><img src="img/V3-035-GPT-unidirectional.png" class="img-fluid figure-img" alt="GPT-unidirectional"></a></p>
<figcaption>GPT-unidirectional</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-036-bert.png" class="lightbox" data-gallery="slides" title="BERT"><img src="img/V3-036-bert.png" class="img-fluid figure-img" alt="BERT"></a></p>
<figcaption>BERT</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-037-multi-mask.png" class="lightbox" data-gallery="slides" title="multi-mask"><img src="img/V3-037-multi-mask.png" class="img-fluid figure-img" alt="multi-mask"></a></p>
<figcaption>multi-mask</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-038-BERT-pre-training.png" class="lightbox" data-gallery="slides" title="BERT-pre-training"><img src="img/V3-038-BERT-pre-training.png" class="img-fluid figure-img" alt="BERT-pre-training"></a></p>
<figcaption>BERT-pre-training</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-039-t5-encoder-decoder.png" class="lightbox" data-gallery="slides" title="t5-encoder-decoder"><img src="img/V3-039-t5-encoder-decoder.png" class="img-fluid figure-img" alt="t5-encoder-decoder"></a></p>
<figcaption>t5-encoder-decoder</figcaption>
</figure>
</div></div>






<p>In CBOW, we want to encode a word as a vector. To do this we used the context before the word and the context after the word and we use that model to learn and creates features for the word. CBOW however uses a fixed window C (for the context).</p>
<p>the main isused with CBOW are:</p>
<ul>
<li>it has a fixed window size</li>
<li>no concept of order</li>
</ul>
<p>so what do we do when we need more context to model the concept we are looking at?</p>
<p>What ElMo does, it uses a bi-directional LSTM, which is a version of an RNN that looks at the inputs from the left and the right. This has the added benefit that the context size is no longer constrained. But since it is an RNN it has problems propagating information as sequences grow longer.</p>
<p>Then Open AI introduced GPT. GPT unfortunately is uni-directional but it makes use of transformers. Although ElMo was bi-directional, it suffered from some issues such as capturing longer-term dependencies.</p>
<p>BERT was then introduced which stands for the Bi-directional Encoder Representation from Transformers.</p>
<p>T5 was introduced which makes use of transfer learning and uses the same model to predict on many tasks.</p>
<ul>
<li>GPT was a transformer decoder</li>
<li>BERT was a transformer encoder</li>
<li>T5 is a decoder encoder</li>
</ul>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-041-t5-text-to-text.png" class="lightbox" data-gallery="slides" title="t5-text-to-text"><img src="img/V3-041-t5-text-to-text.png" class="img-fluid figure-img" alt="t5-text-to-text"></a></p>
<figcaption>t5-text-to-text</figcaption>
</figure>
</div></div><p>Here is an illustration of how T5 works:</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-042-question.png" class="lightbox" data-gallery="slides" title="question"><img src="img/V3-042-question.png" class="img-fluid figure-img" alt="question"></a></p>
<figcaption>question</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V3-043-summary.png" class="lightbox" data-gallery="slides" title="summary"><img src="img/V3-043-summary.png" class="img-fluid figure-img" alt="summary"></a></p>
<figcaption>summary</figcaption>
</figure>
</div></div>
<p>So we can now flesh out the table</p>
</section>
<section id="sec-video4-bert" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-video4-bert">BERT Bidirectional Encoder Representations from Transformers</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V4-050-bert-outline.png" class="lightbox" data-gallery="slides" title="BERT-outline"><img src="img/V4-050-bert-outline.png" class="img-fluid figure-img" alt="BERT-outline"></a></p>
<figcaption>BERT-outline</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V4-050-bert-question.png" class="lightbox" data-gallery="slides" title="BERT-question"><img src="img/V4-050-bert-question.png" class="img-fluid figure-img" alt="BERT-question"></a></p>
<figcaption>BERT-question</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V4-050-bert-summary.png" class="lightbox" data-gallery="slides" title="BERT-summary"><img src="img/V4-050-bert-summary.png" class="img-fluid figure-img" alt="BERT-summary"></a></p>
<figcaption>BERT-summary</figcaption>
</figure>
</div></div>

<p>lets dive deeper into BERT</p>
<p>There are two steps in the BERT framework: pre-training and fine-tuning. During pre-training, the model is trained on unlabeled data over different pre-training tasks. For fine tuning, the BERT model is first initialized with the pre-trained parameters, and all of the parameters are fine-tuned using labeled data from the downstream tasks. For example, in the figure above, we get the corresponding embeddings for the input words, we run it through a few transformer blocks, and then we make the prediction at each time point <span class="math inline">T_i</span>.</p>
<p>Training procedures:</p>
<ul>
<li>Choose 15% of the tokens at random:
<ul>
<li>mask them 80% of the time,</li>
<li>replace them with a random token 10% of the time,</li>
<li>keep as is 10% of the time. There could be multiple masked spans in a sentence. Next sentence prediction is also used when pre-training.</li>
</ul></li>
</ul>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V4-051-bert.png" class="lightbox" data-gallery="slides" title="BERT"><img src="img/V4-051-bert.png" class="img-fluid figure-img" alt="BERT"></a></p>
<figcaption>BERT</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V4-052-bert-spec.png" class="lightbox" data-gallery="slides" title="BERT-spec"><img src="img/V4-052-bert-spec.png" class="img-fluid figure-img" alt="BERT-spec"></a></p>
<figcaption>BERT-spec</figcaption>
</figure>
</div></div>
<p>Spec and features:</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V4-053-bert-pre-training.png" class="lightbox" data-gallery="slides" title="BERT-pre-training"><img src="img/V4-053-bert-pre-training.png" class="img-fluid figure-img" alt="BERT-pre-training"></a></p>
<figcaption>BERT-pre-training</figcaption>
</figure>
</div></div></section>
<section id="sec-video5-bert-objective" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-video5-bert-objective">BERT Objective</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V5-060-BERT-outline.png" class="lightbox" data-gallery="slides" title="BERT-outline"><img src="img/V5-060-BERT-outline.png" class="img-fluid figure-img" alt="BERT-outline"></a></p>
<figcaption>BERT-outline</figcaption>
</figure>
</div></div><p>MLM - masked language modeling.</p>
<p>This is the main unsupervised procedure to train the model with context left and right. It’s not clear how the model handles multiple masked items.</p>
<p>Does it try to predict them all at once or each one by considering input as context and unknowns.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V5-061-BERT-the-input.png" class="lightbox" data-gallery="slides" title="BERT-the-input"><img src="img/V5-061-BERT-the-input.png" class="img-fluid figure-img" alt="BERT-the-input"></a></p>
<figcaption>BERT-the-input</figcaption>
</figure>
</div></div><p>The input embeddings are the sum of the token embeddings, the segmentation embeddings and the position embeddings. The input embeddings: we have a CLS token to indicate the beginning of the sentence and a sep to indicate the end of the sentence The segment embeddings: allows we to indicate whether it is sentence a or b. Positional embeddings: allows we to indicate the word’s position in the sentence.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V5-062-BERT-the-output.png" class="lightbox" data-gallery="slides" title="BERT-the-output"><img src="img/V5-062-BERT-the-output.png" class="img-fluid figure-img" alt="BERT-the-output"></a></p>
<figcaption>BERT-the-output</figcaption>
</figure>
</div></div><p>The C token in the image above could be used for classification purposes. The unlabeled sentence A/B pair will depend on what we are trying to predict, it could range from question answering to sentiment. (in which case the second sentence could be just empty).</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V5-063-BERT-objectives.png" class="lightbox" data-gallery="slides" title="BERT-objectives"><img src="img/V5-063-BERT-objectives.png" class="img-fluid figure-img" alt="BERT-objectives"></a></p>
<figcaption>BERT-objectives</figcaption>
</figure>
</div></div><p>The BERT objective is defined as follows:</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V5-064-BERT-summary.png" class="lightbox" data-gallery="slides" title="BERT-summary"><img src="img/V5-064-BERT-summary.png" class="img-fluid figure-img" alt="BERT-summary"></a></p>
<figcaption>BERT-summary</figcaption>
</figure>
</div></div></section>
<section id="sec-video6-fine-tuning-bert" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-video6-fine-tuning-bert">Fine tuning BERT</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V6-070-BERT-fine-tuning-outline.png" class="lightbox" data-gallery="slides" title="BERT-fine-tuning-outline"><img src="img/V6-070-BERT-fine-tuning-outline.png" class="img-fluid figure-img" alt="BERT-fine-tuning-outline"></a></p>
<figcaption>BERT-fine-tuning-outline</figcaption>
</figure>
</div></div><p>Once we have a pre-trained model, we can fine tune it on different tasks.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V6-071-inputs.png" class="lightbox" data-gallery="slides" title="inputs"><img src="img/V6-071-inputs.png" class="img-fluid figure-img" alt="inputs"></a></p>
<figcaption>inputs</figcaption>
</figure>
</div></div><p>For example, given a hypothesis, we can identify the premise. Given a question, we can find the answer. We can also use it for named entity recognition. Here is a summary of the inputs.</p>
<ul>
<li>We can replace sentences A/B</li>
<li>Paraphrase from sentence A</li>
<li>Question/passage</li>
<li>Hypothesis premise pairs in entailment</li>
<li>Text and a Ø for classification/sequence tagging</li>
<li>Output tokens are fed into a layer for token level tasks otherwise use [CLS] embedding as input.</li>
</ul>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V6-072-summary.png" class="lightbox" data-gallery="slides" title="summary"><img src="img/V6-072-summary.png" class="img-fluid figure-img" alt="summary"></a></p>
<figcaption>summary</figcaption>
</figure>
</div></div></section>
<section id="transformer-t5" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="transformer-t5">Transformer: T5</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V7-073-t5-outline.png" class="lightbox" data-gallery="slides" title="t5-outline"><img src="img/V7-073-t5-outline.png" class="img-fluid figure-img" alt="t5-outline"></a></p>
<figcaption>t5-outline</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V7-074-t5-text-to-text.png" class="lightbox" data-gallery="slides" title="t5-text-to-text"><img src="img/V7-074-t5-text-to-text.png" class="img-fluid figure-img" alt="t5-text-to-text"></a></p>
<figcaption>t5-text-to-text</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V7-075-T5-transformer.png" class="lightbox" data-gallery="slides" title="T5-transformer"><img src="img/V7-075-T5-transformer.png" class="img-fluid figure-img" alt="T5-transformer"></a></p>
<figcaption>T5-transformer</figcaption>
</figure>
</div></div>

<p>One of the major techniques that allowed the T5 model to reach state of the art is the concept of masking:</p>
<p>For example, we represent the “for inviting” with <span class="math inline">&lt;X&gt;</span> and last with <span class="math inline">&lt;Y&gt;</span> then the model predicts what the X should be and what the Y should be. This is exactly what we saw in the BERT loss. We can also mask out a few positions, not just one. The loss is only on the mask for BERT, for T5 it is on the target.</p>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V7-076-T5-architecture.png" class="lightbox" data-gallery="slides" title="T5-architecture"><img src="img/V7-076-T5-architecture.png" class="img-fluid figure-img" alt="T5-architecture"></a></p>
<figcaption>T5-architecture</figcaption>
</figure>
</div></div><p>So we start with the basic encoder-decoder representation. There we have a fully visible attention in the encoder and then causal attention in the decoder. So light gray lines correspond to causal masking. And dark gray lines correspond to the fully visible masking.</p>
<p>In the middle we have the language model which consists of a single transformer layer stack. And it’s being fed the concatenation of the inputs and the target. So it uses causal masking throughout as we can see because they’re all gray lines. And we have <span class="math inline">X_1</span> going inside, we get <span class="math inline">X_2</span>, <span class="math inline">X_2</span> goes into the model and we get <span class="math inline">X3</span> and so forth.</p>
<p>To the right, we have prefix language model which corresponds to allowing fully visible masking over the inputs as we can see with the dark arrows. And then causal masking in the rest.</p>
</section>
<section id="sec-video8-multi-task-training-strategy" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-video8-multi-task-training-strategy">Lecture Multi-Task Training Strategy</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V8-080-T5-architecture.png" class="lightbox" data-gallery="slides" title="T5-architecture"><img src="img/V8-080-T5-architecture.png" class="img-fluid figure-img" alt="T5-architecture"></a></p>
<figcaption>T5-architecture</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V8-081-T5-summary.png" class="lightbox" data-gallery="slides" title="T5-summary"><img src="img/V8-081-T5-summary.png" class="img-fluid figure-img" alt="T5-summary"></a></p>
<figcaption>T5-summary</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V8-082-T5-multi-task-training.png" class="lightbox" data-gallery="slides" title="T5-multi-task-training"><img src="img/V8-082-T5-multi-task-training.png" class="img-fluid figure-img" alt="T5-multi-task-training"></a></p>
<figcaption>T5-multi-task-training</figcaption>
</figure>
</div></div>

<p>This is a reminder of how the T5 model works:</p>
<p>We can see that we only have to add a small prefix to the input and the model as a result will solve the task for you. There are many tasks that the t5 model can do for you. It is possible to formulate most NLP tasks in a “text-to-text” format – that is, a task where the model is fed some text for context or conditioning and is then asked to produce some output text. This framework provides a consistent training objective both for pre-training and fine-tuning. Specifically, the model is trained with a maximum likelihood objective (using “teacher forcing” ) regardless of the task.</p>
<section id="sec-training-data-strategies" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sec-training-data-strategies">Training data strategies</h3>
<dl>
<dt>Examples-proportional mixing</dt>
<dd>
sample in proportion to the size of each task’s dataset
</dd>
<dt>Temperature scaled mixing</dt>
<dd>
adjust the “temperature”” of the mixing rates. This temperature parameter allows we to weight certain examples more than others. To implement temperature scaling with temperature T, we raise each task’s mixing rate rm to the power of 1⁄T and renormalize the rates so that they sum to 1. When T = 1, this approach is equivalent to examples-proportional mixing and as T increases the proportions become closer to equal mixing
</dd>
<dt>Equal mixing</dt>
<dd>
In this case, we sample examples from each task with equal probability. Specifically, each example in each batch is sampled uniformly at random from one of the datasets we train on.
</dd>
</dl>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V8-083-io-format.png" class="lightbox" data-gallery="slides" title="io-format"><img src="img/V8-083-io-format.png" class="img-fluid figure-img" alt="io-format"></a></p>
<figcaption>io-format</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V8-084-multi-task-training.png" class="lightbox" data-gallery="slides" title="multi-task-training"><img src="img/V8-084-multi-task-training.png" class="img-fluid figure-img" alt="multi-task-training"></a></p>
<figcaption>multi-task-training</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V8-085-data-training-strategy.png" class="lightbox" data-gallery="slides" title="data-training-strategy"><img src="img/V8-085-data-training-strategy.png" class="img-fluid figure-img" alt="data-training-strategy"></a></p>
<figcaption>data-training-strategy</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V8-086-unfreezing-adapter-layers.png" class="lightbox" data-gallery="slides" title="unfreezing-adapter-layers"><img src="img/V8-086-unfreezing-adapter-layers.png" class="img-fluid figure-img" alt="unfreezing-adapter-layers"></a></p>
<figcaption>unfreezing-adapter-layers</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V8-087-question.png" class="lightbox" data-gallery="slides" title="question"><img src="img/V8-087-question.png" class="img-fluid figure-img" alt="question"></a></p>
<figcaption>question</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V8-088-fine-tuning.png" class="lightbox" data-gallery="slides" title="fine-tuning"><img src="img/V8-088-fine-tuning.png" class="img-fluid figure-img" alt="fine-tuning"></a></p>
<figcaption>fine-tuning</figcaption>
</figure>
</div></div>




<p>We can see how fine tuning on a specific task could work even though we were pre-training on different tasks.</p>
</section>
</section>
<section id="sec-video9-glue-benchmark" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-video9-glue-benchmark">GLUE Benchmark</h2>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V9-090-GLUE-evaluation.png" class="lightbox" data-gallery="slides" title="GLUE-evaluation"><img src="img/V9-090-GLUE-evaluation.png" class="img-fluid figure-img" alt="GLUE-evaluation"></a></p>
<figcaption>GLUE-evaluation</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V9-091-GLUE-tasks.png" class="lightbox" data-gallery="slides" title="GLUE-tasks"><img src="img/V9-091-GLUE-tasks.png" class="img-fluid figure-img" alt="GLUE-tasks"></a></p>
<figcaption>GLUE-tasks</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V9-092-GLUE.png" class="lightbox" data-gallery="slides" title="GLUE"><img src="img/V9-092-GLUE.png" class="img-fluid figure-img" alt="GLUE"></a></p>
<figcaption>GLUE</figcaption>
</figure>
</div></div>

<p>General Language Understanding Evaluation (GLUE) is contains:</p>
<ul>
<li>A collection used to train, evaluate, analyze natural language understanding systems</li>
<li>Datasets with different genres, and of different sizes and difficulties</li>
<li>Leaderboard</li>
</ul>
<p>Currently T5 is state of the art according to this GLUE benchmark and we will be implementing it for homework this week! This GLUE bench mark is used for research purposes, it is model agnostic, and relies on models that make use of transfer learning.</p>
</section>
<section id="sec-video10-question-answering" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-video10-question-answering">Question Answering</h2>
<div class="page-columns page-full"><p> We will be implementing an encoder this week. Last week we implemented the decoder. So here it is:</p><div class="no-row-height column-margin column-container"><img src="img/V9-093-BERT-feed-forward-block.png" class="img-fluid" data-group="slides" alt="BERT-feed-forward-block"></div></div>

<div class="no-row-height column-margin column-container"><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V9-094-BERT-encoder-Block.png" class="lightbox" data-gallery="slides" title="BERT-encoder-Block"><img src="img/V9-094-BERT-encoder-Block.png" class="img-fluid figure-img" alt="BERT-encoder-Block"></a></p>
<figcaption>BERT-encoder-Block</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V9-095-BERT-blocks.png" class="lightbox" data-gallery="slides" title="BERT-blocks"><img src="img/V9-095-BERT-blocks.png" class="img-fluid figure-img" alt="BERT-blocks"></a></p>
<figcaption>BERT-blocks</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V9-096-q&amp;a-data-example.png" class="lightbox" data-gallery="slides" title="q&amp;a-data-example"><img src="img/V9-096-q&amp;a-data-example.png" class="img-fluid figure-img" alt="q&amp;a-data-example"></a></p>
<figcaption>q&amp;a-data-example</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V9-097-q&amp;a-with-t5.png" class="lightbox" data-gallery="slides" title="q&amp;a-with-t5"><img src="img/V9-097-q&amp;a-with-t5.png" class="img-fluid figure-img" alt="q&amp;a-with-t5"></a></p>
<figcaption>q&amp;a-with-t5</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V9-098-t5.png" class="lightbox" data-gallery="slides" title="t5"><img src="img/V9-098-t5.png" class="img-fluid figure-img" alt="t5"></a></p>
<figcaption>t5</figcaption>
</figure>
</div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="img/V9-099-t5-question.png" class="lightbox" data-gallery="slides" title="t5-question"><img src="img/V9-099-t5-question.png" class="img-fluid figure-img" alt="t5-question"></a></p>
<figcaption>t5-question</figcaption>
</figure>
</div></div>




<p>We can see there is a feed forward and the encoder-block above. It makes use of two residual connections, layer normalization, and dropout.</p>
<p>The steps we will follow to implement it are:</p>
<ul>
<li>Load a pre-trained model</li>
<li>Process data to get the required inputs and outputs: “question: Q context: C” as input and “A” as target</li>
<li>Fine tune your model on the new task and input</li>
<li>Predict using your own model</li>
</ul>
</section>
<section id="sec-programming-assignment-question-answering" class="level2">
<h2 class="anchored" data-anchor-id="sec-programming-assignment-question-answering">Programming Assignment: Question Answering</h2>
</section>
<section id="sec-lab-sentencepiece-and-bpe" class="level2">
<h2 class="anchored" data-anchor-id="sec-lab-sentencepiece-and-bpe">Lab: SentencePiece and BPE</h2>
<section id="sec-nfkc-normalization" class="level3">
<h3 class="anchored" data-anchor-id="sec-nfkc-normalization">NFKC Normalization</h3>
<p>unicode normalization - for accents, diacritics and friends</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> unicodedata <span class="im">import</span> normalize</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>norm_eaccent <span class="op">=</span> normalize(<span class="st">'NFKC'</span>, <span class="st">'</span><span class="ch">\u00E9</span><span class="st">'</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>norm_e_accent <span class="op">=</span> normalize(<span class="st">'NFKC'</span>, <span class="st">'</span><span class="ch">\u0065\u0301</span><span class="st">'</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>norm_eaccent<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>norm_e_accent<span class="sc">}</span><span class="ss"> : </span><span class="sc">{</span>norm_eaccent <span class="op">==</span> norm_e_accent<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="lossless-tokenization" class="level2">
<h2 class="anchored" data-anchor-id="lossless-tokenization">lossless tokenization</h2>
<p>To ensure this lossless tokenization it replaces white space with _ (U+2581).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>s_ <span class="op">=</span> s.replace(<span class="st">' '</span>, <span class="st">'</span><span class="ch">\u2581</span><span class="st">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="sec-sentencepiece" class="level3">
<h3 class="anchored" data-anchor-id="sec-sentencepiece">SentencePiece</h3>
<p><a href="../../notes/c4w3/lab01.html">Tokenization with SentencePiece lab</a></p>
</section>
<section id="sec-bpe" class="level3">
<h3 class="anchored" data-anchor-id="sec-bpe">BPE</h3>
</section>
</section>
<section id="sec-lab-bert-loss" class="level2">
<h2 class="anchored" data-anchor-id="sec-lab-bert-loss">Lab: BERT Loss</h2>
</section>
<section id="sec-lab-t5" class="level2">
<h2 class="anchored" data-anchor-id="sec-lab-t5">Lab: T5</h2>
<p><a href="https://drive.google.com/file/d/1c-8KJkTySRGqCx_JjwjvXuRBTNTqEE0N/view?usp=sharing">open in coloab</a></p>
</section>
<section id="representation.-pdf-bib" class="level2">
<h2 class="anchored" data-anchor-id="representation.-pdf-bib">Representation. [pdf] [bib]</h2>
<ul>
<li>2017 fasttext Facebook CBOW
<ul>
<li>morphological via sub words Algorithm of fasttext is based on these two papers:[8]</li>
<li>Enriching Word Vectors with Subword Information , Piotr Bojanowski, Edouard Grave, Armand Joulin and Tomas Mikolov, 2016</li>
<li>Bag of Tricks for Efficient Text Classification, Armand Joulin, Edouard Grave, Piotr Bojanowski, Tomas Mikolov, 2016</li>
</ul></li>
<li>2018 ELMO Allen Institute for AI ELMo - Character based Bidirectional LSTM - Issue: long term dependency is weak due to vanishing gradient and information loss.</li>
<li>GPT Encoder only with left context</li>
<li>Bert uses</li>
<li>2020 T5 uses a label to specify task uses task specific bidirectional lstm to build the embeddings</li>
<li>BERT Decoder only</li>
</ul>
<p>Input Token embedding - the distributed representation of the tokens in one space S with Dim(S)=D</p>
<pre><code>Segment embedding - because the model cannot tell the segment apart

Position embedding because the model cannot discriminate the word position. </code></pre>
<p>Note we are trying to mimic RNN behavior but we don’t have recursion:</p>
<p>Note these are added - they all live in S. Question: would putting S and P in their own dimensions more interpretable. Questions: how do we know the model does not have embeddings that are similar to E_A and E_0 Output CLS - classification token SEP - separator token convert to embedding C is used for next sentence prediction T_i are used for masked word prediction T</p>
<pre><code>Cross entropy loss + Binary loss

cross entropy loss to compare between two distribution from Softmax

binary loss - could use cross entropy on two cat.
Pretraining
        before feeding data we mask 15% of the tokens.
mask 80% of the time:
training data generator chooses 15%. of these at random for prediction
replace with:
mask .8 of the time a random word .1 of the time
original world otherwise.

a sentence may have multiple masks.

next sentence prediction also used in pre training.
why/how
(s1,s2) true/false


BERT_Base
12 layers
12 attention heads
110 million parameters</code></pre>
<p>Fine tuning BERT<br>
Fine tuning</p>
<p>T5 like BERT does Transfer learning + fine tuning. classification, MT, NE, Sentiment</p>
<pre><code>So we can see over here we have fully visible attention in the encoder and then causal attention in the decoder. 
And then we have the general encoder-decoder representation just as 
notation. 
So light gray lines correspond to causal masking. 
And dark gray lines correspond to the fully visible masking. 
So on the left as I said again, it's the standard encoder-decoder architecture. 
In the middle over here what we have, 
we have the language model which consists of a single transformer layer stack. 
And it's being fed the concatenation of the inputs and the target. 
So it uses causal masking throughout as we can see because they're 
all gray lines. 
And we have X1 going inside over here, get at X2, 
X2 goes into the model X3 and so forth. 
Now over here to the right, 
we have prefix language model which corresponds to allowing fully 
visible masking over the inputs as we can see here in the dark arrows. 
And then causal masking in the rest.
Play video starting at :3:2 and follow transcript3:02
So as we can see over here, it's doing causal masking. 
So the model architecture, it uses encoder/decoder stack. 
It has 12 transformer blocks each. 
So we can think of it as a dozen eggs and then 220 million parameters. 
So in summary, you've seen prefix language model attention. 
You've seen the model architecture for T5. 
And you've seen how the pre-training is done similar to birds, but 
we just use mask language modeling here.


encoder/decoder</code></pre>
<p>1212 transformer blocks 220 million parameters pre training 2^18 steps = 262144</p>
</section>
<section id="references" class="level1">
<h1>References:</h1>
<section id="tokenization" class="level2">
<h2 class="anchored" data-anchor-id="tokenization">Tokenization</h2>
<ol type="1">
<li><a href="https://www.aclweb.org/anthology/D18-2012.pdf">SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing (Kudo &amp; Richardson 2018)</a> sub-word tokenization</li>
<li><a href="https://www.aclweb.org/anthology/P18-1007.pdf">Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates (Kudo 2018)</a> sub-word tokenization</li>
<li><a href="https://arxiv.org/pdf/1508.07909.pdf">Neural Machine Translation of Rare Words with Subword Units (Sennrich et all 2016)</a> sub-word tokenization</li>
<li><a href="https://www.tensorflow.org/tutorials/tensorflow_text/subwords_tokenizer">Subword tokenizers TF tutorial</a> sub-word tokenization</li>
<li>[https://blog.floydhub.com/tokenization-nlp/]</li>
<li><a href="https://arxiv.org/abs/1602.02215">Swivel: Improving Embeddings by Noticing What’s Missing (Shazeer, 2016)</a></li>
</ol>
</section>
<section id="transformers" class="level2">
<h2 class="anchored" data-anchor-id="transformers">Transformers</h2>
<ol type="1">
<li><a href="https://arxiv.org/abs/1910.10683">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a> (Raffel et al, 2019)<br>
</li>
<li><a href="https://arxiv.org/abs/2001.04451">Reformer: The Efficient Transformer</a> (Kitaev et al, 2020)</li>
<li><a href="https://arxiv.org/abs/1706.03762">Attention Is All We Need</a> (Vaswani et al, 2017)</li>
<li><a href="https://arxiv.org/pdf/1802.05365.pdf">Deep contextualized word representations</a> (Peters et al, 2018)</li>
<li><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a> (Devlin et al, 2018)</li>
<li><a href="https://arxiv.org/abs/2103.13076" title="(Kasai et all 2021)">Finetuning Pretrained Transformers into RNNs</a> (Kasai et all 2021)</li>
<li><a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a> (Alammar, 2018)</li>
<li><a href="http://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT-2</a> (Alammar, 2019)</li>
<li><a href="http://jalammar.github.io/how-gpt3-works-visualizations-animations/">How GPT3 Works - Visualizations and Animations</a> (Alammar, 2020)</li>
<li><a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" title="Lilian Weng, 2018">Attention? Attention!</a> (Lilian Weng, 2018)</li>
<li><a href="https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html" title="(Lilian Weng, 2020)">The Transformer Family</a> (Lilian Weng, 2020)</li>
<li><a href="https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/">Teacher forcing for RNNs</a></li>
</ol>
<section id="question-answering-task" class="level3">
<h3 class="anchored" data-anchor-id="question-answering-task">Question Answering Task:</h3>
<ol type="1">
<li><a href="https://arxiv.org/pdf/1509.00685.pdf">Title (Author et al., Year)</a> note</li>
</ol>
</section>
</section>
<section id="links" class="level2">
<h2 class="anchored" data-anchor-id="links">Links</h2>
<ul>
<li><a href="https://github.com/google/jax">Jax</a></li>
<li><a href="https://trax-ml.readthedocs.io/en/latest/index.html">Trax</a></li>
<li><a href="https://gitter.im/trax-ml/community">Trax community</a> on Gitter</li>
<li><a href="https://github.com/abisee/cnn-dailymail">CNN daily mail dataset</a></li>
</ul>
<p>Lei Mao Machine Learning, Artificial Intelligence, Computer Science. [Byte Pair Encoding (Lei Mao 2021)] (https://leimao.github.io/blog/Byte-Pair-Encoding/) videos: Q&amp;A</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/yIdF-17HwSk?start=223" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>Subword tokenizers</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/hAvtJ516Mw4?start=223" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>Swivel Embeddings</p>
<p>https://youtu.be/hAvtJ516Mw4</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-raffel2023exploringlimitstransferlearning" class="csl-entry" role="listitem">
Raffel, Colin, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2023. <span>“Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.”</span> <a href="https://arxiv.org/abs/1910.10683">https://arxiv.org/abs/1910.10683</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{bochman2021,
  author = {Bochman, Oren},
  title = {Question {Answering}},
  date = {2021-04-10},
  url = {https://orenbochman.github.io/notes-nlp/notes/c4w3/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-bochman2021" class="csl-entry quarto-appendix-citeas" role="listitem">
Bochman, Oren. 2021. <span>“Question Answering.”</span> April 10, 2021.
<a href="https://orenbochman.github.io/notes-nlp/notes/c4w3/">https://orenbochman.github.io/notes-nlp/notes/c4w3/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/www\.quarto\.org\/custom");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2023-2025, Oren Bochman</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/OrenBochman/notes-nlp/edit/main/notes/c4w3/index.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/OrenBochman/notes-nlp/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 💛 and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"fade","descPosition":"right","loop":true,"openEffect":"fade","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>